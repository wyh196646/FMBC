{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import ModuleList\n",
    "from functools import partial\n",
    "from typing import List, Tuple, Dict, Optional, Any\n",
    "from torchvision.transforms import Compose, RandomApply\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms.transforms import _setup_angle, _check_sequence_input\n",
    "from torch import Tensor\n",
    "from collections import defaultdict, deque\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from PIL import ImageFilter, ImageOps, Image, ImageDraw\n",
    "\n",
    "import os\n",
    "# 设定实验结果的目录 (请修改为你的实际路径)\n",
    "result_dir = \"/home/yuhaowang/project/FMBC/finetune/outputs/BRACS_Fine\"\n",
    "\n",
    "# 需要展示的评估指标\n",
    "evaluation_metrics = ['val_bacc', 'val_weighted_f1', 'val_macro_auroc']\n",
    "\n",
    "# 你希望的模型顺序（从上到下）\n",
    "desired_order = [\n",
    "    \"UNI\", \"CONCH\", \"Virchow\",\"Gigapath_Tile\",'Gigapath',\"CHIEF_Tile\",\"TITAN\",\"FMBC\"  # 请修改为你的模型名称\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# 遍历目录中的所有模型文件夹\n",
    "for model_name in os.listdir(result_dir):\n",
    "    model_path = os.path.join(result_dir, model_name, \"summary.csv\")\n",
    "    \n",
    "    # 检查是否存在 summary.csv 文件\n",
    "    if os.path.isfile(model_path):\n",
    "        df = pd.read_csv(model_path)\n",
    "\n",
    "        # 计算均值和标准差\n",
    "        summary_stats = {\"Model\": model_name}\n",
    "        for metric in evaluation_metrics:\n",
    "            if metric in df.columns:\n",
    "                mean_val = np.mean(df[metric])\n",
    "                std_val = np.std(df[metric], ddof=1)  # 样本标准差\n",
    "                summary_stats[metric] = f\"{mean_val:.3f}±{std_val:.4f}\"\n",
    "\n",
    "        # 添加到列表\n",
    "        all_results.append(summary_stats)\n",
    "\n",
    "# 转换为 DataFrame\n",
    "final_result_df = pd.DataFrame(all_results)\n",
    "\n",
    "# 按照提供的模型顺序排序\n",
    "final_result_df['sort_order'] = final_result_df['Model'].apply(lambda x: desired_order.index(x) if x in desired_order else len(desired_order))\n",
    "#delete the model not in desired_order\n",
    "final_result_df = final_result_df[final_result_df['sort_order']!=len(desired_order)]\n",
    "final_result_df = final_result_df.sort_values(by='sort_order').drop(columns=['sort_order'])\n",
    "final_result_df.style.hide(axis=\"index\")\n",
    "# 在 Jupyter Notebook 中美观显示\n",
    "display(final_result_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_path = '/home/yuhaowang/data/processed_data'\n",
    "embedding_path ='/data1/embedding'\n",
    "for dataset in os.listdir(data_path):\n",
    "    print(dataset,'has',len(os.listdir(os.path.join(data_path, dataset, 'output'))),'slides')\n",
    "    dataset_embedding_path = os.path.join(embedding_path, dataset)\n",
    "    if not os.path.exists(dataset_embedding_path):\n",
    "        print(dataset, 'has no embedding')\n",
    "        print('---------------------------')\n",
    "\n",
    "        continue\n",
    "    for model in os.listdir(dataset_embedding_path):\n",
    "        print(model,'has',len(os.listdir(os.path.join(dataset_embedding_path, model))),'slides processed')\n",
    "    print('---------------------------')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  h5py\n",
    "def read_assets_from_h5( h5_path: str) -> tuple:\n",
    "    '''Read the assets from the h5 file'''\n",
    "    assets = {}\n",
    "    attrs = {}\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        for key in f.keys():\n",
    "            assets[key] = f[key][:]\n",
    "            if f[key].attrs is not None:\n",
    "                attrs[key] = dict(f[key].attrs)\n",
    "    return assets, attrs\n",
    "\n",
    "data_dir = '/data1/embedding/TCGA-BRCA'\n",
    "for model in os.listdir(data_dir):\n",
    "    embedding_path=os.path.join(data_dir,model)\n",
    "    test_case = os.listdir(embedding_path)[0]\n",
    "    test_data,_ = read_assets_from_h5(os.path.join(embedding_path,test_case))\n",
    "    print(test_data.keys())\n",
    "    print(model)\n",
    "    print(test_data['features'].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
