I20250104 12:39:11 94 dinov2 config.py:67] git:
  sha: fda283ef182296a3187e17b7c6482658c6b64ee3, status: has uncommitted changes, branch: main

I20250104 12:39:11 94 dinov2 config.py:68] config_file: dinov2/configs/train/patch.yaml
eval: 
eval_only: False
local_rank: 4
no_resume: False
opts: ['train.dataset_path=TileDataset:split=TRAIN:root=/ruiyan/yuhao/data', 'train.output_dir=/ruiyan/yuhao/project/FMBC/dinov2/output']
output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
I20250104 12:39:11 94 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.006838803314120883
I20250104 12:39:11 94 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
dino:
  loss_weight: 1.0
  head_n_prototypes: 384
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 384
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 380
  dataset_path: TileDataset:split=TRAIN:root=/ruiyan/yuhao/data
  output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
  saveckp_freq: 20
  seed: 0
  num_workers: 8
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 2000
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.006838803314120883
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250104 12:39:11 94 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250104 12:39:12 94 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250104 12:39:13 94 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 768
I20250104 12:39:13 94 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20250104 12:39:13 94 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20250104 12:39:13 94 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 384
I20250104 12:39:13 94 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20250104 12:39:13 94 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20250104 12:39:13 94 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20250104 12:39:14 94 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20250104 12:39:14 94 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20250104 12:39:14 94 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20250104 12:39:14 94 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20250104 12:39:14 94 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20250104 12:39:14 94 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_base network.
I20250104 12:39:14 94 dinov2 ssl_meta_arch.py:396] DISTRIBUTED FSDP -- preparing model for distributed training
I20250104 12:39:14 94 dinov2 train.py:307] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x Identity()
              (3-5): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-8): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-8): 9 x Identity()
              (9-11): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=384, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x Identity()
              (3-5): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-8): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-8): 9 x Identity()
              (9-11): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=384, bias=False)
      )
    )
  )
)
I20250104 12:39:14 94 dinov2 param_groups.py:54] chunked fsdp
I20250104 12:39:14 94 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.05083731656658002, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.05083731656658002, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.3.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.4.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.1.5.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.6.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.7.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.2.8.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.9.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.10.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] blocks.3.11.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250104 12:39:14 94 dinov2 param_groups.py:64] else code branch
I20250104 12:39:14 94 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 12:39:14 94 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250104 12:39:14 94 dinov2 train.py:106] Schedulers ready.
I20250104 12:39:14 94 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250104 12:39:14 94 dinov2 augmentations.py:34] ###################################
I20250104 12:39:14 94 dinov2 augmentations.py:35] Using data augmentation parameters:
I20250104 12:39:14 94 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20250104 12:39:14 94 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20250104 12:39:14 94 dinov2 augmentations.py:38] local_crops_number: 8
I20250104 12:39:14 94 dinov2 augmentations.py:39] global_crops_size: 224
I20250104 12:39:14 94 dinov2 augmentations.py:40] local_crops_size: 96
I20250104 12:39:14 94 dinov2 augmentations.py:41] ###################################
I20250104 12:39:14 94 dinov2 loaders.py:87] using dataset: "TileDataset:split=TRAIN:root=/ruiyan/yuhao/data"
I20250104 12:47:05 94 dinov2 loaders.py:92] # of dataset samples: 1,960,591
I20250104 12:47:05 94 dinov2 loaders.py:125] sampler: sharded infinite
I20250104 12:47:05 94 dinov2 loaders.py:209] using PyTorch data loader
I20250104 12:47:05 94 dinov2 loaders.py:224] infinite data loader
I20250104 12:47:05 94 dinov2 train.py:221] Starting training from iteration 0
I20250104 12:48:44 94 dinov2 helpers.py:102] Training  [      0/2500000]  eta: 2859 days, 5:29:31  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: inf (inf)  dino_local_crops_loss: 4.6841 (4.6841)  dino_global_crops_loss: 0.5855 (0.5855)  koleo_loss: inf (inf)  ibot_loss: 1.4946 (1.4946)  time: 98.814949  data: 19.400043  max mem: 61574
I20250104 12:48:57 94 dinov2 helpers.py:102] Training  [     10/2500000]  eta: 292 days, 13:30:35  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.8513 (inf)  dino_local_crops_loss: 4.9623 (4.9458)  dino_global_crops_loss: 0.6203 (0.6182)  koleo_loss: 0.7070 (inf)  ibot_loss: 1.5086 (1.5069)  time: 10.111014  data: 1.763970  max mem: 61695
I20250104 12:49:09 94 dinov2 helpers.py:102] Training  [     20/2500000]  eta: 170 days, 16:47:57  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.9619 (inf)  dino_local_crops_loss: 5.1607 (5.0995)  dino_global_crops_loss: 0.6451 (0.6374)  koleo_loss: 0.6292 (inf)  ibot_loss: 1.5107 (1.5090)  time: 1.253663  data: 0.000288  max mem: 61695
I20250104 12:49:22 94 dinov2 helpers.py:102] Training  [     30/2500000]  eta: 127 days, 4:22:46  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.9729 (inf)  dino_local_crops_loss: 5.3146 (5.1710)  dino_global_crops_loss: 0.6643 (0.6464)  koleo_loss: 0.4844 (inf)  ibot_loss: 1.5056 (1.5051)  time: 1.251935  data: 0.000269  max mem: 61695
I20250104 12:49:34 94 dinov2 helpers.py:102] Training  [     40/2500000]  eta: 104 days, 19:23:29  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.8926 (inf)  dino_local_crops_loss: 5.3179 (5.2055)  dino_global_crops_loss: 0.6647 (0.6507)  koleo_loss: 0.4180 (inf)  ibot_loss: 1.4844 (1.4972)  time: 1.231144  data: 0.000393  max mem: 61695
I20250104 12:49:46 94 dinov2 helpers.py:102] Training  [     50/2500000]  eta: 91 days, 6:59:37  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.8134 (inf)  dino_local_crops_loss: 5.3059 (5.2246)  dino_global_crops_loss: 0.6632 (0.6531)  koleo_loss: 0.3792 (inf)  ibot_loss: 1.4569 (1.4878)  time: 1.232497  data: 0.000477  max mem: 61695
I20250104 12:49:58 94 dinov2 helpers.py:102] Training  [     60/2500000]  eta: 82 days, 0:01:04  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.7628 (inf)  dino_local_crops_loss: 5.3001 (5.2369)  dino_global_crops_loss: 0.6625 (0.6546)  koleo_loss: 0.3532 (inf)  ibot_loss: 1.4355 (1.4772)  time: 1.218188  data: 0.000486  max mem: 61695
I20250104 12:50:10 94 dinov2 helpers.py:102] Training  [     70/2500000]  eta: 75 days, 10:04:02  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.6827 (inf)  dino_local_crops_loss: 5.3001 (5.2464)  dino_global_crops_loss: 0.6624 (0.6557)  koleo_loss: 0.3088 (inf)  ibot_loss: 1.4072 (1.4649)  time: 1.207833  data: 0.000452  max mem: 61695
I20250104 12:50:25 94 dinov2 helpers.py:102] Training  [     80/2500000]  eta: 71 days, 8:23:46  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5742 (inf)  dino_local_crops_loss: 5.3078 (5.2543)  dino_global_crops_loss: 0.6628 (0.6566)  koleo_loss: 0.2331 (inf)  ibot_loss: 1.3645 (1.4508)  time: 1.343271  data: 0.000328  max mem: 61695
I20250104 12:50:38 94 dinov2 helpers.py:102] Training  [     90/2500000]  eta: 67 days, 16:10:10  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.4723 (inf)  dino_local_crops_loss: 5.3049 (5.2594)  dino_global_crops_loss: 0.6625 (0.6573)  koleo_loss: 0.1611 (inf)  ibot_loss: 1.3397 (1.4381)  time: 1.388619  data: 0.000337  max mem: 61695
I20250104 12:50:52 94 dinov2 helpers.py:102] Training  [    100/2500000]  eta: 64 days, 20:51:44  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.3696 (inf)  dino_local_crops_loss: 5.2941 (5.2624)  dino_global_crops_loss: 0.6616 (0.6576)  koleo_loss: 0.0845 (inf)  ibot_loss: 1.3316 (1.4274)  time: 1.334942  data: 0.000435  max mem: 61695
I20250104 12:51:05 94 dinov2 helpers.py:102] Training  [    110/2500000]  eta: 62 days, 10:01:27  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.3295 (inf)  dino_local_crops_loss: 5.2861 (5.2645)  dino_global_crops_loss: 0.6609 (0.6579)  koleo_loss: 0.0510 (inf)  ibot_loss: 1.3284 (1.4179)  time: 1.330795  data: 0.000432  max mem: 61695
I20250104 12:51:20 94 dinov2 helpers.py:102] Training  [    120/2500000]  eta: 60 days, 21:29:37  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.3054 (inf)  dino_local_crops_loss: 5.2866 (5.2667)  dino_global_crops_loss: 0.6610 (0.6582)  koleo_loss: 0.0392 (inf)  ibot_loss: 1.3118 (1.4086)  time: 1.411188  data: 0.000522  max mem: 61695
I20250104 12:51:33 94 dinov2 helpers.py:102] Training  [    130/2500000]  eta: 59 days, 3:46:47  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.3462 (inf)  dino_local_crops_loss: 5.3002 (5.2789)  dino_global_crops_loss: 0.6629 (0.6598)  koleo_loss: 0.0328 (inf)  ibot_loss: 1.2978 (1.3993)  time: 1.419323  data: 0.000574  max mem: 61695
I20250104 12:51:47 94 dinov2 helpers.py:102] Training  [    140/2500000]  eta: 57 days, 19:28:10  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5636 (inf)  dino_local_crops_loss: 5.5653 (5.3009)  dino_global_crops_loss: 0.6943 (0.6624)  koleo_loss: 0.0280 (inf)  ibot_loss: 1.2724 (1.3897)  time: 1.353236  data: 0.000617  max mem: 61695
I20250104 12:52:00 94 dinov2 helpers.py:102] Training  [    150/2500000]  eta: 56 days, 12:45:25  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5810 (inf)  dino_local_crops_loss: 5.6022 (5.3213)  dino_global_crops_loss: 0.6990 (0.6649)  koleo_loss: 0.0282 (inf)  ibot_loss: 1.2488 (1.3800)  time: 1.359489  data: 0.000624  max mem: 61695
I20250104 12:52:15 94 dinov2 helpers.py:102] Training  [    160/2500000]  eta: 55 days, 14:42:31  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5798 (inf)  dino_local_crops_loss: 5.6156 (5.3400)  dino_global_crops_loss: 0.7011 (0.6672)  koleo_loss: 0.0294 (inf)  ibot_loss: 1.2347 (1.3703)  time: 1.386553  data: 0.000543  max mem: 61695
I20250104 12:52:28 94 dinov2 helpers.py:102] Training  [    170/2500000]  eta: 54 days, 14:13:53  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5790 (inf)  dino_local_crops_loss: 5.6256 (5.3568)  dino_global_crops_loss: 0.7022 (0.6693)  koleo_loss: 0.0298 (inf)  ibot_loss: 1.2143 (1.3608)  time: 1.381118  data: 0.000603  max mem: 61695
I20250104 12:52:41 94 dinov2 helpers.py:102] Training  [    180/2500000]  eta: 53 days, 17:24:09  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5624 (inf)  dino_local_crops_loss: 5.6293 (5.3720)  dino_global_crops_loss: 0.7027 (0.6711)  koleo_loss: 0.0305 (inf)  ibot_loss: 1.1983 (1.3515)  time: 1.331773  data: 0.000551  max mem: 61695
I20250104 12:52:55 94 dinov2 helpers.py:102] Training  [    190/2500000]  eta: 52 days, 22:03:02  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5558 (inf)  dino_local_crops_loss: 5.6328 (5.3858)  dino_global_crops_loss: 0.7030 (0.6728)  koleo_loss: 0.0308 (inf)  ibot_loss: 1.1865 (1.3427)  time: 1.334397  data: 0.000529  max mem: 61695
I20250104 12:53:09 94 dinov2 helpers.py:102] Training  [    200/2500000]  eta: 52 days, 7:46:21  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5474 (inf)  dino_local_crops_loss: 5.6372 (5.3983)  dino_global_crops_loss: 0.7035 (0.6744)  koleo_loss: 0.0308 (inf)  ibot_loss: 1.1768 (1.3341)  time: 1.370290  data: 0.000623  max mem: 61695
I20250104 12:53:22 94 dinov2 helpers.py:102] Training  [    210/2500000]  eta: 51 days, 15:03:26  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5393 (inf)  dino_local_crops_loss: 5.6391 (5.4098)  dino_global_crops_loss: 0.7036 (0.6757)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1627 (1.3259)  time: 1.358275  data: 0.000635  max mem: 61695
I20250104 12:53:35 94 dinov2 helpers.py:102] Training  [    220/2500000]  eta: 50 days, 23:17:04  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5331 (inf)  dino_local_crops_loss: 5.6407 (5.4203)  dino_global_crops_loss: 0.7037 (0.6770)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.1576 (1.3182)  time: 1.291621  data: 0.000491  max mem: 61695
I20250104 12:53:48 94 dinov2 helpers.py:102] Training  [    230/2500000]  eta: 50 days, 10:27:54  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5298 (inf)  dino_local_crops_loss: 5.6422 (5.4300)  dino_global_crops_loss: 0.7039 (0.6782)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1513 (1.3108)  time: 1.308968  data: 0.000387  max mem: 61695
I20250104 12:54:02 94 dinov2 helpers.py:102] Training  [    240/2500000]  eta: 50 days, 1:46:39  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5221 (inf)  dino_local_crops_loss: 5.6430 (5.4388)  dino_global_crops_loss: 0.7040 (0.6792)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1437 (1.3037)  time: 1.388628  data: 0.000440  max mem: 61695
I20250104 12:54:15 94 dinov2 helpers.py:102] Training  [    250/2500000]  eta: 49 days, 13:26:25  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5153 (inf)  dino_local_crops_loss: 5.6420 (5.4468)  dino_global_crops_loss: 0.7037 (0.6802)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.1360 (1.2970)  time: 1.363408  data: 0.000345  max mem: 61695
I20250104 12:54:28 94 dinov2 helpers.py:102] Training  [    260/2500000]  eta: 49 days, 2:13:52  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5027 (inf)  dino_local_crops_loss: 5.6365 (5.4539)  dino_global_crops_loss: 0.7031 (0.6811)  koleo_loss: 0.0309 (inf)  ibot_loss: 1.1340 (1.2907)  time: 1.288379  data: 0.000341  max mem: 61695
I20250104 12:54:41 94 dinov2 helpers.py:102] Training  [    270/2500000]  eta: 48 days, 16:20:04  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.4861 (inf)  dino_local_crops_loss: 5.6252 (5.4599)  dino_global_crops_loss: 0.7022 (0.6818)  koleo_loss: 0.0309 (inf)  ibot_loss: 1.1288 (1.2846)  time: 1.301291  data: 0.000611  max mem: 61695
I20250104 12:54:56 94 dinov2 helpers.py:102] Training  [    280/2500000]  eta: 48 days, 10:10:18  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.4649 (inf)  dino_local_crops_loss: 5.6021 (5.4644)  dino_global_crops_loss: 0.7001 (0.6824)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1250 (1.2789)  time: 1.372066  data: 0.000577  max mem: 61695
I20250104 12:55:09 94 dinov2 helpers.py:102] Training  [    290/2500000]  eta: 48 days, 2:09:46  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.4324 (inf)  dino_local_crops_loss: 5.5600 (5.4665)  dino_global_crops_loss: 0.6959 (0.6828)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1226 (1.2735)  time: 1.385822  data: 0.000391  max mem: 61695
I20250104 12:55:23 94 dinov2 helpers.py:102] Training  [    300/2500000]  eta: 47 days, 20:58:51  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.3170 (inf)  dino_local_crops_loss: 5.4743 (5.4644)  dino_global_crops_loss: 0.6866 (0.6826)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1174 (1.2683)  time: 1.388010  data: 0.000382  max mem: 61695
I20250104 12:55:37 94 dinov2 helpers.py:102] Training  [    310/2500000]  eta: 47 days, 14:21:22  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.1142 (inf)  dino_local_crops_loss: 5.2990 (5.4551)  dino_global_crops_loss: 0.6672 (0.6817)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.1166 (1.2634)  time: 1.397984  data: 0.000461  max mem: 61695
I20250104 12:55:52 94 dinov2 helpers.py:102] Training  [    320/2500000]  eta: 47 days, 11:12:31  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 6.8622 (inf)  dino_local_crops_loss: 4.9936 (5.4367)  dino_global_crops_loss: 0.6334 (0.6797)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.1125 (1.2587)  time: 1.429059  data: 0.000603  max mem: 61695
I20250104 12:56:06 94 dinov2 helpers.py:102] Training  [    330/2500000]  eta: 47 days, 5:51:38  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 6.5121 (inf)  dino_local_crops_loss: 4.7092 (5.4125)  dino_global_crops_loss: 0.6015 (0.6771)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1126 (1.2543)  time: 1.442921  data: 0.000537  max mem: 61695
I20250104 12:56:20 94 dinov2 helpers.py:102] Training  [    340/2500000]  eta: 47 days, 0:30:04  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 6.3390 (inf)  dino_local_crops_loss: 4.6126 (5.3885)  dino_global_crops_loss: 0.5894 (0.6745)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.1121 (1.2501)  time: 1.377973  data: 0.000427  max mem: 61695
I20250104 12:56:33 94 dinov2 helpers.py:102] Training  [    350/2500000]  eta: 46 days, 18:43:28  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 6.3727 (inf)  dino_local_crops_loss: 4.6399 (5.3706)  dino_global_crops_loss: 0.5936 (0.6726)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.1100 (1.2461)  time: 1.351733  data: 0.000374  max mem: 61695
I20250104 12:56:49 94 dinov2 helpers.py:102] Training  [    360/2500000]  eta: 46 days, 18:21:47  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 6.7405 (inf)  dino_local_crops_loss: 4.8965 (5.3631)  dino_global_crops_loss: 0.6216 (0.6718)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.1080 (1.2422)  time: 1.465934  data: 0.000350  max mem: 61695
I20250104 12:57:03 94 dinov2 helpers.py:102] Training  [    370/2500000]  eta: 46 days, 14:24:39  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.0848 (inf)  dino_local_crops_loss: 5.2576 (5.3636)  dino_global_crops_loss: 0.6618 (0.6719)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.1076 (1.2386)  time: 1.501950  data: 0.000354  max mem: 61695
I20250104 12:57:17 94 dinov2 helpers.py:102] Training  [    380/2500000]  eta: 46 days, 9:42:24  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2864 (inf)  dino_local_crops_loss: 5.4641 (5.3680)  dino_global_crops_loss: 0.6833 (0.6724)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1061 (1.2351)  time: 1.379179  data: 0.000313  max mem: 61695
I20250104 12:57:30 94 dinov2 helpers.py:102] Training  [    390/2500000]  eta: 46 days, 5:32:20  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.4062 (inf)  dino_local_crops_loss: 5.5733 (5.3742)  dino_global_crops_loss: 0.6946 (0.6730)  koleo_loss: 0.0309 (inf)  ibot_loss: 1.1051 (1.2317)  time: 1.361199  data: 0.000373  max mem: 61695
I20250104 12:57:46 94 dinov2 helpers.py:102] Training  [    400/2500000]  eta: 46 days, 4:59:07  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.4665 (inf)  dino_local_crops_loss: 5.6324 (5.3811)  dino_global_crops_loss: 0.6999 (0.6737)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1020 (1.2285)  time: 1.467906  data: 0.000521  max mem: 61695
I20250104 12:57:59 94 dinov2 helpers.py:102] Training  [    410/2500000]  eta: 46 days, 0:49:15  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5009 (inf)  dino_local_crops_loss: 5.6674 (5.3883)  dino_global_crops_loss: 0.7031 (0.6745)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1007 (1.2254)  time: 1.458610  data: 0.000538  max mem: 61695
I20250104 12:58:13 94 dinov2 helpers.py:102] Training  [    420/2500000]  eta: 45 days, 21:11:01  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5292 (inf)  dino_local_crops_loss: 5.6870 (5.3957)  dino_global_crops_loss: 0.7047 (0.6752)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1004 (1.2224)  time: 1.360939  data: 0.000421  max mem: 61695
I20250104 12:58:27 94 dinov2 helpers.py:102] Training  [    430/2500000]  eta: 45 days, 17:21:19  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5416 (inf)  dino_local_crops_loss: 5.7028 (5.4030)  dino_global_crops_loss: 0.7052 (0.6759)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1018 (1.2196)  time: 1.359766  data: 0.000291  max mem: 61695
I20250104 12:58:41 94 dinov2 helpers.py:102] Training  [    440/2500000]  eta: 45 days, 15:29:42  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5547 (inf)  dino_local_crops_loss: 5.7180 (5.4103)  dino_global_crops_loss: 0.7057 (0.6766)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.1002 (1.2169)  time: 1.405591  data: 0.000410  max mem: 61695
I20250104 12:58:55 94 dinov2 helpers.py:102] Training  [    450/2500000]  eta: 45 days, 12:20:09  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5643 (inf)  dino_local_crops_loss: 5.7273 (5.4173)  dino_global_crops_loss: 0.7063 (0.6773)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0980 (1.2143)  time: 1.417724  data: 0.000554  max mem: 61695
I20250104 12:59:08 94 dinov2 helpers.py:102] Training  [    460/2500000]  eta: 45 days, 8:53:55  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5691 (inf)  dino_local_crops_loss: 5.7319 (5.4242)  dino_global_crops_loss: 0.7062 (0.6779)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0979 (1.2118)  time: 1.359093  data: 0.001082  max mem: 61695
I20250104 12:59:22 94 dinov2 helpers.py:102] Training  [    470/2500000]  eta: 45 days, 6:19:03  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5736 (inf)  dino_local_crops_loss: 5.7357 (5.4309)  dino_global_crops_loss: 0.7061 (0.6785)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0977 (1.2093)  time: 1.369415  data: 0.000967  max mem: 61695
I20250104 12:59:37 94 dinov2 helpers.py:102] Training  [    480/2500000]  eta: 45 days, 5:27:52  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5745 (inf)  dino_local_crops_loss: 5.7409 (5.4374)  dino_global_crops_loss: 0.7059 (0.6791)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0953 (1.2070)  time: 1.449656  data: 0.000366  max mem: 61695
I20250104 12:59:51 94 dinov2 helpers.py:102] Training  [    490/2500000]  eta: 45 days, 2:13:55  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5751 (inf)  dino_local_crops_loss: 5.7419 (5.4436)  dino_global_crops_loss: 0.7056 (0.6796)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0954 (1.2047)  time: 1.420438  data: 0.000422  max mem: 61695
I20250104 13:00:04 94 dinov2 helpers.py:102] Training  [    500/2500000]  eta: 44 days, 23:26:13  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5734 (inf)  dino_local_crops_loss: 5.7399 (5.4496)  dino_global_crops_loss: 0.7050 (0.6801)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0958 (1.2025)  time: 1.346214  data: 0.000596  max mem: 61695
I20250104 13:00:18 94 dinov2 helpers.py:102] Training  [    510/2500000]  eta: 44 days, 20:33:20  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5729 (inf)  dino_local_crops_loss: 5.7394 (5.4552)  dino_global_crops_loss: 0.7046 (0.6806)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0958 (1.2005)  time: 1.350154  data: 0.000654  max mem: 61695
I20250104 13:00:33 94 dinov2 helpers.py:102] Training  [    520/2500000]  eta: 44 days, 19:47:23  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5719 (inf)  dino_local_crops_loss: 5.7385 (5.4607)  dino_global_crops_loss: 0.7043 (0.6810)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0958 (1.1984)  time: 1.418183  data: 0.000471  max mem: 61695
I20250104 13:00:46 94 dinov2 helpers.py:102] Training  [    530/2500000]  eta: 44 days, 17:07:30  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5719 (inf)  dino_local_crops_loss: 5.7389 (5.4659)  dino_global_crops_loss: 0.7038 (0.6815)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0951 (1.1965)  time: 1.419700  data: 0.000430  max mem: 61695
I20250104 13:01:00 94 dinov2 helpers.py:102] Training  [    540/2500000]  eta: 44 days, 14:59:01  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5701 (inf)  dino_local_crops_loss: 5.7389 (5.4710)  dino_global_crops_loss: 0.7032 (0.6819)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0952 (1.1947)  time: 1.362542  data: 0.000463  max mem: 61695
I20250104 13:01:14 94 dinov2 helpers.py:102] Training  [    550/2500000]  eta: 44 days, 12:47:49  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5683 (inf)  dino_local_crops_loss: 5.7359 (5.4758)  dino_global_crops_loss: 0.7031 (0.6823)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0985 (1.1929)  time: 1.374224  data: 0.000409  max mem: 61695
I20250104 13:01:28 94 dinov2 helpers.py:102] Training  [    560/2500000]  eta: 44 days, 11:35:27  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5683 (inf)  dino_local_crops_loss: 5.7363 (5.4805)  dino_global_crops_loss: 0.7030 (0.6826)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0991 (1.1912)  time: 1.405827  data: 0.000481  max mem: 61695
I20250104 13:01:42 94 dinov2 helpers.py:102] Training  [    570/2500000]  eta: 44 days, 9:42:07  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5672 (inf)  dino_local_crops_loss: 5.7373 (5.4850)  dino_global_crops_loss: 0.7029 (0.6830)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0951 (1.1895)  time: 1.412484  data: 0.000444  max mem: 61695
I20250104 13:01:55 94 dinov2 helpers.py:102] Training  [    580/2500000]  eta: 44 days, 7:34:35  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5636 (inf)  dino_local_crops_loss: 5.7367 (5.4893)  dino_global_crops_loss: 0.7029 (0.6833)  koleo_loss: 0.0309 (inf)  ibot_loss: 1.0931 (1.1878)  time: 1.370066  data: 0.000408  max mem: 61695
I20250104 13:02:09 94 dinov2 helpers.py:102] Training  [    590/2500000]  eta: 44 days, 5:07:39  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5652 (inf)  dino_local_crops_loss: 5.7345 (5.4935)  dino_global_crops_loss: 0.7029 (0.6837)  koleo_loss: 0.0309 (inf)  ibot_loss: 1.0947 (1.1863)  time: 1.340628  data: 0.000399  max mem: 61695
I20250104 13:02:24 94 dinov2 helpers.py:102] Training  [    600/2500000]  eta: 44 days, 5:17:50  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5674 (inf)  dino_local_crops_loss: 5.7371 (5.4976)  dino_global_crops_loss: 0.7029 (0.6840)  koleo_loss: 0.0309 (inf)  ibot_loss: 1.0947 (1.1847)  time: 1.433622  data: 0.000262  max mem: 61695
I20250104 13:02:38 94 dinov2 helpers.py:102] Training  [    610/2500000]  eta: 44 days, 4:09:24  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5659 (inf)  dino_local_crops_loss: 5.7378 (5.5015)  dino_global_crops_loss: 0.7025 (0.6843)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0930 (1.1833)  time: 1.486038  data: 0.000407  max mem: 61695
I20250104 13:02:51 94 dinov2 helpers.py:102] Training  [    620/2500000]  eta: 44 days, 1:30:08  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5646 (inf)  dino_local_crops_loss: 5.7358 (5.5052)  dino_global_crops_loss: 0.7024 (0.6846)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0962 (1.1819)  time: 1.359293  data: 0.000652  max mem: 61695
I20250104 13:03:05 94 dinov2 helpers.py:102] Training  [    630/2500000]  eta: 43 days, 23:22:58  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5634 (inf)  dino_local_crops_loss: 5.7358 (5.5089)  dino_global_crops_loss: 0.7022 (0.6848)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0958 (1.1805)  time: 1.310442  data: 0.000549  max mem: 61695
I20250104 13:03:19 94 dinov2 helpers.py:102] Training  [    640/2500000]  eta: 43 days, 22:23:51  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5639 (inf)  dino_local_crops_loss: 5.7382 (5.5125)  dino_global_crops_loss: 0.7024 (0.6851)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0937 (1.1791)  time: 1.380242  data: 0.000412  max mem: 61695
I20250104 13:03:33 94 dinov2 helpers.py:102] Training  [    650/2500000]  eta: 43 days, 20:50:08  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5663 (inf)  dino_local_crops_loss: 5.7372 (5.5159)  dino_global_crops_loss: 0.7029 (0.6854)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0953 (1.1778)  time: 1.401104  data: 0.000480  max mem: 61695
I20250104 13:03:47 94 dinov2 helpers.py:102] Training  [    660/2500000]  eta: 43 days, 20:00:51  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5663 (inf)  dino_local_crops_loss: 5.7385 (5.5193)  dino_global_crops_loss: 0.7029 (0.6857)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0932 (1.1766)  time: 1.405665  data: 0.000404  max mem: 61695
I20250104 13:04:01 94 dinov2 helpers.py:102] Training  [    670/2500000]  eta: 43 days, 18:40:28  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5632 (inf)  dino_local_crops_loss: 5.7375 (5.5225)  dino_global_crops_loss: 0.7024 (0.6859)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0916 (1.1753)  time: 1.412450  data: 0.000301  max mem: 61695
I20250104 13:04:16 94 dinov2 helpers.py:102] Training  [    680/2500000]  eta: 43 days, 18:16:07  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5637 (inf)  dino_local_crops_loss: 5.7382 (5.5257)  dino_global_crops_loss: 0.7023 (0.6861)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0919 (1.1741)  time: 1.430101  data: 0.000415  max mem: 61695
I20250104 13:04:29 94 dinov2 helpers.py:102] Training  [    690/2500000]  eta: 43 days, 16:08:13  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5647 (inf)  dino_local_crops_loss: 5.7378 (5.5287)  dino_global_crops_loss: 0.7024 (0.6864)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0948 (1.1730)  time: 1.387516  data: 0.000589  max mem: 61695
I20250104 13:04:42 94 dinov2 helpers.py:102] Training  [    700/2500000]  eta: 43 days, 14:03:57  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5667 (inf)  dino_local_crops_loss: 5.7381 (5.5318)  dino_global_crops_loss: 0.7026 (0.6866)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0938 (1.1718)  time: 1.301049  data: 0.000489  max mem: 61695
I20250104 13:04:54 94 dinov2 helpers.py:102] Training  [    710/2500000]  eta: 43 days, 11:42:09  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5656 (inf)  dino_local_crops_loss: 5.7395 (5.5347)  dino_global_crops_loss: 0.7025 (0.6868)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0928 (1.1707)  time: 1.283102  data: 0.000364  max mem: 61695
I20250104 13:05:09 94 dinov2 helpers.py:102] Training  [    720/2500000]  eta: 43 days, 11:37:33  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5656 (inf)  dino_local_crops_loss: 5.7398 (5.5375)  dino_global_crops_loss: 0.7026 (0.6871)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0914 (1.1696)  time: 1.380490  data: 0.000303  max mem: 61695
I20250104 13:05:22 94 dinov2 helpers.py:102] Training  [    730/2500000]  eta: 43 days, 9:42:23  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5662 (inf)  dino_local_crops_loss: 5.7400 (5.5403)  dino_global_crops_loss: 0.7030 (0.6873)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0917 (1.1686)  time: 1.398708  data: 0.000343  max mem: 61695
I20250104 13:05:35 94 dinov2 helpers.py:102] Training  [    740/2500000]  eta: 43 days, 7:46:40  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5662 (inf)  dino_local_crops_loss: 5.7371 (5.5429)  dino_global_crops_loss: 0.7030 (0.6875)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0957 (1.1676)  time: 1.298331  data: 0.000441  max mem: 61695
I20250104 13:05:48 94 dinov2 helpers.py:102] Training  [    750/2500000]  eta: 43 days, 5:55:24  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5668 (inf)  dino_local_crops_loss: 5.7364 (5.5456)  dino_global_crops_loss: 0.7026 (0.6877)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0969 (1.1666)  time: 1.296319  data: 0.000481  max mem: 61695
I20250104 13:06:02 94 dinov2 helpers.py:102] Training  [    760/2500000]  eta: 43 days, 4:48:18  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5684 (inf)  dino_local_crops_loss: 5.7383 (5.5481)  dino_global_crops_loss: 0.7029 (0.6879)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0953 (1.1657)  time: 1.335251  data: 0.000481  max mem: 61695
I20250104 13:06:15 94 dinov2 helpers.py:102] Training  [    770/2500000]  eta: 43 days, 3:05:49  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5698 (inf)  dino_local_crops_loss: 5.7424 (5.5507)  dino_global_crops_loss: 0.7032 (0.6881)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0937 (1.1648)  time: 1.338579  data: 0.000446  max mem: 61695
I20250104 13:06:28 94 dinov2 helpers.py:102] Training  [    780/2500000]  eta: 43 days, 1:13:01  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5708 (inf)  dino_local_crops_loss: 5.7428 (5.5531)  dino_global_crops_loss: 0.7034 (0.6883)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0936 (1.1638)  time: 1.292085  data: 0.000525  max mem: 61695
I20250104 13:06:41 94 dinov2 helpers.py:102] Training  [    790/2500000]  eta: 42 days, 23:40:56  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5731 (inf)  dino_local_crops_loss: 5.7428 (5.5555)  dino_global_crops_loss: 0.7030 (0.6885)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0950 (1.1630)  time: 1.296926  data: 0.000425  max mem: 61695
I20250104 13:06:55 94 dinov2 helpers.py:102] Training  [    800/2500000]  eta: 42 days, 22:34:04  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5725 (inf)  dino_local_crops_loss: 5.7428 (5.5579)  dino_global_crops_loss: 0.7033 (0.6887)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0942 (1.1621)  time: 1.335945  data: 0.000300  max mem: 61695
I20250104 13:07:08 94 dinov2 helpers.py:102] Training  [    810/2500000]  eta: 42 days, 21:22:25  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5705 (inf)  dino_local_crops_loss: 5.7423 (5.5601)  dino_global_crops_loss: 0.7032 (0.6888)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0930 (1.1612)  time: 1.351731  data: 0.000423  max mem: 61695
I20250104 13:07:23 94 dinov2 helpers.py:102] Training  [    820/2500000]  eta: 42 days, 21:17:08  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5692 (inf)  dino_local_crops_loss: 5.7414 (5.5624)  dino_global_crops_loss: 0.7027 (0.6890)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0911 (1.1604)  time: 1.409160  data: 0.000551  max mem: 61695
I20250104 13:07:37 94 dinov2 helpers.py:102] Training  [    830/2500000]  eta: 42 days, 20:40:56  lr: 0.0004 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5699 (inf)  dino_local_crops_loss: 5.7418 (5.5645)  dino_global_crops_loss: 0.7033 (0.6892)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0943 (1.1596)  time: 1.441895  data: 0.000525  max mem: 61695
I20250104 13:07:51 94 dinov2 helpers.py:102] Training  [    840/2500000]  eta: 42 days, 20:02:46  lr: 0.0005 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5704 (inf)  dino_local_crops_loss: 5.7418 (5.5666)  dino_global_crops_loss: 0.7033 (0.6894)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0941 (1.1588)  time: 1.408083  data: 0.000458  max mem: 61695
I20250104 13:08:08 94 dinov2 helpers.py:102] Training  [    850/2500000]  eta: 42 days, 21:44:42  lr: 0.0005 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5714 (inf)  dino_local_crops_loss: 5.7425 (5.5687)  dino_global_crops_loss: 0.7031 (0.6895)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0938 (1.1580)  time: 1.547443  data: 0.095622  max mem: 61695
I20250104 13:08:20 94 dinov2 helpers.py:102] Training  [    860/2500000]  eta: 42 days, 20:00:16  lr: 0.0005 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5714 (inf)  dino_local_crops_loss: 5.7434 (5.5708)  dino_global_crops_loss: 0.7037 (0.6897)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0934 (1.1573)  time: 1.478809  data: 0.095672  max mem: 61695
I20250104 13:08:34 94 dinov2 helpers.py:102] Training  [    870/2500000]  eta: 42 days, 18:40:58  lr: 0.0005 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5712 (inf)  dino_local_crops_loss: 5.7438 (5.5728)  dino_global_crops_loss: 0.7037 (0.6898)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0923 (1.1565)  time: 1.291741  data: 0.000438  max mem: 61695
I20250104 13:08:47 94 dinov2 helpers.py:102] Training  [    880/2500000]  eta: 42 days, 17:13:17  lr: 0.0005 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5731 (inf)  dino_local_crops_loss: 5.7442 (5.5747)  dino_global_crops_loss: 0.7035 (0.6900)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0939 (1.1559)  time: 1.304755  data: 0.000336  max mem: 61695
I20250104 13:09:00 94 dinov2 helpers.py:102] Training  [    890/2500000]  eta: 42 days, 15:55:20  lr: 0.0005 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5756 (inf)  dino_local_crops_loss: 5.7448 (5.5766)  dino_global_crops_loss: 0.7038 (0.6901)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0926 (1.1551)  time: 1.302317  data: 0.000364  max mem: 61695
I20250104 13:09:13 94 dinov2 helpers.py:102] Training  [    900/2500000]  eta: 42 days, 15:02:58  lr: 0.0005 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5746 (inf)  dino_local_crops_loss: 5.7448 (5.5785)  dino_global_crops_loss: 0.7036 (0.6903)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0925 (1.1544)  time: 1.336423  data: 0.000371  max mem: 61695
I20250104 13:09:26 94 dinov2 helpers.py:102] Training  [    910/2500000]  eta: 42 days, 13:34:27  lr: 0.0005 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5730 (inf)  dino_local_crops_loss: 5.7450 (5.5804)  dino_global_crops_loss: 0.7035 (0.6904)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0910 (1.1537)  time: 1.321434  data: 0.000484  max mem: 61695
I20250104 13:09:39 94 dinov2 helpers.py:102] Training  [    920/2500000]  eta: 42 days, 12:06:05  lr: 0.0005 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5729 (inf)  dino_local_crops_loss: 5.7445 (5.5821)  dino_global_crops_loss: 0.7036 (0.6906)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0909 (1.1531)  time: 1.278715  data: 0.000504  max mem: 61695
I20250104 13:09:52 94 dinov2 helpers.py:102] Training  [    930/2500000]  eta: 42 days, 10:56:11  lr: 0.0005 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5764 (inf)  dino_local_crops_loss: 5.7454 (5.5839)  dino_global_crops_loss: 0.7036 (0.6907)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0952 (1.1525)  time: 1.295273  data: 0.000416  max mem: 61695
I20250104 13:10:06 94 dinov2 helpers.py:102] Training  [    940/2500000]  eta: 42 days, 10:19:29  lr: 0.0005 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5762 (inf)  dino_local_crops_loss: 5.7478 (5.5856)  dino_global_crops_loss: 0.7034 (0.6909)  koleo_loss: 0.0309 (inf)  ibot_loss: 1.0939 (1.1518)  time: 1.349618  data: 0.000323  max mem: 61695
I20250104 13:10:19 94 dinov2 helpers.py:102] Training  [    950/2500000]  eta: 42 days, 9:05:51  lr: 0.0005 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5762 (inf)  dino_local_crops_loss: 5.7475 (5.5873)  dino_global_crops_loss: 0.7034 (0.6910)  koleo_loss: 0.0309 (inf)  ibot_loss: 1.0941 (1.1512)  time: 1.342411  data: 0.000400  max mem: 61695
I20250104 13:10:32 94 dinov2 helpers.py:102] Training  [    960/2500000]  eta: 42 days, 7:44:23  lr: 0.0005 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5762 (inf)  dino_local_crops_loss: 5.7474 (5.5890)  dino_global_crops_loss: 0.7036 (0.6911)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0939 (1.1506)  time: 1.288581  data: 0.000516  max mem: 61695
I20250104 13:10:45 94 dinov2 helpers.py:102] Training  [    970/2500000]  eta: 42 days, 6:41:43  lr: 0.0005 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5762 (inf)  dino_local_crops_loss: 5.7470 (5.5906)  dino_global_crops_loss: 0.7038 (0.6913)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0945 (1.1501)  time: 1.297737  data: 0.000520  max mem: 61695
I20250104 13:10:58 94 dinov2 helpers.py:102] Training  [    980/2500000]  eta: 42 days, 5:57:53  lr: 0.0005 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5782 (inf)  dino_local_crops_loss: 5.7461 (5.5923)  dino_global_crops_loss: 0.7041 (0.6914)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0945 (1.1495)  time: 1.338370  data: 0.000419  max mem: 61695
I20250104 13:11:12 94 dinov2 helpers.py:102] Training  [    990/2500000]  eta: 42 days, 4:56:04  lr: 0.0005 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5779 (inf)  dino_local_crops_loss: 5.7481 (5.5938)  dino_global_crops_loss: 0.7042 (0.6915)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0945 (1.1490)  time: 1.336608  data: 0.000385  max mem: 61695
I20250104 13:11:24 94 dinov2 helpers.py:102] Training  [   1000/2500000]  eta: 42 days, 3:33:20  lr: 0.0005 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5766 (inf)  dino_local_crops_loss: 5.7473 (5.5954)  dino_global_crops_loss: 0.7038 (0.6916)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0957 (1.1484)  time: 1.287570  data: 0.000486  max mem: 61695
I20250104 13:11:37 94 dinov2 helpers.py:102] Training  [   1010/2500000]  eta: 42 days, 2:40:48  lr: 0.0005 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5780 (inf)  dino_local_crops_loss: 5.7467 (5.5969)  dino_global_crops_loss: 0.7037 (0.6918)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0957 (1.1479)  time: 1.295633  data: 0.000443  max mem: 61695
I20250104 13:11:52 94 dinov2 helpers.py:102] Training  [   1020/2500000]  eta: 42 days, 2:27:57  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5787 (inf)  dino_local_crops_loss: 5.7483 (5.5984)  dino_global_crops_loss: 0.7036 (0.6919)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0944 (1.1474)  time: 1.377682  data: 0.000479  max mem: 61695
I20250104 13:12:05 94 dinov2 helpers.py:102] Training  [   1030/2500000]  eta: 42 days, 1:26:41  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5781 (inf)  dino_local_crops_loss: 5.7499 (5.5998)  dino_global_crops_loss: 0.7038 (0.6920)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0938 (1.1468)  time: 1.364829  data: 0.000402  max mem: 61695
I20250104 13:12:18 94 dinov2 helpers.py:102] Training  [   1040/2500000]  eta: 42 days, 0:26:34  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5763 (inf)  dino_local_crops_loss: 5.7491 (5.6012)  dino_global_crops_loss: 0.7039 (0.6921)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0946 (1.1463)  time: 1.304570  data: 0.000421  max mem: 61695
I20250104 13:12:31 94 dinov2 helpers.py:102] Training  [   1050/2500000]  eta: 41 days, 23:25:48  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5766 (inf)  dino_local_crops_loss: 5.7478 (5.6026)  dino_global_crops_loss: 0.7040 (0.6922)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0940 (1.1458)  time: 1.302288  data: 0.000518  max mem: 61695
I20250104 13:12:45 94 dinov2 helpers.py:102] Training  [   1060/2500000]  eta: 41 days, 23:17:30  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5783 (inf)  dino_local_crops_loss: 5.7473 (5.6040)  dino_global_crops_loss: 0.7041 (0.6923)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0934 (1.1453)  time: 1.365414  data: 0.000447  max mem: 61695
I20250104 13:12:58 94 dinov2 helpers.py:102] Training  [   1070/2500000]  eta: 41 days, 22:33:26  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5784 (inf)  dino_local_crops_loss: 5.7473 (5.6054)  dino_global_crops_loss: 0.7037 (0.6924)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0934 (1.1449)  time: 1.384610  data: 0.000448  max mem: 61695
I20250104 13:13:12 94 dinov2 helpers.py:102] Training  [   1080/2500000]  eta: 41 days, 21:38:44  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5780 (inf)  dino_local_crops_loss: 5.7469 (5.6067)  dino_global_crops_loss: 0.7036 (0.6925)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0959 (1.1444)  time: 1.323554  data: 0.000512  max mem: 61695
I20250104 13:13:24 94 dinov2 helpers.py:102] Training  [   1090/2500000]  eta: 41 days, 20:37:18  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5823 (inf)  dino_local_crops_loss: 5.7478 (5.6080)  dino_global_crops_loss: 0.7041 (0.6927)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0978 (1.1440)  time: 1.298593  data: 0.000519  max mem: 61695
I20250104 13:13:39 94 dinov2 helpers.py:102] Training  [   1100/2500000]  eta: 41 days, 20:31:16  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5817 (inf)  dino_local_crops_loss: 5.7492 (5.6093)  dino_global_crops_loss: 0.7044 (0.6928)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0946 (1.1435)  time: 1.360233  data: 0.000446  max mem: 61695
I20250104 13:13:52 94 dinov2 helpers.py:102] Training  [   1110/2500000]  eta: 41 days, 19:47:12  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5792 (inf)  dino_local_crops_loss: 5.7481 (5.6105)  dino_global_crops_loss: 0.7041 (0.6929)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0942 (1.1431)  time: 1.381103  data: 0.000457  max mem: 61695
I20250104 13:14:06 94 dinov2 helpers.py:102] Training  [   1120/2500000]  eta: 41 days, 19:20:27  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5821 (inf)  dino_local_crops_loss: 5.7507 (5.6118)  dino_global_crops_loss: 0.7042 (0.6930)  koleo_loss: 0.0312 (inf)  ibot_loss: 1.0946 (1.1427)  time: 1.352478  data: 0.000462  max mem: 61695
I20250104 13:14:21 94 dinov2 helpers.py:102] Training  [   1130/2500000]  eta: 41 days, 19:37:55  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5810 (inf)  dino_local_crops_loss: 5.7516 (5.6130)  dino_global_crops_loss: 0.7042 (0.6931)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0948 (1.1423)  time: 1.434141  data: 0.000410  max mem: 61695
I20250104 13:14:36 94 dinov2 helpers.py:102] Training  [   1140/2500000]  eta: 41 days, 19:50:41  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5808 (inf)  dino_local_crops_loss: 5.7505 (5.6142)  dino_global_crops_loss: 0.7041 (0.6932)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0949 (1.1419)  time: 1.487535  data: 0.000417  max mem: 61695
I20250104 13:14:49 94 dinov2 helpers.py:102] Training  [   1150/2500000]  eta: 41 days, 19:04:47  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5793 (inf)  dino_local_crops_loss: 5.7487 (5.6154)  dino_global_crops_loss: 0.7037 (0.6932)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0950 (1.1415)  time: 1.400764  data: 0.000399  max mem: 61695
I20250104 13:15:02 94 dinov2 helpers.py:102] Training  [   1160/2500000]  eta: 41 days, 18:25:58  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5793 (inf)  dino_local_crops_loss: 5.7493 (5.6165)  dino_global_crops_loss: 0.7042 (0.6933)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0950 (1.1411)  time: 1.328790  data: 0.000361  max mem: 61695
I20250104 13:15:15 94 dinov2 helpers.py:102] Training  [   1170/2500000]  eta: 41 days, 17:44:29  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5816 (inf)  dino_local_crops_loss: 5.7507 (5.6177)  dino_global_crops_loss: 0.7044 (0.6934)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0934 (1.1407)  time: 1.332885  data: 0.000414  max mem: 61695
I20250104 13:15:31 94 dinov2 helpers.py:102] Training  [   1180/2500000]  eta: 41 days, 18:22:24  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5828 (inf)  dino_local_crops_loss: 5.7518 (5.6188)  dino_global_crops_loss: 0.7044 (0.6935)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0929 (1.1403)  time: 1.439792  data: 0.000525  max mem: 61695
I20250104 13:15:44 94 dinov2 helpers.py:102] Training  [   1190/2500000]  eta: 41 days, 17:35:10  lr: 0.0006 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5807 (inf)  dino_local_crops_loss: 5.7498 (5.6199)  dino_global_crops_loss: 0.7039 (0.6936)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0959 (1.1399)  time: 1.430544  data: 0.000454  max mem: 61695
I20250104 13:15:58 94 dinov2 helpers.py:102] Training  [   1200/2500000]  eta: 41 days, 17:03:38  lr: 0.0007 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5814 (inf)  dino_local_crops_loss: 5.7500 (5.6210)  dino_global_crops_loss: 0.7040 (0.6937)  koleo_loss: 0.0309 (inf)  ibot_loss: 1.0953 (1.1395)  time: 1.331235  data: 0.000449  max mem: 61695
I20250104 13:16:11 94 dinov2 helpers.py:102] Training  [   1210/2500000]  eta: 41 days, 16:22:31  lr: 0.0007 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5814 (inf)  dino_local_crops_loss: 5.7514 (5.6221)  dino_global_crops_loss: 0.7044 (0.6938)  koleo_loss: 0.0309 (inf)  ibot_loss: 1.0944 (1.1392)  time: 1.338038  data: 0.000633  max mem: 61695
I20250104 13:16:25 94 dinov2 helpers.py:102] Training  [   1220/2500000]  eta: 41 days, 16:17:14  lr: 0.0007 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5803 (inf)  dino_local_crops_loss: 5.7512 (5.6232)  dino_global_crops_loss: 0.7046 (0.6939)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0944 (1.1388)  time: 1.374895  data: 0.000648  max mem: 61695
I20250104 13:16:38 94 dinov2 helpers.py:102] Training  [   1230/2500000]  eta: 41 days, 15:40:46  lr: 0.0007 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5802 (inf)  dino_local_crops_loss: 5.7527 (5.6242)  dino_global_crops_loss: 0.7043 (0.6940)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0924 (1.1384)  time: 1.380257  data: 0.000432  max mem: 61695
I20250104 13:16:52 94 dinov2 helpers.py:102] Training  [   1240/2500000]  eta: 41 days, 15:02:03  lr: 0.0007 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5798 (inf)  dino_local_crops_loss: 5.7523 (5.6252)  dino_global_crops_loss: 0.7042 (0.6940)  koleo_loss: 0.0309 (inf)  ibot_loss: 1.0915 (1.1381)  time: 1.329811  data: 0.000543  max mem: 61695
I20250104 13:17:05 94 dinov2 helpers.py:102] Training  [   1250/2500000]  eta: 41 days, 14:23:05  lr: 0.0007 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5859 (inf)  dino_local_crops_loss: 5.7496 (5.6262)  dino_global_crops_loss: 0.7039 (0.6941)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0972 (1.1378)  time: 1.324300  data: 0.000686  max mem: 61695
I20250104 13:17:19 94 dinov2 helpers.py:102] Training  [   1260/2500000]  eta: 41 days, 14:10:37  lr: 0.0007 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0007 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5860 (inf)  dino_local_crops_loss: 5.7521 (5.6272)  dino_global_crops_loss: 0.7043 (0.6942)  koleo_loss: 0.0311 (inf)  ibot_loss: 1.0972 (1.1375)  time: 1.362181  data: 0.000520  max mem: 61695
I20250104 13:17:32 94 dinov2 helpers.py:102] Training  [   1270/2500000]  eta: 41 days, 13:42:13  lr: 0.0007 (0.0003)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0007 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5849 (inf)  dino_local_crops_loss: 5.7521 (5.6282)  dino_global_crops_loss: 0.7045 (0.6943)  koleo_loss: 0.0310 (inf)  ibot_loss: 1.0953 (1.1371)  time: 1.376764  data: 0.000536  max mem: 61695
I20250104 13:17:37 94 dinov2 train.py:278] NaN detected
I20250104 13:21:37 94 dinov2 config.py:67] git:
  sha: fda283ef182296a3187e17b7c6482658c6b64ee3, status: has uncommitted changes, branch: main

I20250104 13:21:37 94 dinov2 config.py:68] config_file: dinov2/configs/train/patch.yaml
eval: 
eval_only: False
local_rank: 4
no_resume: False
opts: ['train.dataset_path=TileDataset:split=TRAIN:root=/ruiyan/yuhao/data', 'train.output_dir=/ruiyan/yuhao/project/FMBC/dinov2/output']
output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
I20250104 13:21:37 94 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.006928203230275509
I20250104 13:21:37 94 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
dino:
  loss_weight: 1.0
  head_n_prototypes: 384
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 384
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 380
  dataset_path: TileDataset:split=TRAIN:root=/ruiyan/yuhao/data
  output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
  saveckp_freq: 20
  seed: 0
  num_workers: 8
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 2000
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.006928203230275509
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250104 13:21:37 94 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250104 13:21:38 94 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 768
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 384
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20250104 13:21:39 94 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_base network.
I20250104 13:21:40 94 dinov2 ssl_meta_arch.py:396] DISTRIBUTED FSDP -- preparing model for distributed training
I20250104 13:21:40 94 dinov2 train.py:307] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x Identity()
              (3-5): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-8): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-8): 9 x Identity()
              (9-11): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=384, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x Identity()
              (3-5): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-8): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-8): 9 x Identity()
              (9-11): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=384, bias=False)
      )
    )
  )
)
I20250104 13:21:40 94 dinov2 param_groups.py:54] chunked fsdp
I20250104 13:21:40 94 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.05083731656658002, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.05083731656658002, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.3.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.4.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.1.5.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.6.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.7.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.2.8.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.9.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.10.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] blocks.3.11.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250104 13:21:40 94 dinov2 param_groups.py:64] else code branch
I20250104 13:21:40 94 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 13:21:40 94 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250104 13:21:40 94 dinov2 train.py:106] Schedulers ready.
I20250104 13:21:40 94 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250104 13:21:40 94 dinov2 augmentations.py:34] ###################################
I20250104 13:21:40 94 dinov2 augmentations.py:35] Using data augmentation parameters:
I20250104 13:21:40 94 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20250104 13:21:40 94 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20250104 13:21:40 94 dinov2 augmentations.py:38] local_crops_number: 8
I20250104 13:21:40 94 dinov2 augmentations.py:39] global_crops_size: 224
I20250104 13:21:40 94 dinov2 augmentations.py:40] local_crops_size: 96
I20250104 13:21:40 94 dinov2 augmentations.py:41] ###################################
I20250104 13:21:40 94 dinov2 loaders.py:87] using dataset: "TileDataset:split=TRAIN:root=/ruiyan/yuhao/data"
I20250104 13:24:21 94 dinov2 config.py:67] git:
  sha: fda283ef182296a3187e17b7c6482658c6b64ee3, status: has uncommitted changes, branch: main

I20250104 13:24:21 94 dinov2 config.py:68] config_file: dinov2/configs/train/patch.yaml
eval: 
eval_only: False
local_rank: 4
no_resume: False
opts: ['train.dataset_path=TileDataset:split=TRAIN:root=/ruiyan/yuhao/data', 'train.output_dir=/ruiyan/yuhao/project/FMBC/dinov2/output']
output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
I20250104 13:24:21 94 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.006928203230275509
I20250104 13:24:21 94 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
dino:
  loss_weight: 1.0
  head_n_prototypes: 384
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 384
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 380
  dataset_path: TileDataset:split=TRAIN:root=/ruiyan/yuhao/data
  output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
  saveckp_freq: 20
  seed: 0
  num_workers: 8
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 2000
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.006928203230275509
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250104 13:24:21 94 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250104 13:24:22 94 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250104 13:24:23 94 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 768
I20250104 13:24:23 94 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20250104 13:24:23 94 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20250104 13:24:23 94 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 384
I20250104 13:24:23 94 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20250104 13:24:23 94 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20250104 13:24:23 94 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20250104 13:24:24 94 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20250104 13:24:24 94 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20250104 13:24:24 94 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20250104 13:24:24 94 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20250104 13:24:24 94 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20250104 13:24:24 94 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_base network.
I20250104 13:24:24 94 dinov2 ssl_meta_arch.py:396] DISTRIBUTED FSDP -- preparing model for distributed training
I20250104 13:24:24 94 dinov2 train.py:307] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x Identity()
              (3-5): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-8): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-8): 9 x Identity()
              (9-11): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=384, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x Identity()
              (3-5): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-8): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-8): 9 x Identity()
              (9-11): 3 x NestedTensorBlock(
                (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=384, bias=False)
      )
    )
  )
)
I20250104 13:24:24 94 dinov2 param_groups.py:54] chunked fsdp
I20250104 13:24:24 94 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.05083731656658002, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.05083731656658002, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.3.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.4.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.1.5.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.6.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.7.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.2.8.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.9.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.10.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] blocks.3.11.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250104 13:24:24 94 dinov2 param_groups.py:64] else code branch
I20250104 13:24:24 94 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250104 13:24:24 94 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250104 13:24:25 94 dinov2 train.py:106] Schedulers ready.
I20250104 13:24:25 94 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250104 13:24:25 94 dinov2 augmentations.py:34] ###################################
I20250104 13:24:25 94 dinov2 augmentations.py:35] Using data augmentation parameters:
I20250104 13:24:25 94 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20250104 13:24:25 94 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20250104 13:24:25 94 dinov2 augmentations.py:38] local_crops_number: 8
I20250104 13:24:25 94 dinov2 augmentations.py:39] global_crops_size: 224
I20250104 13:24:25 94 dinov2 augmentations.py:40] local_crops_size: 96
I20250104 13:24:25 94 dinov2 augmentations.py:41] ###################################
I20250104 13:24:25 94 dinov2 loaders.py:87] using dataset: "TileDataset:split=TRAIN:root=/ruiyan/yuhao/data"
I20250104 13:33:14 94 dinov2 loaders.py:92] # of dataset samples: 92,020,608
I20250104 13:33:14 94 dinov2 loaders.py:125] sampler: sharded infinite
I20250104 13:33:14 94 dinov2 loaders.py:209] using PyTorch data loader
I20250104 13:33:14 94 dinov2 loaders.py:224] infinite data loader
I20250104 13:33:14 94 dinov2 train.py:221] Starting training from iteration 0
I20250104 13:35:43 94 dinov2 helpers.py:102] Training  [      0/2500000]  eta: 4301 days, 5:04:35  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.4789 (7.4789)  dino_local_crops_loss: 4.6839 (4.6839)  dino_global_crops_loss: 0.5855 (0.5855)  koleo_loss: 0.7135 (0.7135)  ibot_loss: 1.4959 (1.4959)  time: 148.649872  data: 118.585098  max mem: 61574
I20250104 13:35:56 94 dinov2 helpers.py:102] Training  [     10/2500000]  eta: 425 days, 1:12:38  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.8011 (7.7703)  dino_local_crops_loss: 4.9622 (4.9458)  dino_global_crops_loss: 0.6203 (0.6182)  koleo_loss: 0.7116 (0.6996)  ibot_loss: 1.5083 (1.5067)  time: 14.689803  data: 10.780991  max mem: 61695
I20250104 13:36:14 94 dinov2 helpers.py:102] Training  [     20/2500000]  eta: 247 days, 8:04:02  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.9771 (7.8926)  dino_local_crops_loss: 5.1624 (5.1015)  dino_global_crops_loss: 0.6453 (0.6377)  koleo_loss: 0.6413 (0.6430)  ibot_loss: 1.5132 (1.5104)  time: 1.542912  data: 0.135512  max mem: 61695
I20250104 13:36:29 94 dinov2 helpers.py:102] Training  [     30/2500000]  eta: 181 days, 15:01:21  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 8.0052 (7.9154)  dino_local_crops_loss: 5.3185 (5.1734)  dino_global_crops_loss: 0.6648 (0.6467)  koleo_loss: 0.5033 (0.5842)  ibot_loss: 1.5140 (1.5112)  time: 1.650064  data: 0.206499  max mem: 61695
I20250104 13:36:46 94 dinov2 helpers.py:102] Training  [     40/2500000]  eta: 149 days, 8:02:08  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.9152 (7.9065)  dino_local_crops_loss: 5.3200 (5.2076)  dino_global_crops_loss: 0.6650 (0.6509)  koleo_loss: 0.4167 (0.5385)  ibot_loss: 1.5089 (1.5095)  time: 1.604837  data: 0.173467  max mem: 61695
I20250104 13:37:05 94 dinov2 helpers.py:102] Training  [     50/2500000]  eta: 131 days, 1:58:49  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.8197 (7.8883)  dino_local_crops_loss: 5.3065 (5.2262)  dino_global_crops_loss: 0.6633 (0.6533)  koleo_loss: 0.3584 (0.5027)  ibot_loss: 1.4980 (1.5061)  time: 1.822816  data: 0.369579  max mem: 61695
I20250104 13:37:20 94 dinov2 helpers.py:102] Training  [     60/2500000]  eta: 116 days, 16:39:39  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.7903 (7.8656)  dino_local_crops_loss: 5.2987 (5.2378)  dino_global_crops_loss: 0.6624 (0.6547)  koleo_loss: 0.3428 (0.4716)  ibot_loss: 1.4864 (1.5014)  time: 1.720555  data: 0.295501  max mem: 61695
I20250104 13:37:36 94 dinov2 helpers.py:102] Training  [     70/2500000]  eta: 106 days, 11:05:10  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.6966 (7.8348)  dino_local_crops_loss: 5.2965 (5.2462)  dino_global_crops_loss: 0.6622 (0.6558)  koleo_loss: 0.2700 (0.4376)  ibot_loss: 1.4690 (1.4953)  time: 1.509695  data: 0.053780  max mem: 61695
I20250104 13:37:51 94 dinov2 helpers.py:102] Training  [     80/2500000]  eta: 98 days, 16:25:28  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.5911 (7.7985)  dino_local_crops_loss: 5.3002 (5.2539)  dino_global_crops_loss: 0.6632 (0.6570)  koleo_loss: 0.1774 (0.3994)  ibot_loss: 1.4477 (1.4884)  time: 1.512297  data: 0.025959  max mem: 61695
I20250104 13:38:09 94 dinov2 helpers.py:102] Training  [     90/2500000]  eta: 93 days, 14:58:04  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.4859 (7.7612)  dino_local_crops_loss: 5.3063 (5.2594)  dino_global_crops_loss: 0.6646 (0.6577)  koleo_loss: 0.0759 (0.3621)  ibot_loss: 1.4334 (1.4820)  time: 1.660696  data: 0.000488  max mem: 61695
I20250104 13:38:24 94 dinov2 helpers.py:102] Training  [    100/2500000]  eta: 88 days, 19:26:15  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.4343 (7.7273)  dino_local_crops_loss: 5.2952 (5.2625)  dino_global_crops_loss: 0.6624 (0.6581)  koleo_loss: 0.0458 (0.3302)  ibot_loss: 1.4282 (1.4764)  time: 1.687340  data: 0.000506  max mem: 61695
I20250104 13:38:40 94 dinov2 helpers.py:102] Training  [    110/2500000]  eta: 84 days, 21:06:01  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.4052 (7.6973)  dino_local_crops_loss: 5.2875 (5.2648)  dino_global_crops_loss: 0.6614 (0.6584)  koleo_loss: 0.0343 (0.3031)  ibot_loss: 1.4192 (1.4710)  time: 1.558560  data: 0.000571  max mem: 61695
I20250104 13:38:57 94 dinov2 helpers.py:102] Training  [    120/2500000]  eta: 82 days, 0:23:59  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.3851 (7.6709)  dino_local_crops_loss: 5.2874 (5.2667)  dino_global_crops_loss: 0.6613 (0.6587)  koleo_loss: 0.0253 (0.2800)  ibot_loss: 1.4104 (1.4656)  time: 1.649089  data: 0.000543  max mem: 61695
I20250104 13:39:14 94 dinov2 helpers.py:102] Training  [    130/2500000]  eta: 79 days, 12:54:05  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.3761 (7.6481)  dino_local_crops_loss: 5.2895 (5.2686)  dino_global_crops_loss: 0.6615 (0.6589)  koleo_loss: 0.0209 (0.2602)  ibot_loss: 1.4033 (1.4605)  time: 1.724474  data: 0.000499  max mem: 61695
I20250104 13:39:29 94 dinov2 helpers.py:102] Training  [    140/2500000]  eta: 76 days, 23:53:19  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.3677 (7.6278)  dino_local_crops_loss: 5.2926 (5.2704)  dino_global_crops_loss: 0.6620 (0.6591)  koleo_loss: 0.0184 (0.2430)  ibot_loss: 1.3936 (1.4553)  time: 1.611293  data: 0.000436  max mem: 61695
I20250104 13:39:45 94 dinov2 helpers.py:102] Training  [    150/2500000]  eta: 74 days, 19:02:42  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.3556 (7.6094)  dino_local_crops_loss: 5.2953 (5.2721)  dino_global_crops_loss: 0.6625 (0.6594)  koleo_loss: 0.0165 (0.2279)  ibot_loss: 1.3817 (1.4500)  time: 1.511206  data: 0.000499  max mem: 61695
I20250104 13:40:04 94 dinov2 helpers.py:102] Training  [    160/2500000]  eta: 73 days, 16:40:54  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.3410 (7.5923)  dino_local_crops_loss: 5.2971 (5.2737)  dino_global_crops_loss: 0.6630 (0.6596)  koleo_loss: 0.0139 (0.2145)  ibot_loss: 1.3666 (1.4445)  time: 1.743054  data: 0.000502  max mem: 61695
I20250104 13:40:24 94 dinov2 helpers.py:102] Training  [    170/2500000]  eta: 72 days, 15:16:36  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.3300 (7.5766)  dino_local_crops_loss: 5.2982 (5.2751)  dino_global_crops_loss: 0.6633 (0.6598)  koleo_loss: 0.0118 (0.2026)  ibot_loss: 1.3559 (1.4390)  time: 1.947781  data: 0.000425  max mem: 61695
I20250104 13:40:38 94 dinov2 helpers.py:102] Training  [    180/2500000]  eta: 70 days, 22:51:45  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.3163 (7.5615)  dino_local_crops_loss: 5.2987 (5.2765)  dino_global_crops_loss: 0.6634 (0.6600)  koleo_loss: 0.0095 (0.1919)  ibot_loss: 1.3444 (1.4331)  time: 1.689435  data: 0.000464  max mem: 61695
I20250104 13:40:53 94 dinov2 helpers.py:102] Training  [    190/2500000]  eta: 69 days, 10:32:23  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2998 (7.5477)  dino_local_crops_loss: 5.2988 (5.2776)  dino_global_crops_loss: 0.6633 (0.6602)  koleo_loss: 0.0073 (0.1822)  ibot_loss: 1.3285 (1.4277)  time: 1.455313  data: 0.000453  max mem: 61695
I20250104 13:41:09 94 dinov2 helpers.py:102] Training  [    200/2500000]  eta: 68 days, 8:44:28  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2921 (7.5349)  dino_local_crops_loss: 5.2988 (5.2787)  dino_global_crops_loss: 0.6633 (0.6604)  koleo_loss: 0.0054 (0.1734)  ibot_loss: 1.3244 (1.4225)  time: 1.553402  data: 0.000420  max mem: 61695
I20250104 13:41:26 94 dinov2 helpers.py:102] Training  [    210/2500000]  eta: 67 days, 11:27:14  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2824 (7.5226)  dino_local_crops_loss: 5.2986 (5.2796)  dino_global_crops_loss: 0.6632 (0.6605)  koleo_loss: 0.0039 (0.1653)  ibot_loss: 1.3171 (1.4171)  time: 1.684815  data: 0.000382  max mem: 61695
I20250104 13:41:41 94 dinov2 helpers.py:102] Training  [    220/2500000]  eta: 66 days, 7:38:19  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2745 (7.5113)  dino_local_crops_loss: 5.2983 (5.2805)  dino_global_crops_loss: 0.6632 (0.6606)  koleo_loss: 0.0025 (0.1579)  ibot_loss: 1.3099 (1.4123)  time: 1.581677  data: 0.000369  max mem: 61695
I20250104 13:41:56 94 dinov2 helpers.py:102] Training  [    230/2500000]  eta: 65 days, 9:24:59  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2680 (7.5005)  dino_local_crops_loss: 5.2981 (5.2812)  dino_global_crops_loss: 0.6631 (0.6607)  koleo_loss: 0.0003 (0.1510)  ibot_loss: 1.3068 (1.4075)  time: 1.500125  data: 0.000470  max mem: 61695
I20250104 13:42:12 94 dinov2 helpers.py:102] Training  [    240/2500000]  eta: 64 days, 12:24:44  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2555 (7.4903)  dino_local_crops_loss: 5.2979 (5.2819)  dino_global_crops_loss: 0.6631 (0.6608)  koleo_loss: -0.0014 (0.1447)  ibot_loss: 1.2973 (1.4029)  time: 1.542244  data: 0.001152  max mem: 61695
I20250104 13:42:28 94 dinov2 helpers.py:102] Training  [    250/2500000]  eta: 63 days, 19:32:09  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2554 (7.4809)  dino_local_crops_loss: 5.2976 (5.2825)  dino_global_crops_loss: 0.6630 (0.6609)  koleo_loss: -0.0034 (0.1387)  ibot_loss: 1.2968 (1.3987)  time: 1.575749  data: 0.032087  max mem: 61695
I20250104 13:42:44 94 dinov2 helpers.py:102] Training  [    260/2500000]  eta: 63 days, 2:52:23  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2535 (7.4722)  dino_local_crops_loss: 5.2974 (5.2831)  dino_global_crops_loss: 0.6629 (0.6610)  koleo_loss: -0.0050 (0.1332)  ibot_loss: 1.2982 (1.3949)  time: 1.599831  data: 0.157486  max mem: 61695
I20250104 13:42:59 94 dinov2 helpers.py:102] Training  [    270/2500000]  eta: 62 days, 10:32:57  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2467 (7.4637)  dino_local_crops_loss: 5.2971 (5.2836)  dino_global_crops_loss: 0.6629 (0.6611)  koleo_loss: -0.0070 (0.1280)  ibot_loss: 1.2943 (1.3910)  time: 1.562168  data: 0.252881  max mem: 61695
I20250104 13:43:17 94 dinov2 helpers.py:102] Training  [    280/2500000]  eta: 62 days, 1:39:05  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2404 (7.4557)  dino_local_crops_loss: 5.2968 (5.2841)  dino_global_crops_loss: 0.6629 (0.6611)  koleo_loss: -0.0086 (0.1231)  ibot_loss: 1.2890 (1.3874)  time: 1.671545  data: 0.319501  max mem: 61695
I20250104 13:43:33 94 dinov2 helpers.py:102] Training  [    290/2500000]  eta: 61 days, 12:24:08  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2384 (7.4482)  dino_local_crops_loss: 5.2965 (5.2845)  dino_global_crops_loss: 0.6629 (0.6612)  koleo_loss: -0.0097 (0.1185)  ibot_loss: 1.2880 (1.3840)  time: 1.694315  data: 0.304548  max mem: 61695
I20250104 13:43:52 94 dinov2 helpers.py:102] Training  [    300/2500000]  eta: 61 days, 6:04:45  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2347 (7.4410)  dino_local_crops_loss: 5.2962 (5.2849)  dino_global_crops_loss: 0.6627 (0.6612)  koleo_loss: -0.0111 (0.1142)  ibot_loss: 1.2872 (1.3807)  time: 1.721376  data: 0.373065  max mem: 61695
I20250104 13:44:06 94 dinov2 helpers.py:102] Training  [    310/2500000]  eta: 60 days, 14:59:49  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2267 (7.4341)  dino_local_crops_loss: 5.2958 (5.2852)  dino_global_crops_loss: 0.6627 (0.6613)  koleo_loss: -0.0123 (0.1101)  ibot_loss: 1.2819 (1.3775)  time: 1.647166  data: 0.344749  max mem: 61695
I20250104 13:44:21 94 dinov2 helpers.py:102] Training  [    320/2500000]  eta: 60 days, 1:24:49  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2296 (7.4279)  dino_local_crops_loss: 5.2951 (5.2855)  dino_global_crops_loss: 0.6627 (0.6613)  koleo_loss: -0.0133 (0.1063)  ibot_loss: 1.2847 (1.3748)  time: 1.454837  data: 0.195399  max mem: 61695
I20250104 13:44:35 94 dinov2 helpers.py:102] Training  [    330/2500000]  eta: 59 days, 12:40:59  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2309 (7.4218)  dino_local_crops_loss: 5.2943 (5.2858)  dino_global_crops_loss: 0.6626 (0.6614)  koleo_loss: -0.0143 (0.1026)  ibot_loss: 1.2897 (1.3721)  time: 1.468537  data: 0.223539  max mem: 61695
I20250104 13:44:54 94 dinov2 helpers.py:102] Training  [    340/2500000]  eta: 59 days, 8:58:23  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2224 (7.4159)  dino_local_crops_loss: 5.2932 (5.2860)  dino_global_crops_loss: 0.6625 (0.6614)  koleo_loss: -0.0151 (0.0991)  ibot_loss: 1.2813 (1.3694)  time: 1.672479  data: 0.431781  max mem: 61695
I20250104 13:45:11 94 dinov2 helpers.py:102] Training  [    350/2500000]  eta: 59 days, 0:55:59  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2225 (7.4105)  dino_local_crops_loss: 5.2917 (5.2861)  dino_global_crops_loss: 0.6624 (0.6614)  koleo_loss: -0.0159 (0.0959)  ibot_loss: 1.2832 (1.3671)  time: 1.760876  data: 0.341865  max mem: 61695
I20250104 13:45:25 94 dinov2 helpers.py:102] Training  [    360/2500000]  eta: 58 days, 13:37:12  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2277 (7.4055)  dino_local_crops_loss: 5.2905 (5.2862)  dino_global_crops_loss: 0.6623 (0.6614)  koleo_loss: -0.0167 (0.0927)  ibot_loss: 1.2923 (1.3651)  time: 1.549443  data: 0.023944  max mem: 61695
I20250104 13:45:42 94 dinov2 helpers.py:102] Training  [    370/2500000]  eta: 58 days, 7:08:43  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2249 (7.4005)  dino_local_crops_loss: 5.2897 (5.2863)  dino_global_crops_loss: 0.6622 (0.6615)  koleo_loss: -0.0173 (0.0898)  ibot_loss: 1.2903 (1.3630)  time: 1.565758  data: 0.015977  max mem: 61695
I20250104 13:45:57 94 dinov2 helpers.py:102] Training  [    380/2500000]  eta: 57 days, 22:51:04  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2202 (7.3958)  dino_local_crops_loss: 5.2893 (5.2864)  dino_global_crops_loss: 0.6621 (0.6615)  koleo_loss: -0.0178 (0.0869)  ibot_loss: 1.2863 (1.3610)  time: 1.619490  data: 0.069808  max mem: 61695
I20250104 13:46:12 94 dinov2 helpers.py:102] Training  [    390/2500000]  eta: 57 days, 13:44:53  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2232 (7.3914)  dino_local_crops_loss: 5.2890 (5.2864)  dino_global_crops_loss: 0.6621 (0.6615)  koleo_loss: -0.0181 (0.0842)  ibot_loss: 1.2895 (1.3592)  time: 1.525537  data: 0.056390  max mem: 61695
I20250104 13:46:27 94 dinov2 helpers.py:102] Training  [    400/2500000]  eta: 57 days, 4:44:02  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2217 (7.3871)  dino_local_crops_loss: 5.2885 (5.2865)  dino_global_crops_loss: 0.6620 (0.6615)  koleo_loss: -0.0183 (0.0817)  ibot_loss: 1.2901 (1.3574)  time: 1.480288  data: 0.000314  max mem: 61695
I20250104 13:46:44 94 dinov2 helpers.py:102] Training  [    410/2500000]  eta: 57 days, 0:11:08  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2215 (7.3831)  dino_local_crops_loss: 5.2869 (5.2865)  dino_global_crops_loss: 0.6619 (0.6615)  koleo_loss: -0.0192 (0.0792)  ibot_loss: 1.2901 (1.3559)  time: 1.588949  data: 0.000367  max mem: 61695
I20250104 13:47:00 94 dinov2 helpers.py:102] Training  [    420/2500000]  eta: 56 days, 17:05:29  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2187 (7.3792)  dino_local_crops_loss: 5.2857 (5.2864)  dino_global_crops_loss: 0.6617 (0.6615)  koleo_loss: -0.0197 (0.0769)  ibot_loss: 1.2914 (1.3544)  time: 1.624421  data: 0.000363  max mem: 61695
I20250104 13:47:14 94 dinov2 helpers.py:102] Training  [    430/2500000]  eta: 56 days, 8:37:54  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2191 (7.3755)  dino_local_crops_loss: 5.2843 (5.2864)  dino_global_crops_loss: 0.6616 (0.6615)  koleo_loss: -0.0200 (0.0746)  ibot_loss: 1.2933 (1.3530)  time: 1.488098  data: 0.000335  max mem: 61695
I20250104 13:47:30 94 dinov2 helpers.py:102] Training  [    440/2500000]  eta: 56 days, 3:14:40  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2191 (7.3718)  dino_local_crops_loss: 5.2824 (5.2862)  dino_global_crops_loss: 0.6614 (0.6615)  koleo_loss: -0.0204 (0.0725)  ibot_loss: 1.2933 (1.3516)  time: 1.520900  data: 0.000394  max mem: 61695
I20250104 13:47:47 94 dinov2 helpers.py:102] Training  [    450/2500000]  eta: 55 days, 23:30:49  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 380.0000 (380.0000)  total_loss: 7.2085 (7.3682)  dino_local_crops_loss: 5.2788 (5.2861)  dino_global_crops_loss: 0.6610 (0.6615)  koleo_loss: -0.0206 (0.0704)  ibot_loss: 1.2885 (1.3502)  time: 1.652343  data: 0.000425  max mem: 61695
