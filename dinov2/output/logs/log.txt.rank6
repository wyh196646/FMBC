I20250118 07:39:26 96 dinov2 config.py:67] git:
  sha: 3aaebc0650e4cd8c86360f4040941ae711160c49, status: has uncommitted changes, branch: main

I20250118 07:39:26 96 dinov2 config.py:68] config_file: dinov2/configs/train/fmbc.yaml
eval: 
eval_only: False
local_rank: 6
no_resume: False
opts: ['train.dataset_path=TileDataset:split=TRAIN:root=/ruiyan/yuhao/data', 'train.output_dir=/ruiyan/yuhao/project/FMBC/dinov2/output']
output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
I20250118 07:39:26 96 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0038729833462074173
I20250118 07:39:26 96 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 120
  dataset_path: TileDataset:split=TRAIN:root=/ruiyan/yuhao/data
  output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
  saveckp_freq: 20
  seed: 0
  num_workers: 16
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 4000
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0038729833462074173
  warmup_epochs: 0
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250118 07:39:27 96 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250118 07:39:30 96 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 1024
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_large network.
I20250118 07:39:35 96 dinov2 ssl_meta_arch.py:396] DISTRIBUTED FSDP -- preparing model for distributed training
I20250118 07:39:35 96 dinov2 train.py:307] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20250118 07:39:35 96 dinov2 param_groups.py:54] chunked fsdp
I20250118 07:39:35 96 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.01435795975383706, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.01435795975383706, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.norm1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.norm1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.attn.proj.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.attn.proj.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.ls1.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.norm2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.norm2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.3.ls2.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.norm1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.norm1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.attn.proj.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.attn.proj.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.ls1.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.norm2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.norm2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.4.ls2.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.norm1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.norm1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.attn.proj.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.attn.proj.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.ls1.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.norm2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.norm2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.0.5.ls2.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.norm1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.norm1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.attn.proj.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.attn.proj.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.ls1.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.norm2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.norm2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.6.ls2.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.norm1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.norm1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.attn.proj.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.attn.proj.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.ls1.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.norm2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.norm2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.7.ls2.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.norm1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.norm1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.attn.proj.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.attn.proj.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.ls1.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.norm2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.norm2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.8.ls2.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.norm1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.norm1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.attn.proj.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.attn.proj.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.ls1.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.norm2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.norm2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.9.ls2.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.norm1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.norm1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.attn.proj.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.attn.proj.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.ls1.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.norm2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.norm2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.10.ls2.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.norm1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.norm1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.attn.proj.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.attn.proj.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.ls1.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.norm2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.norm2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.1.11.ls2.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.12.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.13.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.14.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.15.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.16.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.2.17.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.18.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.19.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.20.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.21.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.22.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] blocks.3.23.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 07:39:35 96 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 07:39:36 96 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250118 07:39:36 96 dinov2 param_groups.py:64] else code branch
I20250118 07:39:36 96 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 07:39:36 96 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 07:39:36 96 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 07:39:36 96 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 07:39:36 96 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 07:39:36 96 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 07:39:36 96 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 07:39:36 96 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 07:39:36 96 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250118 07:39:36 96 dinov2 train.py:106] Schedulers ready.
I20250118 07:39:36 96 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250118 07:39:36 96 dinov2 augmentations.py:34] ###################################
I20250118 07:39:36 96 dinov2 augmentations.py:35] Using data augmentation parameters:
I20250118 07:39:36 96 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20250118 07:39:36 96 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20250118 07:39:36 96 dinov2 augmentations.py:38] local_crops_number: 8
I20250118 07:39:36 96 dinov2 augmentations.py:39] global_crops_size: 224
I20250118 07:39:36 96 dinov2 augmentations.py:40] local_crops_size: 96
I20250118 07:39:36 96 dinov2 augmentations.py:41] ###################################
I20250118 07:39:36 96 dinov2 loaders.py:86] using dataset: "TileDataset:split=TRAIN:root=/ruiyan/yuhao/data"
I20250118 07:48:16 96 dinov2 loaders.py:91] # of dataset samples: 95,954,228
I20250118 07:48:16 96 dinov2 loaders.py:124] sampler: sharded infinite
I20250118 07:48:16 96 dinov2 loaders.py:208] using PyTorch data loader
I20250118 07:48:16 96 dinov2 loaders.py:223] infinite data loader
I20250118 07:48:16 96 dinov2 train.py:221] Starting training from iteration 0
I20250118 07:49:49 96 dinov2 helpers.py:102] Training  [      0/5000000]  eta: 5370 days, 19:15:53  lr: 0.0039 (0.0039)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 120.0000 (120.0000)  total_loss: 13.7306 (13.7306)  dino_local_crops_loss: 9.1555 (9.1555)  dino_global_crops_loss: 1.1444 (1.1444)  koleo_loss: 0.6870 (0.6870)  ibot_loss: 2.7436 (2.7436)  time: 92.807472  data: 84.483719  max mem: 57424
I20250118 07:50:01 96 dinov2 helpers.py:102] Training  [     10/5000000]  eta: 552 days, 23:51:40  lr: 0.0039 (0.0039)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 120.0000 (120.0000)  total_loss: 14.1671 (14.1306)  dino_local_crops_loss: 9.5172 (9.4874)  dino_global_crops_loss: 1.1896 (1.1859)  koleo_loss: 0.6885 (0.6875)  ibot_loss: 2.7718 (2.7697)  time: 9.555759  data: 7.680554  max mem: 57438
I20250118 07:50:14 96 dinov2 helpers.py:102] Training  [     20/5000000]  eta: 323 days, 13:42:12  lr: 0.0039 (0.0039)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 120.0000 (120.0000)  total_loss: 13.8807 (13.9767)  dino_local_crops_loss: 9.7285 (9.6220)  dino_global_crops_loss: 1.2161 (1.2026)  koleo_loss: 0.1403 (0.3909)  ibot_loss: 2.7569 (2.7611)  time: 1.230522  data: 0.000190  max mem: 57749
I20250118 07:50:26 96 dinov2 helpers.py:102] Training  [     30/5000000]  eta: 242 days, 2:42:54  lr: 0.0039 (0.0039)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 120.0000 (120.0000)  total_loss: 13.7966 (13.9193)  dino_local_crops_loss: 9.7853 (9.6780)  dino_global_crops_loss: 1.2223 (1.2097)  koleo_loss: 0.0285 (0.2720)  ibot_loss: 2.7552 (2.7596)  time: 1.229129  data: 0.000209  max mem: 57749
I20250118 07:50:38 96 dinov2 helpers.py:102] Training  [     40/5000000]  eta: 200 days, 7:06:01  lr: 0.0039 (0.0039)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 120.0000 (120.0000)  total_loss: 13.8345 (13.9008)  dino_local_crops_loss: 9.8241 (9.7154)  dino_global_crops_loss: 1.2279 (1.2144)  koleo_loss: 0.0202 (0.2109)  ibot_loss: 2.7604 (2.7601)  time: 1.224442  data: 0.000221  max mem: 57749
I20250118 07:50:50 96 dinov2 helpers.py:102] Training  [     50/5000000]  eta: 174 days, 17:26:12  lr: 0.0039 (0.0039)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 120.0000 (120.0000)  total_loss: 13.8336 (13.8761)  dino_local_crops_loss: 9.8258 (9.7272)  dino_global_crops_loss: 1.2282 (1.2158)  koleo_loss: 0.0144 (0.1717)  ibot_loss: 2.7625 (2.7613)  time: 1.214430  data: 0.000177  max mem: 57749
I20250118 07:51:02 96 dinov2 helpers.py:102] Training  [     60/5000000]  eta: 157 days, 14:57:47  lr: 0.0039 (0.0039)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 120.0000 (120.0000)  total_loss: 13.7290 (13.8500)  dino_local_crops_loss: 9.7344 (9.7262)  dino_global_crops_loss: 1.2168 (1.2157)  koleo_loss: 0.0080 (0.1446)  ibot_loss: 2.7713 (2.7634)  time: 1.212150  data: 0.000192  max mem: 57752
I20250118 07:51:14 96 dinov2 helpers.py:102] Training  [     70/5000000]  eta: 145 days, 5:07:27  lr: 0.0039 (0.0039)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 120.0000 (120.0000)  total_loss: 13.7180 (13.8311)  dino_local_crops_loss: 9.7211 (9.7250)  dino_global_crops_loss: 1.2153 (1.2156)  koleo_loss: 0.0032 (0.1245)  ibot_loss: 2.7760 (2.7659)  time: 1.208875  data: 0.000171  max mem: 57752
I20250118 07:51:26 96 dinov2 helpers.py:102] Training  [     80/5000000]  eta: 135 days, 23:10:20  lr: 0.0039 (0.0039)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 120.0000 (120.0000)  total_loss: 13.6620 (13.8061)  dino_local_crops_loss: 9.6660 (9.7131)  dino_global_crops_loss: 1.2095 (1.2144)  koleo_loss: 0.0024 (0.1095)  ibot_loss: 2.7862 (2.7691)  time: 1.208076  data: 0.000164  max mem: 57752
I20250118 07:51:39 96 dinov2 helpers.py:102] Training  [     90/5000000]  eta: 128 days, 17:26:04  lr: 0.0039 (0.0039)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 120.0000 (120.0000)  total_loss: 13.6318 (13.7867)  dino_local_crops_loss: 9.6265 (9.7030)  dino_global_crops_loss: 1.2074 (1.2138)  koleo_loss: 0.0027 (0.0978)  ibot_loss: 2.7957 (2.7721)  time: 1.213068  data: 0.000183  max mem: 57752
I20250118 07:52:26 96 dinov2 config.py:67] git:
  sha: 3aaebc0650e4cd8c86360f4040941ae711160c49, status: has uncommitted changes, branch: main

I20250118 07:52:26 96 dinov2 config.py:68] config_file: dinov2/configs/train/fmbc.yaml
eval: 
eval_only: False
local_rank: 6
no_resume: False
opts: ['train.dataset_path=TileDataset:split=TRAIN:root=/ruiyan/yuhao/data', 'train.output_dir=/ruiyan/yuhao/project/FMBC/dinov2/output']
output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
I20250118 07:52:26 96 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.00447213595499958
I20250118 07:52:26 96 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 160
  dataset_path: TileDataset:split=TRAIN:root=/ruiyan/yuhao/data
  output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
  saveckp_freq: 20
  seed: 0
  num_workers: 16
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 4000
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.00447213595499958
  warmup_epochs: 0
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250118 07:52:26 96 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250118 07:52:29 96 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 1024
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_large network.
I20250118 07:52:34 96 dinov2 ssl_meta_arch.py:396] DISTRIBUTED FSDP -- preparing model for distributed training
I20250118 07:52:35 96 dinov2 train.py:307] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20250118 07:52:35 96 dinov2 param_groups.py:54] chunked fsdp
I20250118 07:52:35 96 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.01435795975383706, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.01435795975383706, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.norm1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.norm1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.attn.proj.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.attn.proj.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.ls1.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.norm2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.norm2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.3.ls2.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.norm1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.norm1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.attn.proj.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.attn.proj.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.ls1.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.norm2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.norm2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.4.ls2.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.norm1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.norm1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.attn.proj.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.attn.proj.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.ls1.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.norm2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.norm2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.0.5.ls2.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.norm1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.norm1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.attn.proj.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.attn.proj.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.ls1.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.norm2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.norm2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.6.ls2.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.norm1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.norm1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.attn.proj.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.attn.proj.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.ls1.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.norm2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.norm2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.7.ls2.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.norm1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.norm1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.attn.proj.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.attn.proj.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.ls1.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.norm2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.norm2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.8.ls2.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.norm1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.norm1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.attn.proj.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.attn.proj.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.ls1.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.norm2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.norm2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.9.ls2.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.norm1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.norm1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.attn.proj.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.attn.proj.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.ls1.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.norm2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.norm2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.10.ls2.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.norm1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.norm1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.attn.proj.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.attn.proj.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.ls1.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.norm2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.norm2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.1.11.ls2.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.12.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.13.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.14.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.15.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.16.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.2.17.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.18.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.19.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.20.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.21.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.22.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] blocks.3.23.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250118 07:52:35 96 dinov2 param_groups.py:64] else code branch
I20250118 07:52:35 96 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 07:52:35 96 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250118 07:52:35 96 dinov2 train.py:106] Schedulers ready.
I20250118 07:52:35 96 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250118 07:52:35 96 dinov2 augmentations.py:34] ###################################
I20250118 07:52:35 96 dinov2 augmentations.py:35] Using data augmentation parameters:
I20250118 07:52:35 96 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20250118 07:52:35 96 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20250118 07:52:35 96 dinov2 augmentations.py:38] local_crops_number: 8
I20250118 07:52:35 96 dinov2 augmentations.py:39] global_crops_size: 224
I20250118 07:52:35 96 dinov2 augmentations.py:40] local_crops_size: 96
I20250118 07:52:35 96 dinov2 augmentations.py:41] ###################################
I20250118 07:52:35 96 dinov2 loaders.py:86] using dataset: "TileDataset:split=TRAIN:root=/ruiyan/yuhao/data"
I20250118 08:01:10 96 dinov2 loaders.py:91] # of dataset samples: 95,954,228
I20250118 08:01:10 96 dinov2 loaders.py:124] sampler: sharded infinite
I20250118 08:01:10 96 dinov2 loaders.py:208] using PyTorch data loader
I20250118 08:01:10 96 dinov2 loaders.py:223] infinite data loader
I20250118 08:01:10 96 dinov2 train.py:221] Starting training from iteration 0
I20250118 08:02:53 96 dinov2 helpers.py:102] Training  [      0/5000000]  eta: 5965 days, 9:44:46  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7307 (13.7307)  dino_local_crops_loss: 9.1555 (9.1555)  dino_global_crops_loss: 1.1444 (1.1444)  koleo_loss: 0.6870 (0.6870)  ibot_loss: 2.7437 (2.7437)  time: 103.082214  data: 85.598167  max mem: 76057
I20250118 08:03:17 96 dinov2 helpers.py:102] Training  [     10/5000000]  eta: 665 days, 19:54:33  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 14.0980 (14.0826)  dino_local_crops_loss: 9.5172 (9.4928)  dino_global_crops_loss: 1.1896 (1.1866)  koleo_loss: 0.6870 (0.6367)  ibot_loss: 2.7674 (2.7665)  time: 11.505558  data: 7.781910  max mem: 76373
I20250118 08:03:37 96 dinov2 helpers.py:102] Training  [     20/5000000]  eta: 404 days, 3:43:24  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8317 (13.9505)  dino_local_crops_loss: 9.7551 (9.6294)  dino_global_crops_loss: 1.2194 (1.2037)  koleo_loss: 0.1301 (0.3595)  ibot_loss: 2.7542 (2.7578)  time: 2.178910  data: 0.000223  max mem: 76380
I20250118 08:03:52 96 dinov2 helpers.py:102] Training  [     30/5000000]  eta: 302 days, 9:15:02  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8242 (13.9129)  dino_local_crops_loss: 9.7965 (9.6888)  dino_global_crops_loss: 1.2243 (1.2111)  koleo_loss: 0.0389 (0.2525)  ibot_loss: 2.7594 (2.7605)  time: 1.771084  data: 0.000155  max mem: 76380
I20250118 08:04:08 96 dinov2 helpers.py:102] Training  [     40/5000000]  eta: 250 days, 4:04:43  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8327 (13.8924)  dino_local_crops_loss: 9.8180 (9.7197)  dino_global_crops_loss: 1.2273 (1.2150)  koleo_loss: 0.0179 (0.1945)  ibot_loss: 2.7685 (2.7632)  time: 1.529071  data: 0.000198  max mem: 76380
I20250118 08:04:23 96 dinov2 helpers.py:102] Training  [     50/5000000]  eta: 218 days, 8:41:30  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8074 (13.8746)  dino_local_crops_loss: 9.7906 (9.7330)  dino_global_crops_loss: 1.2238 (1.2166)  koleo_loss: 0.0111 (0.1583)  ibot_loss: 2.7755 (2.7667)  time: 1.522866  data: 0.000203  max mem: 76383
I20250118 08:04:40 96 dinov2 helpers.py:102] Training  [     60/5000000]  eta: 198 days, 12:27:47  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7967 (13.8581)  dino_local_crops_loss: 9.7832 (9.7367)  dino_global_crops_loss: 1.2229 (1.2171)  koleo_loss: 0.0096 (0.1338)  ibot_loss: 2.7835 (2.7704)  time: 1.600795  data: 0.000162  max mem: 76383
I20250118 08:04:55 96 dinov2 helpers.py:102] Training  [     70/5000000]  eta: 182 days, 22:51:29  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7132 (13.8272)  dino_local_crops_loss: 9.6969 (9.7207)  dino_global_crops_loss: 1.2122 (1.2152)  koleo_loss: 0.0096 (0.1165)  ibot_loss: 2.7943 (2.7749)  time: 1.601184  data: 0.000170  max mem: 76383
I20250118 08:05:10 96 dinov2 helpers.py:102] Training  [     80/5000000]  eta: 171 days, 5:24:09  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.5427 (13.7863)  dino_local_crops_loss: 9.5323 (9.6919)  dino_global_crops_loss: 1.1938 (1.2119)  koleo_loss: 0.0104 (0.1035)  ibot_loss: 2.8045 (2.7790)  time: 1.520323  data: 0.000197  max mem: 76383
I20250118 08:05:27 96 dinov2 helpers.py:102] Training  [     90/5000000]  eta: 163 days, 2:59:36  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.5032 (13.7615)  dino_local_crops_loss: 9.4966 (9.6781)  dino_global_crops_loss: 1.1898 (1.2103)  koleo_loss: 0.0109 (0.0933)  ibot_loss: 2.7976 (2.7797)  time: 1.602558  data: 0.000268  max mem: 76387
I20250118 08:05:44 96 dinov2 helpers.py:102] Training  [    100/5000000]  eta: 156 days, 15:55:10  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.6691 (13.7661)  dino_local_crops_loss: 9.6682 (9.6889)  dino_global_crops_loss: 1.2094 (1.2117)  koleo_loss: 0.0113 (0.0852)  ibot_loss: 2.7856 (2.7803)  time: 1.688132  data: 0.000234  max mem: 76387
I20250118 08:05:59 96 dinov2 helpers.py:102] Training  [    110/5000000]  eta: 150 days, 10:58:52  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8033 (13.7682)  dino_local_crops_loss: 9.7904 (9.6986)  dino_global_crops_loss: 1.2242 (1.2129)  koleo_loss: 0.0114 (0.0786)  ibot_loss: 2.7761 (2.7781)  time: 1.604049  data: 0.000178  max mem: 76387
I20250118 08:06:16 96 dinov2 helpers.py:102] Training  [    120/5000000]  eta: 146 days, 2:22:40  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7317 (13.7637)  dino_local_crops_loss: 9.7689 (9.7039)  dino_global_crops_loss: 1.2226 (1.2136)  koleo_loss: 0.0110 (0.0729)  ibot_loss: 2.7334 (2.7733)  time: 1.602807  data: 0.000183  max mem: 76387
I20250118 08:06:31 96 dinov2 helpers.py:102] Training  [    130/5000000]  eta: 141 days, 16:01:19  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7384 (13.7685)  dino_local_crops_loss: 9.7994 (9.7163)  dino_global_crops_loss: 1.2254 (1.2151)  koleo_loss: 0.0100 (0.0680)  ibot_loss: 2.7169 (2.7691)  time: 1.605123  data: 0.000197  max mem: 76387
I20250118 08:06:46 96 dinov2 helpers.py:102] Training  [    140/5000000]  eta: 137 days, 21:29:17  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9009 (13.7811)  dino_local_crops_loss: 9.9108 (9.7317)  dino_global_crops_loss: 1.2389 (1.2170)  koleo_loss: 0.0111 (0.0640)  ibot_loss: 2.7404 (2.7684)  time: 1.525284  data: 0.000258  max mem: 76387
I20250118 08:07:02 96 dinov2 helpers.py:102] Training  [    150/5000000]  eta: 134 days, 14:30:10  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9393 (13.7915)  dino_local_crops_loss: 9.9324 (9.7451)  dino_global_crops_loss: 1.2418 (1.2187)  koleo_loss: 0.0117 (0.0606)  ibot_loss: 2.7521 (2.7671)  time: 1.526620  data: 0.000257  max mem: 76387
I20250118 08:07:17 96 dinov2 helpers.py:102] Training  [    160/5000000]  eta: 131 days, 17:08:58  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9402 (13.8013)  dino_local_crops_loss: 9.9367 (9.7571)  dino_global_crops_loss: 1.2423 (1.2202)  koleo_loss: 0.0094 (0.0573)  ibot_loss: 2.7548 (2.7668)  time: 1.523177  data: 0.000193  max mem: 76387
I20250118 08:07:32 96 dinov2 helpers.py:102] Training  [    170/5000000]  eta: 129 days, 4:18:40  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9548 (13.8105)  dino_local_crops_loss: 9.9363 (9.7675)  dino_global_crops_loss: 1.2422 (1.2214)  koleo_loss: 0.0063 (0.0542)  ibot_loss: 2.7709 (2.7673)  time: 1.524624  data: 0.000154  max mem: 76387
I20250118 08:07:47 96 dinov2 helpers.py:102] Training  [    180/5000000]  eta: 126 days, 21:57:55  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9650 (13.8195)  dino_local_crops_loss: 9.9384 (9.7772)  dino_global_crops_loss: 1.2426 (1.2226)  koleo_loss: 0.0039 (0.0514)  ibot_loss: 2.7799 (2.7682)  time: 1.525616  data: 0.000158  max mem: 76387
I20250118 08:08:02 96 dinov2 helpers.py:102] Training  [    190/5000000]  eta: 124 days, 21:08:35  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9788 (13.8280)  dino_local_crops_loss: 9.9433 (9.7860)  dino_global_crops_loss: 1.2436 (1.2238)  koleo_loss: 0.0011 (0.0487)  ibot_loss: 2.7872 (2.7695)  time: 1.522976  data: 0.000158  max mem: 76387
I20250118 08:08:18 96 dinov2 helpers.py:102] Training  [    200/5000000]  eta: 123 days, 1:57:16  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9785 (13.8343)  dino_local_crops_loss: 9.9382 (9.7924)  dino_global_crops_loss: 1.2432 (1.2246)  koleo_loss: -0.0005 (0.0462)  ibot_loss: 2.7969 (2.7711)  time: 1.527445  data: 0.000210  max mem: 76387
I20250118 08:08:33 96 dinov2 helpers.py:102] Training  [    210/5000000]  eta: 121 days, 10:33:31  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9066 (13.8353)  dino_local_crops_loss: 9.8680 (9.7937)  dino_global_crops_loss: 1.2354 (1.2248)  koleo_loss: -0.0017 (0.0440)  ibot_loss: 2.8048 (2.7728)  time: 1.530778  data: 0.000217  max mem: 76387
I20250118 08:08:48 96 dinov2 helpers.py:102] Training  [    220/5000000]  eta: 119 days, 22:20:47  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7966 (13.8320)  dino_local_crops_loss: 9.7611 (9.7910)  dino_global_crops_loss: 1.2244 (1.2247)  koleo_loss: -0.0005 (0.0420)  ibot_loss: 2.8068 (2.7743)  time: 1.525463  data: 0.000185  max mem: 76387
I20250118 08:09:04 96 dinov2 helpers.py:102] Training  [    230/5000000]  eta: 118 days, 13:35:50  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7668 (13.8296)  dino_local_crops_loss: 9.7429 (9.7894)  dino_global_crops_loss: 1.2226 (1.2247)  koleo_loss: -0.0007 (0.0401)  ibot_loss: 2.8011 (2.7754)  time: 1.525159  data: 0.000214  max mem: 76387
I20250118 08:09:19 96 dinov2 helpers.py:102] Training  [    240/5000000]  eta: 117 days, 7:38:36  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7890 (13.8283)  dino_local_crops_loss: 9.7687 (9.7891)  dino_global_crops_loss: 1.2259 (1.2248)  koleo_loss: -0.0016 (0.0384)  ibot_loss: 2.7950 (2.7760)  time: 1.528564  data: 0.000190  max mem: 76387
I20250118 08:09:34 96 dinov2 helpers.py:102] Training  [    250/5000000]  eta: 116 days, 3:22:14  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8002 (13.8273)  dino_local_crops_loss: 9.7865 (9.7891)  dino_global_crops_loss: 1.2280 (1.2250)  koleo_loss: -0.0015 (0.0368)  ibot_loss: 2.7872 (2.7763)  time: 1.522863  data: 0.000176  max mem: 76387
I20250118 08:09:51 96 dinov2 helpers.py:102] Training  [    260/5000000]  eta: 115 days, 10:14:44  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8011 (13.8264)  dino_local_crops_loss: 9.7971 (9.7896)  dino_global_crops_loss: 1.2295 (1.2252)  koleo_loss: -0.0013 (0.0354)  ibot_loss: 2.7754 (2.7762)  time: 1.600885  data: 0.000176  max mem: 76387
I20250118 08:10:06 96 dinov2 helpers.py:102] Training  [    270/5000000]  eta: 114 days, 9:59:52  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8063 (13.8261)  dino_local_crops_loss: 9.8044 (9.7905)  dino_global_crops_loss: 1.2303 (1.2254)  koleo_loss: -0.0006 (0.0341)  ibot_loss: 2.7735 (2.7761)  time: 1.603462  data: 0.000166  max mem: 76387
I20250118 08:10:21 96 dinov2 helpers.py:102] Training  [    280/5000000]  eta: 113 days, 11:33:40  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8274 (13.8265)  dino_local_crops_loss: 9.8211 (9.7919)  dino_global_crops_loss: 1.2319 (1.2257)  koleo_loss: 0.0003 (0.0329)  ibot_loss: 2.7737 (2.7760)  time: 1.522508  data: 0.000195  max mem: 76387
I20250118 08:10:37 96 dinov2 helpers.py:102] Training  [    290/5000000]  eta: 112 days, 14:25:24  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8413 (13.8272)  dino_local_crops_loss: 9.8331 (9.7934)  dino_global_crops_loss: 1.2334 (1.2259)  koleo_loss: 0.0024 (0.0319)  ibot_loss: 2.7723 (2.7759)  time: 1.520828  data: 0.000183  max mem: 76387
I20250118 08:10:52 96 dinov2 helpers.py:102] Training  [    300/5000000]  eta: 111 days, 18:49:59  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8528 (13.8282)  dino_local_crops_loss: 9.8433 (9.7954)  dino_global_crops_loss: 1.2342 (1.2262)  koleo_loss: 0.0042 (0.0310)  ibot_loss: 2.7699 (2.7756)  time: 1.519836  data: 0.000173  max mem: 76387
I20250118 08:11:07 96 dinov2 helpers.py:102] Training  [    310/5000000]  eta: 111 days, 1:00:50  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8598 (13.8291)  dino_local_crops_loss: 9.8557 (9.7973)  dino_global_crops_loss: 1.2349 (1.2265)  koleo_loss: 0.0022 (0.0300)  ibot_loss: 2.7661 (2.7753)  time: 1.527117  data: 0.000212  max mem: 76387
I20250118 08:11:22 96 dinov2 helpers.py:102] Training  [    320/5000000]  eta: 110 days, 8:02:25  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8600 (13.8303)  dino_local_crops_loss: 9.8525 (9.7991)  dino_global_crops_loss: 1.2339 (1.2267)  koleo_loss: 0.0009 (0.0291)  ibot_loss: 2.7697 (2.7753)  time: 1.529789  data: 0.000220  max mem: 76387
I20250118 08:11:38 96 dinov2 helpers.py:102] Training  [    330/5000000]  eta: 109 days, 15:36:15  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8795 (13.8321)  dino_local_crops_loss: 9.8586 (9.8010)  dino_global_crops_loss: 1.2342 (1.2270)  koleo_loss: 0.0005 (0.0283)  ibot_loss: 2.7842 (2.7758)  time: 1.520921  data: 0.000226  max mem: 76387
I20250118 08:11:53 96 dinov2 helpers.py:102] Training  [    340/5000000]  eta: 109 days, 0:38:01  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8934 (13.8341)  dino_local_crops_loss: 9.8673 (9.8031)  dino_global_crops_loss: 1.2349 (1.2272)  koleo_loss: 0.0004 (0.0275)  ibot_loss: 2.7914 (2.7763)  time: 1.521266  data: 0.000235  max mem: 76387
I20250118 08:12:08 96 dinov2 helpers.py:102] Training  [    350/5000000]  eta: 108 days, 10:19:33  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9016 (13.8361)  dino_local_crops_loss: 9.8781 (9.8054)  dino_global_crops_loss: 1.2361 (1.2275)  koleo_loss: 0.0004 (0.0267)  ibot_loss: 2.7865 (2.7765)  time: 1.525027  data: 0.000241  max mem: 76387
I20250118 08:12:23 96 dinov2 helpers.py:102] Training  [    360/5000000]  eta: 107 days, 20:32:30  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9036 (13.8379)  dino_local_crops_loss: 9.8832 (9.8076)  dino_global_crops_loss: 1.2367 (1.2278)  koleo_loss: 0.0009 (0.0261)  ibot_loss: 2.7832 (2.7766)  time: 1.519130  data: 0.000287  max mem: 76387
I20250118 08:12:38 96 dinov2 helpers.py:102] Training  [    370/5000000]  eta: 107 days, 7:39:54  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8953 (13.8393)  dino_local_crops_loss: 9.8885 (9.8098)  dino_global_crops_loss: 1.2375 (1.2280)  koleo_loss: 0.0003 (0.0253)  ibot_loss: 2.7673 (2.7761)  time: 1.517836  data: 0.000298  max mem: 76387
I20250118 08:12:54 96 dinov2 helpers.py:102] Training  [    380/5000000]  eta: 106 days, 19:47:03  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8826 (13.8403)  dino_local_crops_loss: 9.8907 (9.8119)  dino_global_crops_loss: 1.2378 (1.2283)  koleo_loss: -0.0017 (0.0246)  ibot_loss: 2.7555 (2.7755)  time: 1.524427  data: 0.000271  max mem: 76387
I20250118 08:13:09 96 dinov2 helpers.py:102] Training  [    390/5000000]  eta: 106 days, 8:32:41  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8819 (13.8415)  dino_local_crops_loss: 9.8938 (9.8141)  dino_global_crops_loss: 1.2378 (1.2285)  koleo_loss: -0.0019 (0.0239)  ibot_loss: 2.7522 (2.7749)  time: 1.529295  data: 0.000218  max mem: 76387
I20250118 08:13:24 96 dinov2 helpers.py:102] Training  [    400/5000000]  eta: 105 days, 21:44:56  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9003 (13.8430)  dino_local_crops_loss: 9.8976 (9.8162)  dino_global_crops_loss: 1.2386 (1.2288)  koleo_loss: -0.0015 (0.0233)  ibot_loss: 2.7625 (2.7747)  time: 1.528087  data: 0.000168  max mem: 76387
I20250118 08:13:39 96 dinov2 helpers.py:102] Training  [    410/5000000]  eta: 105 days, 11:17:50  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9074 (13.8448)  dino_local_crops_loss: 9.9024 (9.8184)  dino_global_crops_loss: 1.2388 (1.2290)  koleo_loss: -0.0009 (0.0227)  ibot_loss: 2.7698 (2.7747)  time: 1.523720  data: 0.000213  max mem: 76387
I20250118 08:13:55 96 dinov2 helpers.py:102] Training  [    420/5000000]  eta: 105 days, 1:34:14  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9184 (13.8466)  dino_local_crops_loss: 9.9003 (9.8203)  dino_global_crops_loss: 1.2385 (1.2292)  koleo_loss: -0.0008 (0.0222)  ibot_loss: 2.7799 (2.7749)  time: 1.524511  data: 0.000234  max mem: 76387
I20250118 08:14:10 96 dinov2 helpers.py:102] Training  [    430/5000000]  eta: 104 days, 16:13:45  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9229 (13.8485)  dino_local_crops_loss: 9.8981 (9.8221)  dino_global_crops_loss: 1.2380 (1.2295)  koleo_loss: -0.0004 (0.0217)  ibot_loss: 2.7860 (2.7752)  time: 1.526957  data: 0.000225  max mem: 76387
I20250118 08:14:25 96 dinov2 helpers.py:102] Training  [    440/5000000]  eta: 104 days, 7:04:03  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9261 (13.8505)  dino_local_crops_loss: 9.8988 (9.8240)  dino_global_crops_loss: 1.2389 (1.2297)  koleo_loss: 0.0000 (0.0213)  ibot_loss: 2.7886 (2.7756)  time: 1.522065  data: 0.000272  max mem: 76387
I20250118 08:14:40 96 dinov2 helpers.py:102] Training  [    450/5000000]  eta: 103 days, 22:40:13  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9427 (13.8525)  dino_local_crops_loss: 9.9111 (9.8260)  dino_global_crops_loss: 1.2398 (1.2299)  koleo_loss: 0.0041 (0.0209)  ibot_loss: 2.7869 (2.7758)  time: 1.524013  data: 0.000232  max mem: 76387
I20250118 08:14:56 96 dinov2 helpers.py:102] Training  [    460/5000000]  eta: 103 days, 14:37:34  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9394 (13.8543)  dino_local_crops_loss: 9.9093 (9.8277)  dino_global_crops_loss: 1.2399 (1.2301)  koleo_loss: 0.0038 (0.0205)  ibot_loss: 2.7855 (2.7760)  time: 1.529644  data: 0.000157  max mem: 76387
I20250118 08:15:11 96 dinov2 helpers.py:102] Training  [    470/5000000]  eta: 103 days, 6:42:34  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9394 (13.8563)  dino_local_crops_loss: 9.9078 (9.8295)  dino_global_crops_loss: 1.2397 (1.2303)  koleo_loss: 0.0032 (0.0201)  ibot_loss: 2.7870 (2.7762)  time: 1.525834  data: 0.000175  max mem: 76387
I20250118 08:15:26 96 dinov2 helpers.py:102] Training  [    480/5000000]  eta: 102 days, 23:08:39  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9414 (13.8579)  dino_local_crops_loss: 9.9078 (9.8311)  dino_global_crops_loss: 1.2400 (1.2305)  koleo_loss: 0.0054 (0.0199)  ibot_loss: 2.7848 (2.7764)  time: 1.522597  data: 0.000177  max mem: 76387
I20250118 08:15:41 96 dinov2 helpers.py:102] Training  [    490/5000000]  eta: 102 days, 15:54:47  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9347 (13.8596)  dino_local_crops_loss: 9.8997 (9.8325)  dino_global_crops_loss: 1.2390 (1.2307)  koleo_loss: 0.0096 (0.0198)  ibot_loss: 2.7848 (2.7766)  time: 1.523446  data: 0.000191  max mem: 76387
I20250118 08:15:57 96 dinov2 helpers.py:102] Training  [    500/5000000]  eta: 102 days, 8:51:10  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9333 (13.8608)  dino_local_crops_loss: 9.8874 (9.8333)  dino_global_crops_loss: 1.2372 (1.2308)  koleo_loss: 0.0149 (0.0198)  ibot_loss: 2.7896 (2.7769)  time: 1.521791  data: 0.000189  max mem: 76387
I20250118 08:16:12 96 dinov2 helpers.py:102] Training  [    510/5000000]  eta: 102 days, 2:04:10  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9072 (13.8615)  dino_local_crops_loss: 9.8624 (9.8337)  dino_global_crops_loss: 1.2346 (1.2308)  koleo_loss: 0.0154 (0.0197)  ibot_loss: 2.7937 (2.7773)  time: 1.519682  data: 0.000189  max mem: 76387
I20250118 08:16:27 96 dinov2 helpers.py:102] Training  [    520/5000000]  eta: 101 days, 19:38:38  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9028 (13.8624)  dino_local_crops_loss: 9.8508 (9.8341)  dino_global_crops_loss: 1.2335 (1.2309)  koleo_loss: 0.0211 (0.0198)  ibot_loss: 2.7945 (2.7777)  time: 1.521523  data: 0.000200  max mem: 76387
I20250118 08:16:42 96 dinov2 helpers.py:102] Training  [    530/5000000]  eta: 101 days, 13:34:26  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9028 (13.8631)  dino_local_crops_loss: 9.8502 (9.8343)  dino_global_crops_loss: 1.2331 (1.2309)  koleo_loss: 0.0221 (0.0198)  ibot_loss: 2.7964 (2.7780)  time: 1.525528  data: 0.000211  max mem: 76387
I20250118 08:16:58 96 dinov2 helpers.py:102] Training  [    540/5000000]  eta: 101 days, 7:28:46  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8967 (13.8637)  dino_local_crops_loss: 9.8516 (9.8347)  dino_global_crops_loss: 1.2323 (1.2310)  koleo_loss: 0.0220 (0.0199)  ibot_loss: 2.7917 (2.7782)  time: 1.522856  data: 0.000216  max mem: 76387
I20250118 08:17:14 96 dinov2 helpers.py:102] Training  [    550/5000000]  eta: 101 days, 5:59:38  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8901 (13.8640)  dino_local_crops_loss: 9.8501 (9.8349)  dino_global_crops_loss: 1.2320 (1.2310)  koleo_loss: 0.0217 (0.0199)  ibot_loss: 2.7842 (2.7782)  time: 1.605058  data: 0.000251  max mem: 76387
I20250118 08:17:30 96 dinov2 helpers.py:102] Training  [    560/5000000]  eta: 101 days, 0:25:39  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8757 (13.8643)  dino_local_crops_loss: 9.8491 (9.8353)  dino_global_crops_loss: 1.2316 (1.2310)  koleo_loss: 0.0196 (0.0199)  ibot_loss: 2.7794 (2.7782)  time: 1.608616  data: 0.000246  max mem: 76387
I20250118 08:17:45 96 dinov2 helpers.py:102] Training  [    570/5000000]  eta: 100 days, 18:54:38  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8646 (13.8640)  dino_local_crops_loss: 9.8390 (9.8352)  dino_global_crops_loss: 1.2310 (1.2310)  koleo_loss: 0.0176 (0.0198)  ibot_loss: 2.7760 (2.7781)  time: 1.522135  data: 0.000167  max mem: 76387
I20250118 08:18:00 96 dinov2 helpers.py:102] Training  [    580/5000000]  eta: 100 days, 13:28:36  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8527 (13.8639)  dino_local_crops_loss: 9.8341 (9.8351)  dino_global_crops_loss: 1.2302 (1.2309)  koleo_loss: 0.0173 (0.0198)  ibot_loss: 2.7741 (2.7780)  time: 1.516911  data: 0.000190  max mem: 76387
I20250118 08:18:15 96 dinov2 helpers.py:102] Training  [    590/5000000]  eta: 100 days, 8:27:26  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8140 (13.8626)  dino_local_crops_loss: 9.7929 (9.8342)  dino_global_crops_loss: 1.2252 (1.2308)  koleo_loss: 0.0138 (0.0197)  ibot_loss: 2.7718 (2.7779)  time: 1.519587  data: 0.000199  max mem: 76387
I20250118 08:18:30 96 dinov2 helpers.py:102] Training  [    600/5000000]  eta: 100 days, 3:25:21  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7747 (13.8610)  dino_local_crops_loss: 9.7764 (9.8332)  dino_global_crops_loss: 1.2237 (1.2307)  koleo_loss: 0.0114 (0.0195)  ibot_loss: 2.7627 (2.7775)  time: 1.520556  data: 0.000196  max mem: 76387
I20250118 08:18:46 96 dinov2 helpers.py:102] Training  [    610/5000000]  eta: 99 days, 22:37:42  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7514 (13.8593)  dino_local_crops_loss: 9.7941 (9.8328)  dino_global_crops_loss: 1.2260 (1.2307)  koleo_loss: 0.0114 (0.0194)  ibot_loss: 2.7410 (2.7764)  time: 1.518286  data: 0.000219  max mem: 76387
I20250118 08:19:03 96 dinov2 helpers.py:102] Training  [    620/5000000]  eta: 99 days, 21:44:17  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7023 (13.8563)  dino_local_crops_loss: 9.7995 (9.8322)  dino_global_crops_loss: 1.2262 (1.2306)  koleo_loss: 0.0137 (0.0193)  ibot_loss: 2.6732 (2.7742)  time: 1.603787  data: 0.000267  max mem: 76387
I20250118 08:19:18 96 dinov2 helpers.py:102] Training  [    630/5000000]  eta: 99 days, 17:18:52  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.6808 (13.8535)  dino_local_crops_loss: 9.8055 (9.8320)  dino_global_crops_loss: 1.2265 (1.2305)  koleo_loss: 0.0143 (0.0192)  ibot_loss: 2.6247 (2.7717)  time: 1.606716  data: 0.000304  max mem: 76387
I20250118 08:19:33 96 dinov2 helpers.py:102] Training  [    640/5000000]  eta: 99 days, 12:58:15  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7005 (13.8514)  dino_local_crops_loss: 9.8332 (9.8323)  dino_global_crops_loss: 1.2296 (1.2306)  koleo_loss: 0.0145 (0.0192)  ibot_loss: 2.6162 (2.7694)  time: 1.524468  data: 0.000273  max mem: 76387
I20250118 08:19:48 96 dinov2 helpers.py:102] Training  [    650/5000000]  eta: 99 days, 8:46:08  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7240 (13.8498)  dino_local_crops_loss: 9.8599 (9.8329)  dino_global_crops_loss: 1.2326 (1.2306)  koleo_loss: 0.0148 (0.0191)  ibot_loss: 2.6241 (2.7672)  time: 1.523329  data: 0.000275  max mem: 76387
I20250118 08:20:03 96 dinov2 helpers.py:102] Training  [    660/5000000]  eta: 99 days, 4:32:54  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7510 (13.8485)  dino_local_crops_loss: 9.8513 (9.8332)  dino_global_crops_loss: 1.2326 (1.2306)  koleo_loss: 0.0147 (0.0190)  ibot_loss: 2.6409 (2.7656)  time: 1.520059  data: 0.000293  max mem: 76387
I20250118 08:20:19 96 dinov2 helpers.py:102] Training  [    670/5000000]  eta: 99 days, 0:38:51  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7706 (13.8480)  dino_local_crops_loss: 9.8503 (9.8337)  dino_global_crops_loss: 1.2328 (1.2307)  koleo_loss: 0.0149 (0.0190)  ibot_loss: 2.6790 (2.7645)  time: 1.521277  data: 0.000282  max mem: 76387
I20250118 08:20:34 96 dinov2 helpers.py:102] Training  [    680/5000000]  eta: 98 days, 20:56:19  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8117 (13.8474)  dino_local_crops_loss: 9.8527 (9.8339)  dino_global_crops_loss: 1.2334 (1.2307)  koleo_loss: 0.0149 (0.0189)  ibot_loss: 2.7040 (2.7638)  time: 1.527867  data: 0.000229  max mem: 76387
I20250118 08:20:49 96 dinov2 helpers.py:102] Training  [    690/5000000]  eta: 98 days, 17:16:08  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8097 (13.8468)  dino_local_crops_loss: 9.8370 (9.8339)  dino_global_crops_loss: 1.2336 (1.2308)  koleo_loss: 0.0128 (0.0188)  ibot_loss: 2.7233 (2.7633)  time: 1.528077  data: 0.000200  max mem: 76387
I20250118 08:21:05 96 dinov2 helpers.py:102] Training  [    700/5000000]  eta: 98 days, 13:40:15  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8097 (13.8462)  dino_local_crops_loss: 9.8270 (9.8337)  dino_global_crops_loss: 1.2325 (1.2308)  koleo_loss: 0.0115 (0.0187)  ibot_loss: 2.7333 (2.7630)  time: 1.525554  data: 0.000227  max mem: 76387
I20250118 08:21:20 96 dinov2 helpers.py:102] Training  [    710/5000000]  eta: 98 days, 10:13:45  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8102 (13.8459)  dino_local_crops_loss: 9.8207 (9.8336)  dino_global_crops_loss: 1.2325 (1.2308)  koleo_loss: 0.0102 (0.0186)  ibot_loss: 2.7452 (2.7629)  time: 1.526136  data: 0.000199  max mem: 76387
I20250118 08:21:35 96 dinov2 helpers.py:102] Training  [    720/5000000]  eta: 98 days, 6:45:08  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8148 (13.8455)  dino_local_crops_loss: 9.8208 (9.8336)  dino_global_crops_loss: 1.2352 (1.2309)  koleo_loss: 0.0106 (0.0185)  ibot_loss: 2.7446 (2.7626)  time: 1.524164  data: 0.000195  max mem: 76387
I20250118 08:21:50 96 dinov2 helpers.py:102] Training  [    730/5000000]  eta: 98 days, 3:18:25  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7993 (13.8446)  dino_local_crops_loss: 9.8081 (9.8331)  dino_global_crops_loss: 1.2384 (1.2310)  koleo_loss: 0.0106 (0.0184)  ibot_loss: 2.7369 (2.7621)  time: 1.519103  data: 0.000201  max mem: 76387
I20250118 08:22:05 96 dinov2 helpers.py:102] Training  [    740/5000000]  eta: 98 days, 0:02:23  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7699 (13.8434)  dino_local_crops_loss: 9.7983 (9.8326)  dino_global_crops_loss: 1.2402 (1.2312)  koleo_loss: 0.0090 (0.0182)  ibot_loss: 2.7204 (2.7614)  time: 1.519706  data: 0.000176  max mem: 76387
I20250118 08:22:21 96 dinov2 helpers.py:102] Training  [    750/5000000]  eta: 97 days, 20:54:02  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7317 (13.8415)  dino_local_crops_loss: 9.7855 (9.8318)  dino_global_crops_loss: 1.2390 (1.2312)  koleo_loss: 0.0069 (0.0181)  ibot_loss: 2.7032 (2.7604)  time: 1.523097  data: 0.000171  max mem: 76387
I20250118 08:22:36 96 dinov2 helpers.py:102] Training  [    760/5000000]  eta: 97 days, 17:42:59  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.6508 (13.8383)  dino_local_crops_loss: 9.7439 (9.8304)  dino_global_crops_loss: 1.2363 (1.2313)  koleo_loss: 0.0059 (0.0179)  ibot_loss: 2.6647 (2.7587)  time: 1.520721  data: 0.000195  max mem: 76387
I20250118 08:22:51 96 dinov2 helpers.py:102] Training  [    770/5000000]  eta: 97 days, 14:49:37  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.5308 (13.8337)  dino_local_crops_loss: 9.7104 (9.8286)  dino_global_crops_loss: 1.2347 (1.2313)  koleo_loss: 0.0059 (0.0178)  ibot_loss: 2.5915 (2.7560)  time: 1.523120  data: 0.000194  max mem: 76387
I20250118 08:23:06 96 dinov2 helpers.py:102] Training  [    780/5000000]  eta: 97 days, 11:52:26  lr: 0.0045 (0.0045)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.5178 (13.8303)  dino_local_crops_loss: 9.6618 (9.8259)  dino_global_crops_loss: 1.2288 (1.2312)  koleo_loss: 0.0071 (0.0178)  ibot_loss: 2.5733 (2.7554)  time: 1.525140  data: 0.000237  max mem: 76387
I20250118 08:23:19 96 dinov2 train.py:278] NaN detected
I20250118 08:26:08 96 dinov2 config.py:67] git:
  sha: 3aaebc0650e4cd8c86360f4040941ae711160c49, status: has uncommitted changes, branch: main

I20250118 08:26:08 96 dinov2 config.py:68] config_file: dinov2/configs/train/fmbc.yaml
eval: 
eval_only: False
local_rank: 6
no_resume: False
opts: ['train.dataset_path=TileDataset:split=TRAIN:root=/ruiyan/yuhao/data', 'train.output_dir=/ruiyan/yuhao/project/FMBC/dinov2/output']
output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
I20250118 08:26:08 96 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.00447213595499958
I20250118 08:26:08 96 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 160
  dataset_path: TileDataset:split=TRAIN:root=/ruiyan/yuhao/data
  output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
  saveckp_freq: 20
  seed: 0
  num_workers: 16
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 4000
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.00447213595499958
  warmup_epochs: 0
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250118 08:26:08 96 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250118 08:26:12 96 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 1024
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20250118 08:26:16 96 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_large network.
I20250118 08:26:17 96 dinov2 ssl_meta_arch.py:396] DISTRIBUTED FSDP -- preparing model for distributed training
I20250118 08:26:17 96 dinov2 train.py:307] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20250118 08:26:17 96 dinov2 param_groups.py:54] chunked fsdp
I20250118 08:26:17 96 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.01435795975383706, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.01435795975383706, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.norm1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.norm1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.attn.proj.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.attn.proj.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.ls1.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.norm2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.norm2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.3.ls2.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.norm1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.norm1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.attn.proj.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.attn.proj.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.ls1.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.norm2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.norm2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.4.ls2.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.norm1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.norm1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.attn.proj.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.attn.proj.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.ls1.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.norm2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.norm2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.0.5.ls2.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.norm1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.norm1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.attn.proj.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.attn.proj.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.ls1.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.norm2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.norm2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.6.ls2.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.norm1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.norm1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.attn.proj.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.attn.proj.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.ls1.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.norm2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.norm2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.7.ls2.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.norm1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.norm1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.attn.proj.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.attn.proj.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.ls1.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.norm2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.norm2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.8.ls2.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.norm1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.norm1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.attn.proj.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.attn.proj.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.ls1.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.norm2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.norm2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.9.ls2.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.norm1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.norm1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.attn.proj.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.attn.proj.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.ls1.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.norm2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.norm2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.10.ls2.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.norm1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.norm1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.attn.proj.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.attn.proj.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.ls1.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.norm2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.norm2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.1.11.ls2.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.12.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.13.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.14.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.15.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.16.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.2.17.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.18.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.19.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.20.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.21.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.22.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] blocks.3.23.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250118 08:26:17 96 dinov2 param_groups.py:64] else code branch
I20250118 08:26:17 96 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 08:26:17 96 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250118 08:26:17 96 dinov2 train.py:106] Schedulers ready.
I20250118 08:26:17 96 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250118 08:26:17 96 dinov2 augmentations.py:34] ###################################
I20250118 08:26:17 96 dinov2 augmentations.py:35] Using data augmentation parameters:
I20250118 08:26:17 96 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20250118 08:26:17 96 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20250118 08:26:17 96 dinov2 augmentations.py:38] local_crops_number: 8
I20250118 08:26:17 96 dinov2 augmentations.py:39] global_crops_size: 224
I20250118 08:26:17 96 dinov2 augmentations.py:40] local_crops_size: 96
I20250118 08:26:17 96 dinov2 augmentations.py:41] ###################################
I20250118 08:26:17 96 dinov2 loaders.py:86] using dataset: "TileDataset:split=TRAIN:root=/ruiyan/yuhao/data"
I20250118 08:27:23 96 dinov2 config.py:67] git:
  sha: 3aaebc0650e4cd8c86360f4040941ae711160c49, status: has uncommitted changes, branch: main

I20250118 08:27:23 96 dinov2 config.py:68] config_file: dinov2/configs/train/fmbc.yaml
eval: 
eval_only: False
local_rank: 6
no_resume: False
opts: ['train.dataset_path=TileDataset:split=TRAIN:root=/ruiyan/yuhao/data', 'train.output_dir=/ruiyan/yuhao/project/FMBC/dinov2/output']
output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
I20250118 08:27:23 96 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.00447213595499958
I20250118 08:27:23 96 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp16
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 160
  dataset_path: TileDataset:split=TRAIN:root=/ruiyan/yuhao/data
  output_dir: /ruiyan/yuhao/project/FMBC/dinov2/output
  saveckp_freq: 20
  seed: 0
  num_workers: 16
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.994
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 4000
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.00447213595499958
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250118 08:27:23 96 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250118 08:27:27 96 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250118 08:27:31 96 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 1024
I20250118 08:27:31 96 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20250118 08:27:31 96 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20250118 08:27:31 96 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20250118 08:27:31 96 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20250118 08:27:31 96 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20250118 08:27:31 96 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20250118 08:27:32 96 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20250118 08:27:32 96 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20250118 08:27:32 96 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20250118 08:27:32 96 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20250118 08:27:32 96 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20250118 08:27:32 96 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_large network.
I20250118 08:27:32 96 dinov2 ssl_meta_arch.py:396] DISTRIBUTED FSDP -- preparing model for distributed training
I20250118 08:27:32 96 dinov2 train.py:307] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20250118 08:27:32 96 dinov2 param_groups.py:54] chunked fsdp
I20250118 08:27:32 96 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.01435795975383706, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.01435795975383706, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.norm1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.norm1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.attn.proj.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.attn.proj.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.ls1.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.norm2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.norm2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.3.ls2.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.norm1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.norm1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.attn.proj.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.attn.proj.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.ls1.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.norm2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.norm2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.4.ls2.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.norm1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.norm1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.attn.proj.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.attn.proj.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.ls1.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.norm2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.norm2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.0.5.ls2.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.norm1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.norm1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.attn.proj.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.attn.proj.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.ls1.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.norm2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.norm2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.6.ls2.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.norm1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.norm1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.attn.proj.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.attn.proj.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.ls1.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.norm2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.norm2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.7.ls2.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.norm1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.norm1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.attn.proj.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.attn.proj.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.ls1.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.norm2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.norm2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.8.ls2.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.norm1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.norm1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.attn.proj.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.attn.proj.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.ls1.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.norm2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.norm2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.9.ls2.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.norm1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.norm1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.attn.proj.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.attn.proj.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.ls1.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.norm2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.norm2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.10.ls2.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.norm1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.norm1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.attn.proj.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.attn.proj.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.ls1.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.norm2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.norm2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.1.11.ls2.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.12.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.13.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.14.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.15.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.16.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.2.17.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.18.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.19.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.20.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.21.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.22.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] blocks.3.23.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250118 08:27:32 96 dinov2 param_groups.py:64] else code branch
I20250118 08:27:32 96 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20250118 08:27:32 96 dinov2 ssl_meta_arch.py:383] fusing param groups
I20250118 08:27:33 96 dinov2 train.py:106] Schedulers ready.
I20250118 08:27:33 96 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250118 08:27:33 96 dinov2 augmentations.py:34] ###################################
I20250118 08:27:33 96 dinov2 augmentations.py:35] Using data augmentation parameters:
I20250118 08:27:33 96 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20250118 08:27:33 96 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20250118 08:27:33 96 dinov2 augmentations.py:38] local_crops_number: 8
I20250118 08:27:33 96 dinov2 augmentations.py:39] global_crops_size: 224
I20250118 08:27:33 96 dinov2 augmentations.py:40] local_crops_size: 96
I20250118 08:27:33 96 dinov2 augmentations.py:41] ###################################
I20250118 08:27:33 96 dinov2 loaders.py:86] using dataset: "TileDataset:split=TRAIN:root=/ruiyan/yuhao/data"
I20250118 08:36:03 96 dinov2 loaders.py:91] # of dataset samples: 95,954,228
I20250118 08:36:03 96 dinov2 loaders.py:124] sampler: sharded infinite
I20250118 08:36:03 96 dinov2 loaders.py:208] using PyTorch data loader
I20250118 08:36:03 96 dinov2 loaders.py:223] infinite data loader
I20250118 08:36:03 96 dinov2 train.py:221] Starting training from iteration 0
I20250118 08:37:49 96 dinov2 helpers.py:102] Training  [      0/5000000]  eta: 6119 days, 8:30:20  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7307 (13.7307)  dino_local_crops_loss: 9.1555 (9.1555)  dino_global_crops_loss: 1.1444 (1.1444)  koleo_loss: 0.6870 (0.6870)  ibot_loss: 2.7437 (2.7437)  time: 105.742447  data: 84.822212  max mem: 76057
I20250118 08:38:13 96 dinov2 helpers.py:102] Training  [     10/5000000]  eta: 680 days, 5:03:38  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 14.1703 (14.1294)  dino_local_crops_loss: 9.5172 (9.4874)  dino_global_crops_loss: 1.1896 (1.1859)  koleo_loss: 0.6870 (0.6864)  ibot_loss: 2.7721 (2.7696)  time: 11.754067  data: 7.711278  max mem: 76373
I20250118 08:38:33 96 dinov2 helpers.py:102] Training  [     20/5000000]  eta: 412 days, 1:24:09  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 14.4105 (14.3171)  dino_local_crops_loss: 9.7285 (9.6619)  dino_global_crops_loss: 1.2161 (1.2077)  koleo_loss: 0.6777 (0.6647)  ibot_loss: 2.7883 (2.7828)  time: 2.189296  data: 0.000177  max mem: 76380
I20250118 08:38:48 96 dinov2 helpers.py:102] Training  [     30/5000000]  eta: 307 days, 23:10:41  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 14.5518 (14.3962)  dino_local_crops_loss: 9.9251 (9.7600)  dino_global_crops_loss: 1.2406 (1.2200)  koleo_loss: 0.5928 (0.6261)  ibot_loss: 2.8021 (2.7902)  time: 1.783867  data: 0.000152  max mem: 76380
I20250118 08:39:04 96 dinov2 helpers.py:102] Training  [     40/5000000]  eta: 254 days, 11:54:03  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 14.5404 (14.4226)  dino_local_crops_loss: 9.9870 (9.8163)  dino_global_crops_loss: 1.2484 (1.2270)  koleo_loss: 0.4941 (0.5844)  ibot_loss: 2.8076 (2.7949)  time: 1.538916  data: 0.000414  max mem: 76380
I20250118 08:39:19 96 dinov2 helpers.py:102] Training  [     50/5000000]  eta: 221 days, 21:10:36  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 14.4580 (14.4225)  dino_local_crops_loss: 9.9857 (9.8475)  dino_global_crops_loss: 1.2482 (1.2309)  koleo_loss: 0.4153 (0.5464)  ibot_loss: 2.8089 (2.7976)  time: 1.528518  data: 0.000425  max mem: 76383
I20250118 08:39:36 96 dinov2 helpers.py:102] Training  [     60/5000000]  eta: 201 days, 11:06:24  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 14.3822 (14.4117)  dino_local_crops_loss: 9.9622 (9.8645)  dino_global_crops_loss: 1.2453 (1.2331)  koleo_loss: 0.3687 (0.5154)  ibot_loss: 2.8063 (2.7987)  time: 1.602688  data: 0.000158  max mem: 76383
I20250118 08:39:51 96 dinov2 helpers.py:102] Training  [     70/5000000]  eta: 185 days, 11:58:27  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 14.3182 (14.3932)  dino_local_crops_loss: 9.9388 (9.8737)  dino_global_crops_loss: 1.2424 (1.2342)  koleo_loss: 0.3352 (0.4866)  ibot_loss: 2.8015 (2.7986)  time: 1.602283  data: 0.000162  max mem: 76383
I20250118 08:40:06 96 dinov2 helpers.py:102] Training  [     80/5000000]  eta: 173 days, 11:42:04  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 14.2306 (14.3679)  dino_local_crops_loss: 9.9193 (9.8784)  dino_global_crops_loss: 1.2399 (1.2348)  koleo_loss: 0.2791 (0.4575)  ibot_loss: 2.7928 (2.7971)  time: 1.523525  data: 0.000162  max mem: 76383
I20250118 08:40:23 96 dinov2 helpers.py:102] Training  [     90/5000000]  eta: 165 days, 4:37:58  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 14.1328 (14.3364)  dino_local_crops_loss: 9.9039 (9.8806)  dino_global_crops_loss: 1.2380 (1.2351)  koleo_loss: 0.2131 (0.4268)  ibot_loss: 2.7779 (2.7938)  time: 1.608965  data: 0.000155  max mem: 76387
I20250118 08:40:40 96 dinov2 helpers.py:102] Training  [    100/5000000]  eta: 158 days, 12:45:10  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 14.0152 (14.2988)  dino_local_crops_loss: 9.8922 (9.8811)  dino_global_crops_loss: 1.2365 (1.2351)  koleo_loss: 0.1322 (0.3934)  ibot_loss: 2.7543 (2.7892)  time: 1.692812  data: 0.000158  max mem: 76387
I20250118 08:40:55 96 dinov2 helpers.py:102] Training  [    110/5000000]  eta: 152 days, 5:35:42  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8909 (14.2583)  dino_local_crops_loss: 9.8687 (9.8778)  dino_global_crops_loss: 1.2339 (1.2348)  koleo_loss: 0.0510 (0.3619)  ibot_loss: 2.7373 (2.7839)  time: 1.611717  data: 0.000168  max mem: 76387
I20250118 08:41:12 96 dinov2 helpers.py:102] Training  [    120/5000000]  eta: 147 days, 18:10:25  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8036 (14.2189)  dino_local_crops_loss: 9.8200 (9.8722)  dino_global_crops_loss: 1.2277 (1.2341)  koleo_loss: 0.0338 (0.3343)  ibot_loss: 2.7221 (2.7784)  time: 1.613146  data: 0.000161  max mem: 76387
I20250118 08:41:28 96 dinov2 helpers.py:102] Training  [    130/5000000]  eta: 143 days, 5:41:08  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7629 (14.1837)  dino_local_crops_loss: 9.8057 (9.8671)  dino_global_crops_loss: 1.2260 (1.2334)  koleo_loss: 0.0221 (0.3102)  ibot_loss: 2.7117 (2.7730)  time: 1.612460  data: 0.000151  max mem: 76387
I20250118 08:41:43 96 dinov2 helpers.py:102] Training  [    140/5000000]  eta: 139 days, 9:39:59  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7613 (14.1541)  dino_local_crops_loss: 9.8096 (9.8637)  dino_global_crops_loss: 1.2266 (1.2331)  koleo_loss: 0.0155 (0.2892)  ibot_loss: 2.7059 (2.7682)  time: 1.535575  data: 0.000147  max mem: 76387
I20250118 08:41:58 96 dinov2 helpers.py:102] Training  [    150/5000000]  eta: 136 days, 0:55:09  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7728 (14.1296)  dino_local_crops_loss: 9.8278 (9.8620)  dino_global_crops_loss: 1.2292 (1.2329)  koleo_loss: 0.0120 (0.2707)  ibot_loss: 2.7040 (2.7639)  time: 1.536087  data: 0.000165  max mem: 76387
I20250118 08:42:14 96 dinov2 helpers.py:102] Training  [    160/5000000]  eta: 133 days, 2:14:10  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7934 (14.1095)  dino_local_crops_loss: 9.8485 (9.8619)  dino_global_crops_loss: 1.2321 (1.2329)  koleo_loss: 0.0088 (0.2543)  ibot_loss: 2.7047 (2.7603)  time: 1.531307  data: 0.000192  max mem: 76387
I20250118 08:42:29 96 dinov2 helpers.py:102] Training  [    170/5000000]  eta: 130 days, 11:45:44  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8144 (14.0929)  dino_local_crops_loss: 9.8676 (9.8627)  dino_global_crops_loss: 1.2344 (1.2331)  koleo_loss: 0.0061 (0.2398)  ibot_loss: 2.7073 (2.7574)  time: 1.531150  data: 0.000175  max mem: 76387
I20250118 08:42:44 96 dinov2 helpers.py:102] Training  [    180/5000000]  eta: 128 days, 4:18:36  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8351 (14.0793)  dino_local_crops_loss: 9.8836 (9.8643)  dino_global_crops_loss: 1.2362 (1.2333)  koleo_loss: 0.0037 (0.2267)  ibot_loss: 2.7116 (2.7550)  time: 1.531573  data: 0.000163  max mem: 76387
I20250118 08:43:00 96 dinov2 helpers.py:102] Training  [    190/5000000]  eta: 126 days, 2:37:09  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8538 (14.0679)  dino_local_crops_loss: 9.8965 (9.8663)  dino_global_crops_loss: 1.2376 (1.2335)  koleo_loss: 0.0016 (0.2148)  ibot_loss: 2.7175 (2.7532)  time: 1.532042  data: 0.000166  max mem: 76387
I20250118 08:43:15 96 dinov2 helpers.py:102] Training  [    200/5000000]  eta: 124 days, 5:34:51  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8675 (14.0584)  dino_local_crops_loss: 9.9065 (9.8685)  dino_global_crops_loss: 1.2387 (1.2338)  koleo_loss: -0.0000 (0.2041)  ibot_loss: 2.7238 (2.7519)  time: 1.529624  data: 0.000185  max mem: 76387
I20250118 08:43:30 96 dinov2 helpers.py:102] Training  [    210/5000000]  eta: 122 days, 13:08:38  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8823 (14.0502)  dino_local_crops_loss: 9.9145 (9.8708)  dino_global_crops_loss: 1.2396 (1.2341)  koleo_loss: -0.0017 (0.1943)  ibot_loss: 2.7288 (2.7510)  time: 1.530043  data: 0.000205  max mem: 76387
I20250118 08:43:46 96 dinov2 helpers.py:102] Training  [    220/5000000]  eta: 121 days, 0:43:15  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8907 (14.0433)  dino_local_crops_loss: 9.9209 (9.8732)  dino_global_crops_loss: 1.2404 (1.2344)  koleo_loss: -0.0033 (0.1854)  ibot_loss: 2.7331 (2.7503)  time: 1.535394  data: 0.000173  max mem: 76387
I20250118 08:44:01 96 dinov2 helpers.py:102] Training  [    230/5000000]  eta: 119 days, 15:17:25  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8981 (14.0372)  dino_local_crops_loss: 9.9255 (9.8756)  dino_global_crops_loss: 1.2410 (1.2347)  koleo_loss: -0.0046 (0.1771)  ibot_loss: 2.7366 (2.7498)  time: 1.536879  data: 0.000199  max mem: 76387
I20250118 08:44:16 96 dinov2 helpers.py:102] Training  [    240/5000000]  eta: 118 days, 8:20:26  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9068 (14.0319)  dino_local_crops_loss: 9.9295 (9.8779)  dino_global_crops_loss: 1.2415 (1.2350)  koleo_loss: -0.0060 (0.1695)  ibot_loss: 2.7413 (2.7495)  time: 1.533002  data: 0.000202  max mem: 76387
I20250118 08:44:32 96 dinov2 helpers.py:102] Training  [    250/5000000]  eta: 117 days, 4:07:42  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9129 (14.0273)  dino_local_crops_loss: 9.9325 (9.8801)  dino_global_crops_loss: 1.2418 (1.2353)  koleo_loss: -0.0066 (0.1625)  ibot_loss: 2.7452 (2.7494)  time: 1.532914  data: 0.000166  max mem: 76387
I20250118 08:44:49 96 dinov2 helpers.py:102] Training  [    260/5000000]  eta: 116 days, 10:34:55  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9178 (14.0232)  dino_local_crops_loss: 9.9350 (9.8823)  dino_global_crops_loss: 1.2421 (1.2355)  koleo_loss: -0.0073 (0.1560)  ibot_loss: 2.7479 (2.7495)  time: 1.615278  data: 0.000184  max mem: 76387
I20250118 08:45:04 96 dinov2 helpers.py:102] Training  [    270/5000000]  eta: 115 days, 10:17:19  lr: 0.0001 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9227 (14.0196)  dino_local_crops_loss: 9.9366 (9.8843)  dino_global_crops_loss: 1.2423 (1.2358)  koleo_loss: -0.0084 (0.1499)  ibot_loss: 2.7518 (2.7496)  time: 1.616732  data: 0.000401  max mem: 76387
I20250118 08:45:19 96 dinov2 helpers.py:102] Training  [    280/5000000]  eta: 114 days, 11:22:37  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9249 (14.0163)  dino_local_crops_loss: 9.9379 (9.8862)  dino_global_crops_loss: 1.2424 (1.2360)  koleo_loss: -0.0093 (0.1442)  ibot_loss: 2.7538 (2.7498)  time: 1.534765  data: 0.000382  max mem: 76387
I20250118 08:45:35 96 dinov2 helpers.py:102] Training  [    290/5000000]  eta: 113 days, 14:12:55  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9275 (14.0132)  dino_local_crops_loss: 9.9385 (9.8880)  dino_global_crops_loss: 1.2425 (1.2363)  koleo_loss: -0.0102 (0.1389)  ibot_loss: 2.7564 (2.7501)  time: 1.533094  data: 0.000149  max mem: 76387
I20250118 08:45:50 96 dinov2 helpers.py:102] Training  [    300/5000000]  eta: 112 days, 18:07:01  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9285 (14.0104)  dino_local_crops_loss: 9.9387 (9.8897)  dino_global_crops_loss: 1.2425 (1.2365)  koleo_loss: -0.0110 (0.1339)  ibot_loss: 2.7582 (2.7504)  time: 1.531223  data: 0.000155  max mem: 76387
I20250118 08:46:05 96 dinov2 helpers.py:102] Training  [    310/5000000]  eta: 111 days, 23:50:42  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9293 (14.0078)  dino_local_crops_loss: 9.9377 (9.8912)  dino_global_crops_loss: 1.2424 (1.2366)  koleo_loss: -0.0119 (0.1292)  ibot_loss: 2.7607 (2.7508)  time: 1.533492  data: 0.000249  max mem: 76387
I20250118 08:46:21 96 dinov2 helpers.py:102] Training  [    320/5000000]  eta: 111 days, 6:22:57  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9275 (14.0053)  dino_local_crops_loss: 9.9360 (9.8926)  dino_global_crops_loss: 1.2422 (1.2368)  koleo_loss: -0.0126 (0.1248)  ibot_loss: 2.7619 (2.7511)  time: 1.535674  data: 0.000246  max mem: 76387
I20250118 08:46:36 96 dinov2 helpers.py:102] Training  [    330/5000000]  eta: 110 days, 13:39:58  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9234 (14.0027)  dino_local_crops_loss: 9.9324 (9.8937)  dino_global_crops_loss: 1.2418 (1.2370)  koleo_loss: -0.0134 (0.1206)  ibot_loss: 2.7626 (2.7515)  time: 1.528194  data: 0.000157  max mem: 76387
I20250118 08:46:51 96 dinov2 helpers.py:102] Training  [    340/5000000]  eta: 109 days, 22:18:28  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9186 (14.0001)  dino_local_crops_loss: 9.9271 (9.8946)  dino_global_crops_loss: 1.2412 (1.2371)  koleo_loss: -0.0141 (0.1166)  ibot_loss: 2.7642 (2.7519)  time: 1.529150  data: 0.000147  max mem: 76387
I20250118 08:47:07 96 dinov2 helpers.py:102] Training  [    350/5000000]  eta: 109 days, 7:59:53  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.9089 (13.9975)  dino_local_crops_loss: 9.9195 (9.8952)  dino_global_crops_loss: 1.2403 (1.2372)  koleo_loss: -0.0148 (0.1129)  ibot_loss: 2.7648 (2.7522)  time: 1.535988  data: 0.000148  max mem: 76387
I20250118 08:47:22 96 dinov2 helpers.py:102] Training  [    360/5000000]  eta: 108 days, 18:14:55  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8983 (13.9946)  dino_local_crops_loss: 9.9106 (9.8955)  dino_global_crops_loss: 1.2395 (1.2372)  koleo_loss: -0.0155 (0.1093)  ibot_loss: 2.7652 (2.7526)  time: 1.535167  data: 0.000163  max mem: 76387
I20250118 08:47:37 96 dinov2 helpers.py:102] Training  [    370/5000000]  eta: 108 days, 5:20:27  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8874 (13.9916)  dino_local_crops_loss: 9.8997 (9.8955)  dino_global_crops_loss: 1.2384 (1.2372)  koleo_loss: -0.0159 (0.1059)  ibot_loss: 2.7653 (2.7530)  time: 1.533489  data: 0.000164  max mem: 76387
I20250118 08:47:53 96 dinov2 helpers.py:102] Training  [    380/5000000]  eta: 107 days, 17:04:41  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8745 (13.9883)  dino_local_crops_loss: 9.8880 (9.8951)  dino_global_crops_loss: 1.2371 (1.2372)  koleo_loss: -0.0164 (0.1027)  ibot_loss: 2.7652 (2.7533)  time: 1.534393  data: 0.000165  max mem: 76387
I20250118 08:48:08 96 dinov2 helpers.py:102] Training  [    390/5000000]  eta: 107 days, 5:33:35  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8575 (13.9848)  dino_local_crops_loss: 9.8753 (9.8945)  dino_global_crops_loss: 1.2358 (1.2371)  koleo_loss: -0.0169 (0.0996)  ibot_loss: 2.7644 (2.7535)  time: 1.535603  data: 0.000168  max mem: 76387
I20250118 08:48:23 96 dinov2 helpers.py:102] Training  [    400/5000000]  eta: 106 days, 18:36:51  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8405 (13.9810)  dino_local_crops_loss: 9.8606 (9.8935)  dino_global_crops_loss: 1.2343 (1.2371)  koleo_loss: -0.0173 (0.0967)  ibot_loss: 2.7629 (2.7538)  time: 1.537231  data: 0.000184  max mem: 76387
I20250118 08:48:39 96 dinov2 helpers.py:102] Training  [    410/5000000]  eta: 106 days, 8:13:11  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8268 (13.9770)  dino_local_crops_loss: 9.8490 (9.8922)  dino_global_crops_loss: 1.2326 (1.2369)  koleo_loss: -0.0172 (0.0940)  ibot_loss: 2.7620 (2.7540)  time: 1.537488  data: 0.000181  max mem: 76387
I20250118 08:48:54 96 dinov2 helpers.py:102] Training  [    420/5000000]  eta: 105 days, 22:12:11  lr: 0.0001 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.8015 (13.9725)  dino_local_crops_loss: 9.8285 (9.8904)  dino_global_crops_loss: 1.2305 (1.2368)  koleo_loss: -0.0173 (0.0913)  ibot_loss: 2.7603 (2.7541)  time: 1.536008  data: 0.000157  max mem: 76387
I20250118 08:49:09 96 dinov2 helpers.py:102] Training  [    430/5000000]  eta: 105 days, 12:41:02  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7719 (13.9676)  dino_local_crops_loss: 9.8045 (9.8882)  dino_global_crops_loss: 1.2276 (1.2365)  koleo_loss: -0.0176 (0.0888)  ibot_loss: 2.7569 (2.7541)  time: 1.534764  data: 0.000157  max mem: 76387
I20250118 08:49:25 96 dinov2 helpers.py:102] Training  [    440/5000000]  eta: 105 days, 3:36:16  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7358 (13.9622)  dino_local_crops_loss: 9.7760 (9.8855)  dino_global_crops_loss: 1.2244 (1.2362)  koleo_loss: -0.0175 (0.0864)  ibot_loss: 2.7546 (2.7541)  time: 1.535407  data: 0.000155  max mem: 76387
I20250118 08:49:40 96 dinov2 helpers.py:102] Training  [    450/5000000]  eta: 104 days, 18:50:44  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.7173 (13.9563)  dino_local_crops_loss: 9.7593 (9.8823)  dino_global_crops_loss: 1.2226 (1.2359)  koleo_loss: -0.0169 (0.0841)  ibot_loss: 2.7508 (2.7540)  time: 1.534203  data: 0.000151  max mem: 76387
I20250118 08:49:56 96 dinov2 helpers.py:102] Training  [    460/5000000]  eta: 104 days, 10:41:54  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.6702 (13.9495)  dino_local_crops_loss: 9.7232 (9.8784)  dino_global_crops_loss: 1.2180 (1.2354)  koleo_loss: -0.0172 (0.0819)  ibot_loss: 2.7480 (2.7538)  time: 1.536724  data: 0.000144  max mem: 76387
I20250118 08:50:11 96 dinov2 helpers.py:102] Training  [    470/5000000]  eta: 104 days, 2:45:54  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.6165 (13.9422)  dino_local_crops_loss: 9.6790 (9.8740)  dino_global_crops_loss: 1.2117 (1.2349)  koleo_loss: -0.0177 (0.0798)  ibot_loss: 2.7432 (2.7535)  time: 1.538337  data: 0.000162  max mem: 76387
I20250118 08:50:26 96 dinov2 helpers.py:102] Training  [    480/5000000]  eta: 103 days, 19:25:47  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.5864 (13.9346)  dino_local_crops_loss: 9.6596 (9.8693)  dino_global_crops_loss: 1.2085 (1.2343)  koleo_loss: -0.0177 (0.0777)  ibot_loss: 2.7389 (2.7532)  time: 1.540744  data: 0.000189  max mem: 76387
I20250118 08:50:42 96 dinov2 helpers.py:102] Training  [    490/5000000]  eta: 103 days, 12:05:26  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.5624 (13.9265)  dino_local_crops_loss: 9.6362 (9.8641)  dino_global_crops_loss: 1.2061 (1.2337)  koleo_loss: -0.0170 (0.0758)  ibot_loss: 2.7359 (2.7528)  time: 1.540042  data: 0.000169  max mem: 76387
I20250118 08:50:57 96 dinov2 helpers.py:102] Training  [    500/5000000]  eta: 103 days, 4:54:31  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.5099 (13.9179)  dino_local_crops_loss: 9.5976 (9.8586)  dino_global_crops_loss: 1.2004 (1.2330)  koleo_loss: -0.0173 (0.0740)  ibot_loss: 2.7328 (2.7524)  time: 1.532251  data: 0.000163  max mem: 76387
I20250118 08:51:12 96 dinov2 helpers.py:102] Training  [    510/5000000]  eta: 102 days, 22:02:25  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.4891 (13.9093)  dino_local_crops_loss: 9.5773 (9.8529)  dino_global_crops_loss: 1.1983 (1.2323)  koleo_loss: -0.0175 (0.0722)  ibot_loss: 2.7286 (2.7519)  time: 1.530410  data: 0.000173  max mem: 76387
I20250118 08:51:28 96 dinov2 helpers.py:102] Training  [    520/5000000]  eta: 102 days, 15:37:46  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.4540 (13.8999)  dino_local_crops_loss: 9.5515 (9.8467)  dino_global_crops_loss: 1.1943 (1.2315)  koleo_loss: -0.0178 (0.0704)  ibot_loss: 2.7257 (2.7513)  time: 1.534652  data: 0.000192  max mem: 76387
I20250118 08:51:43 96 dinov2 helpers.py:102] Training  [    530/5000000]  eta: 102 days, 9:15:05  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.3868 (13.8895)  dino_local_crops_loss: 9.4981 (9.8394)  dino_global_crops_loss: 1.1875 (1.2306)  koleo_loss: -0.0184 (0.0688)  ibot_loss: 2.7201 (2.7507)  time: 1.534299  data: 0.000201  max mem: 76387
I20250118 08:51:58 96 dinov2 helpers.py:102] Training  [    540/5000000]  eta: 102 days, 3:06:34  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.3067 (13.8781)  dino_local_crops_loss: 9.4322 (9.8313)  dino_global_crops_loss: 1.1794 (1.2296)  koleo_loss: -0.0185 (0.0672)  ibot_loss: 2.7168 (2.7500)  time: 1.530322  data: 0.000171  max mem: 76387
I20250118 08:52:15 96 dinov2 helpers.py:102] Training  [    550/5000000]  eta: 102 days, 1:23:24  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.2072 (13.8647)  dino_local_crops_loss: 9.3484 (9.8215)  dino_global_crops_loss: 1.1684 (1.2283)  koleo_loss: -0.0186 (0.0656)  ibot_loss: 2.7129 (2.7493)  time: 1.613653  data: 0.000172  max mem: 76387
I20250118 08:52:31 96 dinov2 helpers.py:102] Training  [    560/5000000]  eta: 101 days, 19:38:44  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.1061 (13.8508)  dino_local_crops_loss: 9.2568 (9.8111)  dino_global_crops_loss: 1.1578 (1.2270)  koleo_loss: -0.0190 (0.0641)  ibot_loss: 2.7093 (2.7486)  time: 1.614432  data: 0.000204  max mem: 76387
I20250118 08:52:46 96 dinov2 helpers.py:102] Training  [    570/5000000]  eta: 101 days, 14:06:20  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 13.0576 (13.8361)  dino_local_crops_loss: 9.2220 (9.8000)  dino_global_crops_loss: 1.1510 (1.2256)  koleo_loss: -0.0191 (0.0626)  ibot_loss: 2.7060 (2.7478)  time: 1.531964  data: 0.000189  max mem: 76387
I20250118 08:53:01 96 dinov2 helpers.py:102] Training  [    580/5000000]  eta: 101 days, 8:52:21  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.9808 (13.8213)  dino_local_crops_loss: 9.1525 (9.7889)  dino_global_crops_loss: 1.1439 (1.2242)  koleo_loss: -0.0189 (0.0612)  ibot_loss: 2.7021 (2.7470)  time: 1.534469  data: 0.000183  max mem: 76387
I20250118 08:53:17 96 dinov2 helpers.py:102] Training  [    590/5000000]  eta: 101 days, 4:00:29  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.9700 (13.8069)  dino_local_crops_loss: 9.1451 (9.7780)  dino_global_crops_loss: 1.1430 (1.2228)  koleo_loss: -0.0189 (0.0599)  ibot_loss: 2.6983 (2.7461)  time: 1.540982  data: 0.000174  max mem: 76387
I20250118 08:53:32 96 dinov2 helpers.py:102] Training  [    600/5000000]  eta: 100 days, 23:04:52  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.9606 (13.7927)  dino_local_crops_loss: 9.1419 (9.7674)  dino_global_crops_loss: 1.1412 (1.2214)  koleo_loss: -0.0193 (0.0586)  ibot_loss: 2.6949 (2.7453)  time: 1.540210  data: 0.000169  max mem: 76387
I20250118 08:53:47 96 dinov2 helpers.py:102] Training  [    610/5000000]  eta: 100 days, 18:20:52  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.9466 (13.7790)  dino_local_crops_loss: 9.1367 (9.7572)  dino_global_crops_loss: 1.1410 (1.2201)  koleo_loss: -0.0196 (0.0573)  ibot_loss: 2.6935 (2.7444)  time: 1.536077  data: 0.000211  max mem: 76387
I20250118 08:54:04 96 dinov2 helpers.py:102] Training  [    620/5000000]  eta: 100 days, 17:26:59  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.9416 (13.7654)  dino_local_crops_loss: 9.1336 (9.7470)  dino_global_crops_loss: 1.1396 (1.2188)  koleo_loss: -0.0196 (0.0560)  ibot_loss: 2.6899 (2.7435)  time: 1.619137  data: 0.000219  max mem: 76387
I20250118 08:54:20 96 dinov2 helpers.py:102] Training  [    630/5000000]  eta: 100 days, 13:02:16  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.9314 (13.7522)  dino_local_crops_loss: 9.1264 (9.7372)  dino_global_crops_loss: 1.1394 (1.2176)  koleo_loss: -0.0192 (0.0548)  ibot_loss: 2.6869 (2.7426)  time: 1.621002  data: 0.000204  max mem: 76387
I20250118 08:54:35 96 dinov2 helpers.py:102] Training  [    640/5000000]  eta: 100 days, 8:29:12  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.9052 (13.7391)  dino_local_crops_loss: 9.1004 (9.7274)  dino_global_crops_loss: 1.1365 (1.2163)  koleo_loss: -0.0194 (0.0537)  ibot_loss: 2.6842 (2.7417)  time: 1.534140  data: 0.000182  max mem: 76387
I20250118 08:54:51 96 dinov2 helpers.py:102] Training  [    650/5000000]  eta: 100 days, 4:19:54  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.8869 (13.7259)  dino_local_crops_loss: 9.0919 (9.7175)  dino_global_crops_loss: 1.1356 (1.2151)  koleo_loss: -0.0194 (0.0526)  ibot_loss: 2.6799 (2.7407)  time: 1.533771  data: 0.000180  max mem: 76387
I20250118 08:55:06 96 dinov2 helpers.py:102] Training  [    660/5000000]  eta: 100 days, 0:27:47  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.8689 (13.7130)  dino_local_crops_loss: 9.0755 (9.7079)  dino_global_crops_loss: 1.1342 (1.2139)  koleo_loss: -0.0192 (0.0515)  ibot_loss: 2.6764 (2.7397)  time: 1.543612  data: 0.000174  max mem: 76387
I20250118 08:55:21 96 dinov2 helpers.py:102] Training  [    670/5000000]  eta: 99 days, 20:14:51  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.8647 (13.7005)  dino_local_crops_loss: 9.0788 (9.6987)  dino_global_crops_loss: 1.1333 (1.2127)  koleo_loss: -0.0195 (0.0504)  ibot_loss: 2.6730 (2.7387)  time: 1.536268  data: 0.000158  max mem: 76387
I20250118 08:55:37 96 dinov2 helpers.py:102] Training  [    680/5000000]  eta: 99 days, 16:22:37  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.8823 (13.6882)  dino_local_crops_loss: 9.0966 (9.6897)  dino_global_crops_loss: 1.1351 (1.2115)  koleo_loss: -0.0197 (0.0494)  ibot_loss: 2.6694 (2.7376)  time: 1.530531  data: 0.000158  max mem: 76387
I20250118 08:55:52 96 dinov2 helpers.py:102] Training  [    690/5000000]  eta: 99 days, 12:41:19  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.8382 (13.6757)  dino_local_crops_loss: 9.0630 (9.6804)  dino_global_crops_loss: 1.1330 (1.2103)  koleo_loss: -0.0199 (0.0484)  ibot_loss: 2.6664 (2.7366)  time: 1.537707  data: 0.000179  max mem: 76387
I20250118 08:56:07 96 dinov2 helpers.py:102] Training  [    700/5000000]  eta: 99 days, 9:07:48  lr: 0.0002 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.8362 (13.6642)  dino_local_crops_loss: 9.0591 (9.6720)  dino_global_crops_loss: 1.1319 (1.2093)  koleo_loss: -0.0200 (0.0474)  ibot_loss: 2.6635 (2.7355)  time: 1.540074  data: 0.000175  max mem: 76387
I20250118 08:56:23 96 dinov2 helpers.py:102] Training  [    710/5000000]  eta: 99 days, 5:43:45  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.8444 (13.6524)  dino_local_crops_loss: 9.0736 (9.6634)  dino_global_crops_loss: 1.1322 (1.2082)  koleo_loss: -0.0202 (0.0465)  ibot_loss: 2.6603 (2.7344)  time: 1.542181  data: 0.000181  max mem: 76387
I20250118 08:56:38 96 dinov2 helpers.py:102] Training  [    720/5000000]  eta: 99 days, 2:19:06  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.8176 (13.6408)  dino_local_crops_loss: 9.0518 (9.6549)  dino_global_crops_loss: 1.1292 (1.2071)  koleo_loss: -0.0202 (0.0455)  ibot_loss: 2.6546 (2.7333)  time: 1.540952  data: 0.000183  max mem: 76387
I20250118 08:56:54 96 dinov2 helpers.py:102] Training  [    730/5000000]  eta: 98 days, 23:07:59  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.7948 (13.6290)  dino_local_crops_loss: 9.0375 (9.6463)  dino_global_crops_loss: 1.1270 (1.2060)  koleo_loss: -0.0202 (0.0446)  ibot_loss: 2.6490 (2.7321)  time: 1.541732  data: 0.000155  max mem: 76387
I20250118 08:57:09 96 dinov2 helpers.py:102] Training  [    740/5000000]  eta: 98 days, 19:48:57  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.7698 (13.6175)  dino_local_crops_loss: 9.0180 (9.6380)  dino_global_crops_loss: 1.1266 (1.2049)  koleo_loss: -0.0200 (0.0438)  ibot_loss: 2.6447 (2.7309)  time: 1.539408  data: 0.000161  max mem: 76387
I20250118 08:57:24 96 dinov2 helpers.py:102] Training  [    750/5000000]  eta: 98 days, 16:45:23  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.7787 (13.6061)  dino_local_crops_loss: 9.0267 (9.6297)  dino_global_crops_loss: 1.1266 (1.2038)  koleo_loss: -0.0199 (0.0429)  ibot_loss: 2.6375 (2.7296)  time: 1.538175  data: 0.000162  max mem: 76387
I20250118 08:57:40 96 dinov2 helpers.py:102] Training  [    760/5000000]  eta: 98 days, 13:36:54  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.7383 (13.5942)  dino_local_crops_loss: 8.9987 (9.6211)  dino_global_crops_loss: 1.1237 (1.2027)  koleo_loss: -0.0199 (0.0421)  ibot_loss: 2.6327 (2.7283)  time: 1.538316  data: 0.000161  max mem: 76387
I20250118 08:57:55 96 dinov2 helpers.py:102] Training  [    770/5000000]  eta: 98 days, 10:40:23  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.6966 (13.5825)  dino_local_crops_loss: 8.9776 (9.6127)  dino_global_crops_loss: 1.1215 (1.2017)  koleo_loss: -0.0199 (0.0413)  ibot_loss: 2.6217 (2.7269)  time: 1.537150  data: 0.000341  max mem: 76387
I20250118 08:58:11 96 dinov2 helpers.py:102] Training  [    780/5000000]  eta: 98 days, 7:36:31  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.6712 (13.5706)  dino_local_crops_loss: 8.9545 (9.6042)  dino_global_crops_loss: 1.1183 (1.2006)  koleo_loss: -0.0197 (0.0405)  ibot_loss: 2.6121 (2.7253)  time: 1.534864  data: 0.000335  max mem: 76387
I20250118 08:58:26 96 dinov2 helpers.py:102] Training  [    790/5000000]  eta: 98 days, 4:41:55  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.6157 (13.5584)  dino_local_crops_loss: 8.9207 (9.5956)  dino_global_crops_loss: 1.1139 (1.1995)  koleo_loss: -0.0196 (0.0398)  ibot_loss: 2.5978 (2.7236)  time: 1.531502  data: 0.000153  max mem: 76387
I20250118 08:58:41 96 dinov2 helpers.py:102] Training  [    800/5000000]  eta: 98 days, 1:56:31  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.5745 (13.5461)  dino_local_crops_loss: 8.9041 (9.5869)  dino_global_crops_loss: 1.1099 (1.1984)  koleo_loss: -0.0193 (0.0390)  ibot_loss: 2.5814 (2.7217)  time: 1.536028  data: 0.000169  max mem: 76387
I20250118 08:58:57 96 dinov2 helpers.py:102] Training  [    810/5000000]  eta: 97 days, 23:15:44  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.5216 (13.5330)  dino_local_crops_loss: 8.8664 (9.5777)  dino_global_crops_loss: 1.1056 (1.1972)  koleo_loss: -0.0193 (0.0383)  ibot_loss: 2.5647 (2.7197)  time: 1.538613  data: 0.000394  max mem: 76387
I20250118 08:59:12 96 dinov2 helpers.py:102] Training  [    820/5000000]  eta: 97 days, 20:25:25  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.4622 (13.5192)  dino_local_crops_loss: 8.8135 (9.5680)  dino_global_crops_loss: 1.0993 (1.1959)  koleo_loss: -0.0191 (0.0376)  ibot_loss: 2.5545 (2.7177)  time: 1.532259  data: 0.000397  max mem: 76387
I20250118 08:59:27 96 dinov2 helpers.py:102] Training  [    830/5000000]  eta: 97 days, 17:32:33  lr: 0.0003 (0.0001)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.2868 (13.5034)  dino_local_crops_loss: 8.6926 (9.5565)  dino_global_crops_loss: 1.0836 (1.1945)  koleo_loss: -0.0188 (0.0369)  ibot_loss: 2.5407 (2.7155)  time: 1.522332  data: 0.000176  max mem: 76387
I20250118 08:59:42 96 dinov2 helpers.py:102] Training  [    840/5000000]  eta: 97 days, 15:02:21  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 12.0652 (13.4845)  dino_local_crops_loss: 8.5171 (9.5425)  dino_global_crops_loss: 1.0608 (1.1927)  koleo_loss: -0.0187 (0.0363)  ibot_loss: 2.5290 (2.7131)  time: 1.528377  data: 0.000171  max mem: 76387
I20250118 08:59:58 96 dinov2 helpers.py:102] Training  [    850/5000000]  eta: 97 days, 12:39:06  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 11.8210 (13.4632)  dino_local_crops_loss: 8.2904 (9.5263)  dino_global_crops_loss: 1.0318 (1.1906)  koleo_loss: -0.0190 (0.0356)  ibot_loss: 2.5098 (2.7107)  time: 1.539498  data: 0.000181  max mem: 76387
I20250118 09:00:13 96 dinov2 helpers.py:102] Training  [    860/5000000]  eta: 97 days, 10:11:46  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 11.5219 (13.4399)  dino_local_crops_loss: 8.0398 (9.5082)  dino_global_crops_loss: 1.0005 (1.1883)  koleo_loss: -0.0190 (0.0350)  ibot_loss: 2.5084 (2.7084)  time: 1.537422  data: 0.000172  max mem: 76387
I20250118 09:00:29 96 dinov2 helpers.py:102] Training  [    870/5000000]  eta: 97 days, 7:48:28  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 11.4078 (13.4160)  dino_local_crops_loss: 7.8354 (9.4884)  dino_global_crops_loss: 0.9759 (1.1857)  koleo_loss: -0.0175 (0.0344)  ibot_loss: 2.5178 (2.7074)  time: 1.533938  data: 0.000156  max mem: 76387
I20250118 09:00:44 96 dinov2 helpers.py:102] Training  [    880/5000000]  eta: 97 days, 5:34:54  lr: 0.0003 (0.0002)  wd: 0.0400 (0.0400)  mom: 0.9940 (0.9940)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 160.0000 (160.0000)  total_loss: 11.3514 (13.3925)  dino_local_crops_loss: 7.7420 (9.4682)  dino_global_crops_loss: 0.9607 (1.1831)  koleo_loss: -0.0173 (0.0338)  ibot_loss: 2.6931 (2.7074)  time: 1.537717  data: 0.000182  max mem: 76387
