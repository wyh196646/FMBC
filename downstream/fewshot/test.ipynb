{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.datasets import make_classification\n",
    "from uni.downstream.eval_patch_features.fewshot import eval_knn, eval_fewshot\n",
    "\n",
    "\n",
    "class H5Dataset():\n",
    "    def __init__(self, feature_dirs, label_csv):\n",
    "        self.feature_dirs = feature_dirs\n",
    "        self.features, self.labels = self.load_data(label_csv)\n",
    "\n",
    "    def read_assets_from_h5(self, h5_path):\n",
    "        '''Read the assets from the h5 file'''\n",
    "        assets = {}\n",
    "        with h5py.File(h5_path, 'r') as f:\n",
    "            for key in f.keys():\n",
    "                data = f[key][:]\n",
    "                if len(data.shape) == 2:  # If shape is (N, 768), apply mean\n",
    "                    data = np.mean(data, axis=0, keepdims=True)  # Shape becomes (1, 768)\n",
    "                assets[key] = data\n",
    "        return assets\n",
    "    \n",
    "    def load_data(self, label_csv):\n",
    "        label_df = pd.read_csv(label_csv)\n",
    "        labels = label_df['label'].values  # Extract label column\n",
    "        \n",
    "        all_features = []\n",
    "        for folder in self.feature_dirs:\n",
    "            for file in os.listdir(folder):\n",
    "                if file.endswith(\".h5\"):\n",
    "                    h5_path = os.path.join(folder, file)\n",
    "                    assets = self.read_assets_from_h5(h5_path)\n",
    "                    \n",
    "                    # Assuming each h5 file has only one key\n",
    "                    for key, feature in assets.items():\n",
    "                        feature = feature.flatten()  # Ensure shape is (768,)\n",
    "                        all_features.append(feature)\n",
    "        \n",
    "        all_features = np.array(all_features)  # Shape (N, 768\n",
    "        \n",
    "        return torch.tensor(all_features, dtype=torch.float32), torch.tensor(labels[:all_features.shape[0]], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Example usage\n",
    "feature_dirs = [\"model1\", \"model2\", \"model3\"]  # Update with your actual paths\n",
    "label_csv = \"labels.csv\"  # Path to your CSV file\n",
    "feature_dirs ='/data4/embedding/TCGA-BRCA/UNI'\n",
    "label_dirs = '/home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/subtype/TCGA-BRCA-SUBTYPE.csv'\n",
    "dataset = H5Dataset(feature_dirs, label_csv)\n",
    "\n",
    "\n",
    "results_df, results_agg = eval_fewshot(train_feats, train_labels, test_feats, test_labels, \n",
    "n_iter=10, n_way=5, n_shot=5, n_query=10,\n",
    "center_feats=True, normalize_feats=True, average_feats=True)\n",
    "\n",
    "print(\"Few-shot Evaluation Results:\")\n",
    "print(results_df.head())\n",
    "print(\"Aggregated Results:\", results_agg)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
