{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import ModuleList\n",
    "from functools import partial\n",
    "from typing import List, Tuple, Dict, Optional, Any\n",
    "from torchvision.transforms import Compose, RandomApply\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms.transforms import _setup_angle, _check_sequence_input\n",
    "from torch import Tensor\n",
    "from collections import defaultdict, deque\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from PIL import ImageFilter, ImageOps, Image, ImageDraw\n",
    "\n",
    "import os\n",
    "# 设定实验结果的目录 (请修改为你的实际路径)\n",
    "result_dir = \"/home/yuhaowang/project/FMBC/finetune/outputs/BRACS_Fine\"\n",
    "\n",
    "# 需要展示的评估指标\n",
    "evaluation_metrics = ['val_bacc', 'val_weighted_f1', 'val_macro_auroc']\n",
    "\n",
    "# 你希望的模型顺序（从上到下）\n",
    "desired_order = [\n",
    "    \"UNI\", \"CONCH\", \"Virchow\",\"Gigapath_Tile\",'Gigapath',\"CHIEF_Tile\",\"TITAN\",\"FMBC\"  # 请修改为你的模型名称\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# 遍历目录中的所有模型文件夹\n",
    "for model_name in os.listdir(result_dir):\n",
    "    model_path = os.path.join(result_dir, model_name, \"summary.csv\")\n",
    "    \n",
    "    # 检查是否存在 summary.csv 文件\n",
    "    if os.path.isfile(model_path):\n",
    "        df = pd.read_csv(model_path)\n",
    "\n",
    "        # 计算均值和标准差\n",
    "        summary_stats = {\"Model\": model_name}\n",
    "        for metric in evaluation_metrics:\n",
    "            if metric in df.columns:\n",
    "                mean_val = np.mean(df[metric])\n",
    "                std_val = np.std(df[metric], ddof=1)  # 样本标准差\n",
    "                summary_stats[metric] = f\"{mean_val:.3f}±{std_val:.4f}\"\n",
    "\n",
    "        # 添加到列表\n",
    "        all_results.append(summary_stats)\n",
    "\n",
    "# 转换为 DataFrame\n",
    "final_result_df = pd.DataFrame(all_results)\n",
    "\n",
    "# 按照提供的模型顺序排序\n",
    "final_result_df['sort_order'] = final_result_df['Model'].apply(lambda x: desired_order.index(x) if x in desired_order else len(desired_order))\n",
    "#delete the model not in desired_order\n",
    "final_result_df = final_result_df[final_result_df['sort_order']!=len(desired_order)]\n",
    "final_result_df = final_result_df.sort_values(by='sort_order').drop(columns=['sort_order'])\n",
    "final_result_df.style.hide(axis=\"index\")\n",
    "# 在 Jupyter Notebook 中美观显示\n",
    "display(final_result_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_path = '/home/yuhaowang/data/processed_data'\n",
    "embedding_path ='/data1/embedding'\n",
    "for dataset in os.listdir(data_path):\n",
    "    print(dataset,'has',len(os.listdir(os.path.join(data_path, dataset, 'output'))),'slides')\n",
    "    dataset_embedding_path = os.path.join(embedding_path, dataset)\n",
    "    if not os.path.exists(dataset_embedding_path):\n",
    "        print(dataset, 'has no embedding')\n",
    "        print('---------------------------')\n",
    "\n",
    "        continue\n",
    "    for model in os.listdir(dataset_embedding_path):\n",
    "        print(model,'has',len(os.listdir(os.path.join(dataset_embedding_path, model))),'slides processed')\n",
    "    print('---------------------------')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  h5py\n",
    "def read_assets_from_h5( h5_path: str) -> tuple:\n",
    "    '''Read the assets from the h5 file'''\n",
    "    assets = {}\n",
    "    attrs = {}\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        for key in f.keys():\n",
    "            assets[key] = f[key][:]\n",
    "            if f[key].attrs is not None:\n",
    "                attrs[key] = dict(f[key].attrs)\n",
    "    return assets, attrs\n",
    "\n",
    "data_dir = '/data1/embedding/TCGA-BRCA'\n",
    "for model in os.listdir(data_dir):\n",
    "    embedding_path=os.path.join(data_dir,model)\n",
    "    test_case = os.listdir(embedding_path)[0]\n",
    "    test_data,_ = read_assets_from_h5(os.path.join(embedding_path,test_case))\n",
    "    print(test_data.keys())\n",
    "    print(model)\n",
    "    print(test_data['features'].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 174\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal Test C-index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_test_cindex\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[43mtrain_survival_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 144\u001b[0m, in \u001b[0;36mtrain_survival_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    143\u001b[0m model \u001b[38;5;241m=\u001b[39m SurvivalModel(input_dim, hidden_dim, num_bins)\n\u001b[0;32m--> 144\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m    146\u001b[0m criterion \u001b[38;5;241m=\u001b[39m NLLSurvLoss()\n",
      "File \u001b[0;32m~/anaconda3/envs/UNI/lib/python3.10/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/UNI/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/UNI/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/UNI/lib/python3.10/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/UNI/lib/python3.10/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lifelines.utils import concordance_index\n",
    "#CUDA error: device-side assert triggered\n",
    "import os\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "# Loss Function (provided by you)\n",
    "class NLLSurvLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.0, eps=1e-7, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def __call__(self, x, y_bins, y_event):\n",
    "        y_event = y_event.type(torch.int64)\n",
    "        y_bins = y_bins.type(torch.int64)\n",
    "        y_censor = 1 - y_event\n",
    "        hazards = torch.sigmoid(x)\n",
    "        S = torch.cumprod(1 - hazards, dim=1)\n",
    "        S_padded = torch.cat([torch.ones_like(y_censor), S], 1)\n",
    "        s_prev = torch.gather(S_padded, dim=1, index=y_bins).clamp(min=self.eps)\n",
    "        h_this = torch.gather(hazards, dim=1, index=y_bins).clamp(min=self.eps)\n",
    "        s_this = torch.gather(S_padded, dim=1, index=y_bins + 1).clamp(min=self.eps)\n",
    "        uncensored_loss = -(1 - y_censor) * (torch.log(s_prev) + torch.log(h_this))\n",
    "        censored_loss = -y_censor * torch.log(s_this)\n",
    "        loss = uncensored_loss + self.alpha * censored_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid reduction type: {self.reduction}\")\n",
    "\n",
    "\n",
    "\n",
    "# Model Class\n",
    "class SurvivalModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)  # Output dim = number of time bins\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# C-index calculation\n",
    "def calculate_cindex(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_times = []\n",
    "    all_events = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            features = batch['features'].to(device)\n",
    "            events = batch['event'].numpy()\n",
    "            times = batch['time_bin'].numpy()\n",
    "            logits = model(features)\n",
    "            hazards = torch.sigmoid(logits)\n",
    "            survival = torch.cumprod(1 - hazards, dim=1)\n",
    "            risk_scores = -survival.sum(dim=1).cpu().numpy()  # Negative sum of survival as risk score\n",
    "            \n",
    "            all_preds.extend(risk_scores)\n",
    "            all_times.extend(times.flatten())\n",
    "            all_events.extend(events.flatten())\n",
    "    \n",
    "    cindex = concordance_index(all_times, all_preds, all_events)\n",
    "    return cindex\n",
    "\n",
    "# Main training loop\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lifelines.utils import concordance_index\n",
    "import os\n",
    "\n",
    "\n",
    "# SurvivalDataset 修改版\n",
    "class SurvivalDataset(Dataset):\n",
    "    def __init__(self, data_file, time_bins):\n",
    "        df = pd.read_csv(data_file)\n",
    "        df = df.dropna(subset=['OS_MONTHS'])\n",
    "        self.features = torch.tensor(df['Sex'].values, dtype=torch.float32).unsqueeze(1)\n",
    "        self.time_bins = time_bins\n",
    "        \n",
    "        event_np = df['OS_STATUS'].apply(lambda x: 1 if 'DECEASED' in x else 0).values\n",
    "        time_np = df['OS_MONTHS'].values\n",
    "        \n",
    "        binned_time = np.digitize(time_np, bins=time_bins[:-1]) - 1\n",
    "        num_bins = len(time_bins) - 1\n",
    "        binned_time = np.where(event_np == 1, \n",
    "                              np.clip(binned_time, 0, num_bins - 1), \n",
    "                              np.clip(binned_time, 0, num_bins))\n",
    "        self.binned_time = torch.tensor(binned_time, dtype=torch.int64).unsqueeze(1)\n",
    "        self.event = torch.tensor(event_np, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': self.features[idx],\n",
    "            'event': self.event[idx],\n",
    "            'time_bin': self.binned_time[idx]\n",
    "        }\n",
    "\n",
    "# 主训练函数修改版\n",
    "def train_survival_model():\n",
    "    input_dim = 1\n",
    "    hidden_dim = 32\n",
    "    num_bins = 10\n",
    "    batch_size = 32\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    data_file = './TCGA-BRCA-KM.csv'\n",
    "    df = pd.read_csv(data_file)\n",
    "    max_time = df['OS_MONTHS'].max() + 1\n",
    "    time_bins = np.linspace(0, max_time, num_bins + 1)\n",
    "\n",
    "    dataset = SurvivalDataset(data_file, time_bins)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = SurvivalModel(input_dim, hidden_dim, num_bins)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = NLLSurvLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            features = batch['features'].to(device)\n",
    "            time_bins = batch['time_bin'].to(device)\n",
    "            events = batch['event'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, time_bins, events)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        train_cindex = calculate_cindex(model, train_loader, device)\n",
    "        test_cindex = calculate_cindex(model, test_loader, device)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}, '\n",
    "              f'Train C-index: {train_cindex:.4f}, Test C-index: {test_cindex:.4f}')\n",
    "\n",
    "    final_test_cindex = calculate_cindex(model, test_loader, device)\n",
    "    print(f'Final Test C-index: {final_test_cindex:.4f}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_survival_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = '/home/yuhaowang/data/'\n",
    "save_dir = '/data4/embedding'\n",
    "def get_unprocessed_datasets(data_dir, processed_dir):\n",
    "    \"\"\"获取未处理的数据集\"\"\"\n",
    "    all_datasets = os.listdir(data_dir)\n",
    "    processed_datasets = os.listdir(processed_dir) if os.path.exists(processed_dir) else []\n",
    "    \n",
    "    #unprocessd_dataset= [d for d in all_datasets if len(os.listdir(os.path.join(data_dir, d,'output'))) != len(os.listdir(os.path.join(processed_dir, d, 'FMBC')))]\n",
    "    unprocessed_dataset = []\n",
    "    for d in all_datasets:\n",
    "        if len(os.listdir(os.path.join(data_dir, d, 'output'))) - len(os.listdir(os.path.join(processed_dir, d, 'FMBC')))>10:\n",
    "            unprocessed_dataset.append(d)\n",
    "    return unprocessed_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_unprocessed_datasets(data_dir, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study_ID</th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>status</th>\n",
       "      <th>time</th>\n",
       "      <th>Sex</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brca_tcga</td>\n",
       "      <td>TCGA-3C-AAAU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.95</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brca_tcga</td>\n",
       "      <td>TCGA-3C-AALI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brca_tcga</td>\n",
       "      <td>TCGA-3C-AALJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.42</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brca_tcga</td>\n",
       "      <td>TCGA-3C-AALK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brca_tcga</td>\n",
       "      <td>TCGA-4H-AAAK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.43</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>brca_tcga</td>\n",
       "      <td>TCGA-WT-AB44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>brca_tcga</td>\n",
       "      <td>TCGA-XX-A899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.34</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>brca_tcga</td>\n",
       "      <td>TCGA-XX-A89A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>brca_tcga</td>\n",
       "      <td>TCGA-Z7-A8R5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>brca_tcga</td>\n",
       "      <td>TCGA-Z7-A8R6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.96</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1101 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Study_ID    Patient_ID  status    time  Sex  label\n",
       "0     brca_tcga  TCGA-3C-AAAU     0.0  132.95    0    1.0\n",
       "1     brca_tcga  TCGA-3C-AALI     0.0  131.57    0    1.0\n",
       "2     brca_tcga  TCGA-3C-AALJ     0.0   48.42    0    1.0\n",
       "3     brca_tcga  TCGA-3C-AALK     0.0   47.57    0    1.0\n",
       "4     brca_tcga  TCGA-4H-AAAK     0.0   11.43    0    1.0\n",
       "...         ...           ...     ...     ...  ...    ...\n",
       "1096  brca_tcga  TCGA-WT-AB44     0.0   29.01    1    1.0\n",
       "1097  brca_tcga  TCGA-XX-A899     0.0   15.34    1    1.0\n",
       "1098  brca_tcga  TCGA-XX-A89A     0.0   16.03    1    1.0\n",
       "1099  brca_tcga  TCGA-Z7-A8R5     0.0  107.98    1    1.0\n",
       "1100  brca_tcga  TCGA-Z7-A8R6     0.0  106.96    1    1.0\n",
       "\n",
       "[1101 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('/home/yuhaowang/project/FMBC/finetune/dataset_csv/survival/TCGA-BRCA-KM.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status = 1-df.status\n",
    "#pass time and label is ok \n",
    "import pandas as pd\n",
    "data = pd.read_csv('/home/yuhaowang/project/Baseline/CMTA/csv/tcga_brca_all_clean.csv')\n",
    "data.head()\n",
    "#keep only some columns,  ase_id\tslide_id\tsite\tis_female\toncotree_code\tage\tsurvival_months\tcensorship\n",
    "temp = data[['case_id','slide_id','survival_months','censorship']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv('/home/yuhaowang/project/FMBC/finetune/dataset_csv/survival/TCGA-BRCA-KM.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>case_id</th>\n",
       "      <th>slide_id</th>\n",
       "      <th>survival_months</th>\n",
       "      <th>censorship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-3C-AALI</td>\n",
       "      <td>TCGA-3C-AALI-01Z-00-DX1.F6E9A5DF-D8FB-45CF-B4B...</td>\n",
       "      <td>131.57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TCGA-3C-AALI</td>\n",
       "      <td>TCGA-3C-AALI-01Z-00-DX2.CF4496E0-AB52-4F3E-BDF...</td>\n",
       "      <td>131.57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TCGA-3C-AALJ</td>\n",
       "      <td>TCGA-3C-AALJ-01Z-00-DX1.777C0957-255A-42F0-9EE...</td>\n",
       "      <td>48.42</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TCGA-3C-AALJ</td>\n",
       "      <td>TCGA-3C-AALJ-01Z-00-DX2.62DFE56B-B84C-40F9-962...</td>\n",
       "      <td>48.42</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TCGA-3C-AALK</td>\n",
       "      <td>TCGA-3C-AALK-01Z-00-DX1.4E6EB156-BB19-410F-878...</td>\n",
       "      <td>47.57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1018</td>\n",
       "      <td>TCGA-WT-AB44</td>\n",
       "      <td>TCGA-WT-AB44-01Z-00-DX1.B6ECEA7C-DA26-4B34-88C...</td>\n",
       "      <td>29.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1019</td>\n",
       "      <td>TCGA-XX-A899</td>\n",
       "      <td>TCGA-XX-A899-01Z-00-DX1.08FE27B7-73B8-4CE3-ACF...</td>\n",
       "      <td>15.34</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>1020</td>\n",
       "      <td>TCGA-XX-A89A</td>\n",
       "      <td>TCGA-XX-A89A-01Z-00-DX1.671E2AD6-4D1A-4579-88C...</td>\n",
       "      <td>16.03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>1021</td>\n",
       "      <td>TCGA-Z7-A8R5</td>\n",
       "      <td>TCGA-Z7-A8R5-01Z-00-DX1.3BDB407F-514C-4131-B05...</td>\n",
       "      <td>107.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>1022</td>\n",
       "      <td>TCGA-Z7-A8R6</td>\n",
       "      <td>TCGA-Z7-A8R6-01Z-00-DX1.CE4ED818-D762-4324-9DE...</td>\n",
       "      <td>106.96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1023 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0       case_id  \\\n",
       "0              0  TCGA-3C-AALI   \n",
       "1              1  TCGA-3C-AALI   \n",
       "2              2  TCGA-3C-AALJ   \n",
       "3              3  TCGA-3C-AALJ   \n",
       "4              4  TCGA-3C-AALK   \n",
       "...          ...           ...   \n",
       "1018        1018  TCGA-WT-AB44   \n",
       "1019        1019  TCGA-XX-A899   \n",
       "1020        1020  TCGA-XX-A89A   \n",
       "1021        1021  TCGA-Z7-A8R5   \n",
       "1022        1022  TCGA-Z7-A8R6   \n",
       "\n",
       "                                               slide_id  survival_months  \\\n",
       "0     TCGA-3C-AALI-01Z-00-DX1.F6E9A5DF-D8FB-45CF-B4B...           131.57   \n",
       "1     TCGA-3C-AALI-01Z-00-DX2.CF4496E0-AB52-4F3E-BDF...           131.57   \n",
       "2     TCGA-3C-AALJ-01Z-00-DX1.777C0957-255A-42F0-9EE...            48.42   \n",
       "3     TCGA-3C-AALJ-01Z-00-DX2.62DFE56B-B84C-40F9-962...            48.42   \n",
       "4     TCGA-3C-AALK-01Z-00-DX1.4E6EB156-BB19-410F-878...            47.57   \n",
       "...                                                 ...              ...   \n",
       "1018  TCGA-WT-AB44-01Z-00-DX1.B6ECEA7C-DA26-4B34-88C...            29.01   \n",
       "1019  TCGA-XX-A899-01Z-00-DX1.08FE27B7-73B8-4CE3-ACF...            15.34   \n",
       "1020  TCGA-XX-A89A-01Z-00-DX1.671E2AD6-4D1A-4579-88C...            16.03   \n",
       "1021  TCGA-Z7-A8R5-01Z-00-DX1.3BDB407F-514C-4131-B05...           107.98   \n",
       "1022  TCGA-Z7-A8R6-01Z-00-DX1.CE4ED818-D762-4324-9DE...           106.96   \n",
       "\n",
       "      censorship  \n",
       "0            1.0  \n",
       "1            1.0  \n",
       "2            1.0  \n",
       "3            1.0  \n",
       "4            1.0  \n",
       "...          ...  \n",
       "1018         1.0  \n",
       "1019         1.0  \n",
       "1020         1.0  \n",
       "1021         1.0  \n",
       "1022         1.0  \n",
       "\n",
       "[1023 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/home/yuhaowang/project/FMBC/finetune/dataset_csv/survival/TCGA-BRCA-Survival.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the survival data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/home/yuhaowang/project/FMBC/finetune/dataset_csv/survival/TCGA-BRCA-Survival.csv\"\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Check for necessary columns and preprocess\n",
    "required_columns = ['case_id', 'survival_months', 'censorship']\n",
    "\n",
    "# Ensure all required columns exist\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "# Drop duplicates based on case_id to get unique patients\n",
    "df = df.drop_duplicates(subset=['case_id']).reset_index(drop=True)\n",
    "\n",
    "# Define bins for discretization of survival months\n",
    "n_bins = 4\n",
    "eps = 1e-6  # Small value to adjust bin edges\n",
    "\n",
    "# Create quantile-based bins for survival months\n",
    "uncensored_df = df[df['censorship'] < 1]  # Only uncensored data for binning\n",
    "disc_labels, q_bins = pd.qcut(uncensored_df['survival_months'], q=n_bins, retbins=True, labels=False)\n",
    "\n",
    "# Adjust bin edges\n",
    "q_bins[0] = df['survival_months'].min() - eps\n",
    "q_bins[-1] = df['survival_months'].max() + eps\n",
    "\n",
    "# Apply binning to all patients\n",
    "df['disc_label'], _ = pd.cut(df['survival_months'], bins=q_bins, labels=False, retbins=True, right=False, include_lowest=True)\n",
    "df['disc_label'] = df['disc_label'].astype(int)  # Ensure integer labels\n",
    "\n",
    "# Save the processed dataset\n",
    "# processed_file_path = \"/mnt/data/TCGA-BRCA-Survival-Processed.csv\"\n",
    "df.to_csv(\"/home/yuhaowang/project/FMBC/finetune/dataset_csv/survival/TCGA-BRCA-Survival.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: /home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_ER.csv\n",
      "Generated: /home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_PR.csv\n",
      "Generated: /home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_pCR.csv\n",
      "Generated: /home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_PD-L1-tumor.csv\n",
      "Generated: /home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_PD-L1-stroma.csv\n",
      "Generated: /home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_CD8-peritumoral.csv\n",
      "Generated: /home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_CD8-intratumoral.csv\n",
      "Generated: /home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_CD163-intratumoral.csv\n",
      "Generated: /home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_CD163-peritumoral.csv\n"
     ]
    }
   ],
   "source": [
    "#/home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_HER2_2subtype.csv\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# 读取CSV文件\n",
    "file_path = '/home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_HER2_2subtype.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 确保 'slide id' 存在\n",
    "if 'slide_id' in df.columns:\n",
    "    slide_id_col = df['slide_id']\n",
    "    \n",
    "    # 遍历其他列，分别创建新CSV\n",
    "    for column in df.columns:\n",
    "        if column != 'slide_id':\n",
    "            new_df = pd.DataFrame({'slide_id': slide_id_col, column: df[column]})\n",
    "            new_file_path = f\"/home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_{column}.csv\"\n",
    "            new_df.to_csv(new_file_path, index=False)\n",
    "            print(f\"Generated: {new_file_path}\")\n",
    "else:\n",
    "    print(\"Error: 'slide id' column not found in the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_TNBC_2subtype.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(columns=['pCR (no-0, yes-1)'], inplace=True)\n",
    "df.to_csv('/home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/biomarker/IMPRESS_TNBC_2subtype.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CONCH/TCGA-D8-A3Z6-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CONCH/TCGA-PL-A8LZ-01A-03-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CONCH/TCGA-OK-A5Q2-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CONCH/TCGA-OK-A5Q2-01Z-00-DX3.5F9215C3-E407-46F8-968E-503D7D14605C.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CONCH/TCGA-PL-A8LZ-01A-03-DX3.E5D16DBF-CABD-4C96-A794-5F27BC305055.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CONCH/TCGA-OK-A5Q2-01Z-00-DX4.83B45D6C-E350-4436-812F-4155D9F7D331.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CONCH/TCGA-D8-A3Z5-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CONCH/TCGA-OK-A5Q2-01Z-00-DX4.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CONCH/TCGA-D8-A3Z5-01Z-00-DX3.BB83C7D4-F795-47E7-9A5C-7DBF0EB7FDAA.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/UNI/TCGA-D8-A3Z6-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/UNI/TCGA-OK-A5Q2-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/UNI/TCGA-D8-A3Z5-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/UNI/TCGA-OK-A5Q2-01Z-00-DX4.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CHIEF/TCGA-D8-A3Z6-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CHIEF/TCGA-PL-A8LZ-01A-03-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CHIEF/TCGA-OK-A5Q2-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CHIEF/TCGA-D8-A3Z5-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CHIEF/TCGA-OK-A5Q2-01Z-00-DX4.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/Gigapath_tile/TCGA-D8-A3Z6-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/Gigapath_tile/TCGA-PL-A8LZ-01A-03-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/Gigapath_tile/TCGA-OK-A5Q2-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/Gigapath_tile/TCGA-D8-A3Z5-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/Gigapath_tile/TCGA-OK-A5Q2-01Z-00-DX4.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/Gigapath/TCGA-D8-A3Z6-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/Gigapath/TCGA-PL-A8LZ-01A-03-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/Gigapath/TCGA-OK-A5Q2-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/Gigapath/TCGA-D8-A3Z5-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/Gigapath/TCGA-OK-A5Q2-01Z-00-DX4.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CHIEF_tile/TCGA-D8-A3Z6-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CHIEF_tile/TCGA-PL-A8LZ-01A-03-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CHIEF_tile/TCGA-OK-A5Q2-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CHIEF_tile/TCGA-D8-A3Z5-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/CHIEF_tile/TCGA-OK-A5Q2-01Z-00-DX4.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/TITAN/TCGA-D8-A3Z6-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/TITAN/TCGA-PL-A8LZ-01A-03-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/TITAN/TCGA-OK-A5Q2-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/TITAN/TCGA-OK-A5Q2-01Z-00-DX3.5F9215C3-E407-46F8-968E-503D7D14605C.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/TITAN/TCGA-PL-A8LZ-01A-03-DX3.E5D16DBF-CABD-4C96-A794-5F27BC305055.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/TITAN/TCGA-OK-A5Q2-01Z-00-DX4.83B45D6C-E350-4436-812F-4155D9F7D331.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/TITAN/TCGA-D8-A3Z5-01Z-00-DX3.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/TITAN/TCGA-OK-A5Q2-01Z-00-DX4.h5\n",
      "Deleted: /data4/fm_embedding/embedding/TCGA-BRCA/TITAN/TCGA-D8-A3Z5-01Z-00-DX3.BB83C7D4-F795-47E7-9A5C-7DBF0EB7FDAA.h5\n"
     ]
    }
   ],
   "source": [
    "#/data4/fm_embedding/embedding/TCGA-BRCA\n",
    "#glob matching all h5 file recursively, delete name contain DX1\n",
    "import os\n",
    "import glob\n",
    "data_dir = '/data4/fm_embedding/embedding/TCGA-BRCA'\n",
    "for filename in glob.iglob(os.path.join(data_dir, '**/*.h5'), recursive=True):\n",
    "    if 'DX1' in filename or 'DX2' in filename or 'DX3' in filename or 'DX4' in filename:\n",
    "        os.remove(filename)\n",
    "        print(f\"Deleted: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/yuhaowang/project/FMBC/downstream/finetune/dataset_csv/subtype/DORID_2.csv'\n",
    "import pandas as pd \n",
    "data = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide_id</th>\n",
       "      <th>IDC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI-DRBR-001_2523</td>\n",
       "      <td>Invasive carcinoma of breast (disorder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI-DRBR-002_1975</td>\n",
       "      <td>Invasive carcinoma of breast (disorder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI-DRBR-003_2478</td>\n",
       "      <td>Invasive carcinoma of breast (disorder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI-DRBR-004_1358</td>\n",
       "      <td>Invasive carcinoma of breast (disorder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI-DRBR-005_1984</td>\n",
       "      <td>non-invasive carcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>AI-DRBR-155_2313</td>\n",
       "      <td>Invasive carcinoma of breast (disorder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>AI-DRBR-156_2361</td>\n",
       "      <td>Invasive carcinoma of breast (disorder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>AI-DRBR-158_1335</td>\n",
       "      <td>Invasive carcinoma of breast (disorder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>AI-DRBR-159_2229</td>\n",
       "      <td>Invasive carcinoma of breast (disorder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             slide_id                                       IDC\n",
       "0    AI-DRBR-001_2523   Invasive carcinoma of breast (disorder)\n",
       "1    AI-DRBR-002_1975   Invasive carcinoma of breast (disorder)\n",
       "2    AI-DRBR-003_2478   Invasive carcinoma of breast (disorder)\n",
       "3    AI-DRBR-004_1358   Invasive carcinoma of breast (disorder)\n",
       "4    AI-DRBR-005_1984                    non-invasive carcinoma\n",
       "..                ...                                       ...\n",
       "283  AI-DRBR-155_2313   Invasive carcinoma of breast (disorder)\n",
       "284  AI-DRBR-156_2361   Invasive carcinoma of breast (disorder)\n",
       "285  AI-DRBR-158_1335   Invasive carcinoma of breast (disorder)\n",
       "286  AI-DRBR-159_2229   Invasive carcinoma of breast (disorder)\n",
       "287               NaN                                       NaN\n",
       "\n",
       "[288 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows duplicate \n",
    "data.drop_duplicates(subset=['slide_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
